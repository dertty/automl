{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ee419fd-0036-4e95-b925-9cff1ec9904b",
   "metadata": {},
   "source": [
    "## This example contains sample script for feature processing and launching models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8ec103b6-8a2a-45d8-9a28-d6edc05330c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pprint import pp\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccad833c-831f-4dc3-9699-54ceb8559309",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42\n",
    "N_JOBS = 5\n",
    "TARGET = \"satisfaction\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b4eaa5-0154-4f0f-ae3b-853e2e659c00",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54a42b70-fe20-4e73-af2b-c436932983ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10000 entries, 80638 to 16420\n",
      "Data columns (total 25 columns):\n",
      " #   Column                             Non-Null Count  Dtype  \n",
      "---  ------                             --------------  -----  \n",
      " 0   id                                 10000 non-null  int64  \n",
      " 1   Gender                             10000 non-null  object \n",
      " 2   Customer Type                      10000 non-null  object \n",
      " 3   Age                                10000 non-null  int64  \n",
      " 4   Type of Travel                     10000 non-null  object \n",
      " 5   Class                              10000 non-null  object \n",
      " 6   Flight Distance                    10000 non-null  int64  \n",
      " 7   Inflight wifi service              10000 non-null  int64  \n",
      " 8   Departure/Arrival time convenient  10000 non-null  int64  \n",
      " 9   Ease of Online booking             10000 non-null  int64  \n",
      " 10  Gate location                      10000 non-null  int64  \n",
      " 11  Food and drink                     10000 non-null  int64  \n",
      " 12  Online boarding                    10000 non-null  int64  \n",
      " 13  Seat comfort                       10000 non-null  int64  \n",
      " 14  Inflight entertainment             10000 non-null  int64  \n",
      " 15  On-board service                   10000 non-null  int64  \n",
      " 16  Leg room service                   10000 non-null  int64  \n",
      " 17  Baggage handling                   10000 non-null  int64  \n",
      " 18  Checkin service                    10000 non-null  int64  \n",
      " 19  Inflight service                   10000 non-null  int64  \n",
      " 20  Cleanliness                        10000 non-null  int64  \n",
      " 21  Departure Delay in Minutes         10000 non-null  int64  \n",
      " 22  Arrival Delay in Minutes           9975 non-null   float64\n",
      " 23  satisfaction                       10000 non-null  object \n",
      " 24  cnst                               10000 non-null  int64  \n",
      "dtypes: float64(1), int64(19), object(5)\n",
      "memory usage: 2.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/airlines_train.csv\").drop(columns=\"Unnamed: 0\").sample(n=10_000, random_state=RANDOM_STATE).assign(cnst=1); df.info()\n",
    "X, y = df.drop(columns=TARGET), df[TARGET]\n",
    "\n",
    "# rename X columns to remove \"-\" symbol (not processed by catboost)\n",
    "X = X.rename(columns = lambda x:re.sub('-', '', x))\n",
    "y = LabelEncoder().fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test  = train_test_split(X, y, stratify=y, random_state=RANDOM_STATE, test_size=0.2)\n",
    "\n",
    "X_train = X_train.reset_index(drop=True)\n",
    "X_test = X_test.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8fdd8f3-958d-4ba7-95e8-b60223894fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'nlp' extra dependecy package 'gensim' isn't installed. Look at README.md in repo 'LightAutoML' for installation instructions.\n",
      "'nlp' extra dependecy package 'nltk' isn't installed. Look at README.md in repo 'LightAutoML' for installation instructions.\n",
      "'nlp' extra dependecy package 'transformers' isn't installed. Look at README.md in repo 'LightAutoML' for installation instructions.\n",
      "'nlp' extra dependecy package 'gensim' isn't installed. Look at README.md in repo 'LightAutoML' for installation instructions.\n",
      "'nlp' extra dependecy package 'nltk' isn't installed. Look at README.md in repo 'LightAutoML' for installation instructions.\n",
      "'nlp' extra dependecy package 'transformers' isn't installed. Look at README.md in repo 'LightAutoML' for installation instructions.\n",
      "[2024-12-09 11:54:27]\n",
      "/workspaces/python/venvs/lama_venv/lib/python3.9/site-packages/lightautoml/ml_algo/dl_model.py:42: UserWarning: 'transformers' - package isn't installed\n",
      "  warnings.warn(\"'transformers' - package isn't installed\")\n",
      "/workspaces/python/venvs/lama_venv/lib/python3.9/site-packages/lightautoml/text/embed.py:22: UserWarning: 'transformers' - package isn't installed\n",
      "  warnings.warn(\"'transformers' - package isn't installed\")\n",
      "/workspaces/python/venvs/lama_venv/lib/python3.9/site-packages/lightautoml/text/dl_transformers.py:25: UserWarning: 'transformers' - package isn't installed\n",
      "  warnings.warn(\"'transformers' - package isn't installed\")\n"
     ]
    }
   ],
   "source": [
    "import sys; sys.path.append(\"../\"); sys.path.append(\"../src/\")\n",
    "\n",
    "from src.automl.feature_processing import PreprocessingPipeline, ValTestsPipeline, CatboostShapFeatureSelector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9037b926-4de1-439c-acad-9df40061c834",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-12-09 11:54:28,204] - [  PREPROC   ] - Успешно заданы шаги pipeline\n",
      "[2024-12-09 11:54:28,206] - [ VAL TESTS  ] - Успешно заданы шаги pipeline\n"
     ]
    }
   ],
   "source": [
    "feat_pipe = PreprocessingPipeline(obj_encoders=[\"oe\"])\n",
    "val_test_pipe = ValTestsPipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef386a2-9087-491c-98c1-449332c5476a",
   "metadata": {},
   "source": [
    "#### Feature pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "043ceefa-b632-4ba6-ba2b-688d78aa0741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial train data shape (8000, 24)\n",
      "[2024-12-09 11:54:28,225] - [Pipeline] .. (step 1 of 6) Processing nan_cols_dropper, total=   0.0\n",
      "[2024-12-09 11:54:28,253] - [Pipeline] ....... (step 2 of 6) Processing nan_imputer, total=   0.0\n",
      "[2024-12-09 11:54:28,269] - [  PREPROC   ] - QConstant features to drop: ['cnst']\n",
      "[2024-12-09 11:54:28,272] - [Pipeline] .... (step 3 of 6) Processing qconst_dropper, total=   0.0\n",
      "[2024-12-09 11:54:28,285] - [  PREPROC   ] - Corr features to drop: ['Arrival Delay in Minutes', 'Arrival Delay in Minutes']\n",
      "[2024-12-09 11:54:28,286] - [Pipeline] . (step 4 of 6) Processing corr_cols_dropper, total=   0.0\n",
      "[2024-12-09 11:54:28,324] - [Pipeline] .... (step 5 of 6) Processing outlier_capper, total=   0.0\n",
      "[2024-12-09 11:54:28,358] - [Pipeline] ... (step 6 of 6) Processing feature_encoder, total=   0.0\n",
      "Train data shape after pipeline (8000, 22)\n"
     ]
    }
   ],
   "source": [
    "print(\"Initial train data shape\", X_train.shape)\n",
    "X_train = feat_pipe.fit_transform(X_train, y_train)\n",
    "print(\"Train data shape after pipeline\", X_train.shape)\n",
    "X_test = feat_pipe.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365259ae-17b6-44cc-84da-0e244ae78b10",
   "metadata": {},
   "source": [
    "#### ValTest pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c974e198-0f45-41b5-8f10-3c1a9411611b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## adding evidently shifted by distribution features\n",
    "X_train[\"bad_feature\"] = np.random.uniform(0, 10, size=X_train.shape[0])\n",
    "X_test[\"bad_feature\"] = np.random.uniform(5, 15, size=X_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cdc72841-f88f-4bd7-bab3-587587f54eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial train data shape (8000, 23)\n",
      "[2024-12-09 11:54:28,811] - [ VAL TESTS  ] - Features not passing psi test to drop: ['bad_feature']\n",
      "[2024-12-09 11:54:28,812] - [Pipeline] .......... (step 1 of 2) Processing PSI_test, total=   0.3\n",
      "[2024-12-09 11:54:28,947] - [Pipeline] .. (step 2 of 2) Processing Adversarial_test, total=   0.1\n",
      "Train data shape after pipeline (8000, 22)\n"
     ]
    }
   ],
   "source": [
    "print(\"Initial train data shape\", X_train.shape)\n",
    "X_train = val_test_pipe.fit_transform(X_train, X_test)\n",
    "print(\"Train data shape after pipeline\", X_train.shape)\n",
    "X_test = val_test_pipe.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ddc0f234-f755-4957-985e-b62fafcdf63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = X_train.columns[(X_train.columns.str.startswith(\"OneHotEncoder\")) | (X_train.columns.str.startswith(\"OrdinalEncoder\"))].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11eb84d7-d1a1-4cce-811e-0945bbd6b394",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['OrdinalEncoder__Gender',\n",
       " 'OrdinalEncoder__Customer Type',\n",
       " 'OrdinalEncoder__Type of Travel',\n",
       " 'OrdinalEncoder__Class']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b11dbde-87ec-41e0-8c42-3dcac1dfe3c9",
   "metadata": {},
   "source": [
    "#### Select features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86b14a35-07d2-4532-a241-8abf95951412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-12-09 11:54:30,337] - [  FEAT SEL  ] - Started feature selection.\n",
      "[2024-12-09 11:55:04,990] - [  FEAT SEL  ] - Selected features: ['OrdinalEncoder__Customer Type', 'OrdinalEncoder__Type of Travel', 'OrdinalEncoder__Class', 'StandardScaler__Inflight wifi service', 'StandardScaler__Departure/Arrival time convenient', 'StandardScaler__Online boarding', 'StandardScaler__Inflight entertainment', 'StandardScaler__Baggage handling', 'StandardScaler__Checkin service', 'StandardScaler__Inflight service']\n"
     ]
    }
   ],
   "source": [
    "selector = CatboostShapFeatureSelector(\n",
    "    n_features_to_select=10,\n",
    "    n_jobs=N_JOBS,\n",
    "    steps=5\n",
    ")\n",
    "\n",
    "X_train = selector.fit_transform(X_train, y_train, categorical_features=cat_features)\n",
    "X_test = selector.transform(X_test)\n",
    "\n",
    "# correct cat_features\n",
    "cat_features = X_train.columns[(X_train.columns.str.startswith(\"OneHotEncoder\")) | (X_train.columns.str.startswith(\"OrdinalEncoder\"))].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c016435-bc58-452e-a373-89a49e6f4aaa",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5df826c9-c236-4818-961a-c5ef19937f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.automl.model import AutoML\n",
    "from src.automl.model.models_lists import linear_models, forest_models, boosting_models, lama_models, lama_nn_models, all_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "99d9cdba-b2b9-4b1c-84f5-92f0bf0d12e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear models:\n",
      "{'regression': [<class 'src.automl.model.linear.linear.RidgeRegression'>],\n",
      " 'classification': [<class 'src.automl.model.linear.linear.LogisticRegression'>]}\n",
      "\n",
      "\n",
      "Forest models:\n",
      "{'regression': [<class 'src.automl.model.sklearn_forests.random_forests.RandomForestRegression'>,\n",
      "                <class 'src.automl.model.sklearn_forests.extra_forests.ExtraTreesRegression'>],\n",
      " 'classification': [<class 'src.automl.model.sklearn_forests.random_forests.RandomForestClassification'>,\n",
      "                    <class 'src.automl.model.sklearn_forests.extra_forests.ExtraTreesClassification'>]}\n",
      "\n",
      "\n",
      "Boostings:\n",
      "{'regression': [<class 'src.automl.model.catboost.catboost.CatBoostRegression'>,\n",
      "                <class 'src.automl.model.xgboost.xgboost.XGBRegression'>,\n",
      "                <class 'src.automl.model.lightgbm.lightgbm.LightGBMRegression'>],\n",
      " 'classification': [<class 'src.automl.model.catboost.catboost.CatBoostClassification'>,\n",
      "                    <class 'src.automl.model.xgboost.xgboost.XGBClassification'>,\n",
      "                    <class 'src.automl.model.lightgbm.lightgbm.LightGBMClassification'>]}\n",
      "\n",
      "\n",
      "LAMA models:\n",
      "{'regression': [(<class 'src.automl.model.lama.default_lama.TabularLama'>,\n",
      "                 {'task': 'regression'}),\n",
      "                (<class 'src.automl.model.lama.default_lama.TabularLamaUtilized'>,\n",
      "                 {'task': 'regression'})],\n",
      " 'classification': [(<class 'src.automl.model.lama.default_lama.TabularLama'>,\n",
      "                     {'task': 'classification'}),\n",
      "                    (<class 'src.automl.model.lama.default_lama.TabularLamaUtilized'>,\n",
      "                     {'task': 'classification'})]}\n",
      "\n",
      "\n",
      "LAMA_NN models:\n",
      "{'regression': [(<class 'src.automl.model.lama.nn_lama.TabularLamaNN'>,\n",
      "                 {'nn_name': 'mlp', 'task': 'regression'}),\n",
      "                (<class 'src.automl.model.lama.nn_lama.TabularLamaNN'>,\n",
      "                 {'nn_name': 'denselight', 'task': 'regression'}),\n",
      "                (<class 'src.automl.model.lama.nn_lama.TabularLamaNN'>,\n",
      "                 {'nn_name': 'dense', 'task': 'regression'}),\n",
      "                (<class 'src.automl.model.lama.nn_lama.TabularLamaNN'>,\n",
      "                 {'nn_name': 'node', 'task': 'regression'}),\n",
      "                (<class 'src.automl.model.lama.nn_lama.TabularLamaNN'>,\n",
      "                 {'nn_name': 'autoint', 'task': 'regression'}),\n",
      "                (<class 'src.automl.model.lama.nn_lama.TabularLamaNN'>,\n",
      "                 {'nn_name': 'fttransformer', 'task': 'regression'})],\n",
      " 'classification': [(<class 'src.automl.model.lama.nn_lama.TabularLamaNN'>,\n",
      "                     {'nn_name': 'mlp', 'task': 'classification'}),\n",
      "                    (<class 'src.automl.model.lama.nn_lama.TabularLamaNN'>,\n",
      "                     {'nn_name': 'denselight', 'task': 'classification'}),\n",
      "                    (<class 'src.automl.model.lama.nn_lama.TabularLamaNN'>,\n",
      "                     {'nn_name': 'dense', 'task': 'classification'}),\n",
      "                    (<class 'src.automl.model.lama.nn_lama.TabularLamaNN'>,\n",
      "                     {'nn_name': 'node', 'task': 'classification'}),\n",
      "                    (<class 'src.automl.model.lama.nn_lama.TabularLamaNN'>,\n",
      "                     {'nn_name': 'autoint', 'task': 'classification'}),\n",
      "                    (<class 'src.automl.model.lama.nn_lama.TabularLamaNN'>,\n",
      "                     {'nn_name': 'fttransformer', 'task': 'classification'})]}\n",
      "\n",
      "\n",
      "All models:\n",
      "{'regression': [<class 'src.automl.model.linear.linear.RidgeRegression'>,\n",
      "                <class 'src.automl.model.sklearn_forests.random_forests.RandomForestRegression'>,\n",
      "                <class 'src.automl.model.sklearn_forests.extra_forests.ExtraTreesRegression'>,\n",
      "                <class 'src.automl.model.catboost.catboost.CatBoostRegression'>,\n",
      "                <class 'src.automl.model.xgboost.xgboost.XGBRegression'>,\n",
      "                <class 'src.automl.model.lightgbm.lightgbm.LightGBMRegression'>,\n",
      "                (<class 'src.automl.model.lama.default_lama.TabularLama'>,\n",
      "                 {'task': 'regression'}),\n",
      "                (<class 'src.automl.model.lama.default_lama.TabularLamaUtilized'>,\n",
      "                 {'task': 'regression'}),\n",
      "                (<class 'src.automl.model.lama.nn_lama.TabularLamaNN'>,\n",
      "                 {'nn_name': 'mlp', 'task': 'regression'}),\n",
      "                (<class 'src.automl.model.lama.nn_lama.TabularLamaNN'>,\n",
      "                 {'nn_name': 'denselight', 'task': 'regression'}),\n",
      "                (<class 'src.automl.model.lama.nn_lama.TabularLamaNN'>,\n",
      "                 {'nn_name': 'dense', 'task': 'regression'}),\n",
      "                (<class 'src.automl.model.lama.nn_lama.TabularLamaNN'>,\n",
      "                 {'nn_name': 'node', 'task': 'regression'}),\n",
      "                (<class 'src.automl.model.lama.nn_lama.TabularLamaNN'>,\n",
      "                 {'nn_name': 'autoint', 'task': 'regression'}),\n",
      "                (<class 'src.automl.model.lama.nn_lama.TabularLamaNN'>,\n",
      "                 {'nn_name': 'fttransformer', 'task': 'regression'})],\n",
      " 'classification': [<class 'src.automl.model.linear.linear.LogisticRegression'>,\n",
      "                    <class 'src.automl.model.sklearn_forests.random_forests.RandomForestClassification'>,\n",
      "                    <class 'src.automl.model.sklearn_forests.extra_forests.ExtraTreesClassification'>,\n",
      "                    <class 'src.automl.model.catboost.catboost.CatBoostClassification'>,\n",
      "                    <class 'src.automl.model.xgboost.xgboost.XGBClassification'>,\n",
      "                    <class 'src.automl.model.lightgbm.lightgbm.LightGBMClassification'>,\n",
      "                    (<class 'src.automl.model.lama.default_lama.TabularLama'>,\n",
      "                     {'task': 'classification'}),\n",
      "                    (<class 'src.automl.model.lama.default_lama.TabularLamaUtilized'>,\n",
      "                     {'task': 'classification'}),\n",
      "                    (<class 'src.automl.model.lama.nn_lama.TabularLamaNN'>,\n",
      "                     {'nn_name': 'mlp', 'task': 'classification'}),\n",
      "                    (<class 'src.automl.model.lama.nn_lama.TabularLamaNN'>,\n",
      "                     {'nn_name': 'denselight', 'task': 'classification'}),\n",
      "                    (<class 'src.automl.model.lama.nn_lama.TabularLamaNN'>,\n",
      "                     {'nn_name': 'dense', 'task': 'classification'}),\n",
      "                    (<class 'src.automl.model.lama.nn_lama.TabularLamaNN'>,\n",
      "                     {'nn_name': 'node', 'task': 'classification'}),\n",
      "                    (<class 'src.automl.model.lama.nn_lama.TabularLamaNN'>,\n",
      "                     {'nn_name': 'autoint', 'task': 'classification'}),\n",
      "                    (<class 'src.automl.model.lama.nn_lama.TabularLamaNN'>,\n",
      "                     {'nn_name': 'fttransformer', 'task': 'classification'})]}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, cont in zip([\"Linear models\", \"Forest models\", \"Boostings\", \"LAMA models\", \"LAMA_NN models\", \"All models\"],\n",
    "                      [linear_models, forest_models, boosting_models, lama_models, lama_nn_models, all_models]):\n",
    "    print(f\"{name}:\")\n",
    "    pp(cont)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c8822ae4-d358-471f-b1ad-2e3ba0929697",
   "metadata": {},
   "outputs": [],
   "source": [
    "TUNING_TIMEOUT = 60 # time for tuning each model\n",
    "TASK = \"classification\" # one of [\"regression\", \"classification\"]\n",
    "METRIC = \"roc_auc\" # either sklearn metirc or a custom metric\n",
    "STACK = True # whether to perform stacking\n",
    "BLEND = True # whether to perform blending\n",
    "MODELS_LIST = linear_models[TASK] + forest_models[TASK] + boosting_models[TASK] + lama_models[TASK]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0285da8c-b2d0-4d66-9fb5-223162d76893",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoML(\n",
    "    task=TASK,\n",
    "    models_list=MODELS_LIST,\n",
    "    metric=METRIC,\n",
    "    n_jobs=N_JOBS,\n",
    "    tuning_timeout=TUNING_TIMEOUT,\n",
    "    stack=STACK,\n",
    "    blend=BLEND\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f8357fb2-ec89-4c95-adc0-c0e501786184",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-12-09 12:11:06,768] - [   MODEL    ] - 1 out of 10. LogisticRegression\n",
      "[2024-12-09 12:11:06,771] - [   START    ] - Working with LogisticRegression\n",
      "[2024-12-09 12:11:06,772] - [   START    ] - Tuning LogisticRegression\n",
      "[2024-12-09 12:11:07,937] - [   PARAMS   ] - C=0.3593813663804626, metric=0.9205910173274916\n",
      "[2024-12-09 12:11:07,938] - [BEST PARAMS ] - {'C': 0.3593813663804626, 'class_weight': 'balanced', 'max_iter': 1000, 'n_jobs': 5, 'random_state': 42, 'time_series': False}\n",
      "[2024-12-09 12:11:07,938] - [    END     ] - Tuning LogisticRegression\n",
      "[2024-12-09 12:11:07,938] - [   START    ] - Fitting LogisticRegression\n",
      "[2024-12-09 12:11:07,941] - [    FIT     ] - LogisticRegression fold 0\n",
      "[2024-12-09 12:11:07,970] - [    FIT     ] - LogisticRegression fold 1\n",
      "[2024-12-09 12:11:07,991] - [    FIT     ] - LogisticRegression fold 2\n",
      "[2024-12-09 12:11:08,012] - [    FIT     ] - LogisticRegression fold 3\n",
      "[2024-12-09 12:11:08,030] - [    FIT     ] - LogisticRegression fold 4\n",
      "[2024-12-09 12:11:08,052] - [    END     ] - Fitting LogisticRegression\n",
      "[2024-12-09 12:11:08,066] - [   SCORE    ] - Train: 0.9214138323181766\n",
      "[2024-12-09 12:11:08,071] - [   SCORE    ] - OOF: 0.9202374715224696\n",
      "[2024-12-09 12:11:08,084] - [   SCORE    ] - Test: 0.920195330485399\n",
      "[2024-12-09 12:11:08,085] - [   SCORE    ] - Overfit: 0.13 %\n",
      "[2024-12-09 12:11:08,086] - [    END     ] - Working with LogisticRegression\n",
      "[2024-12-09 12:11:08,086] - [  NEW BEST  ] - LogisticRegression. Best score: 0.920195330485399 \n",
      "\n",
      "[2024-12-09 12:11:08,086] - [   MODEL    ] - 2 out of 10. RandomForestClassification\n",
      "[2024-12-09 12:11:08,087] - [   START    ] - Working with RandomForestClassification\n",
      "[2024-12-09 12:11:08,087] - [   START    ] - Tuning RandomForestClassification\n",
      "[2024-12-09 12:11:10,716] - [   OPTUNA   ] - Trial 0. New best score 0.9254733929326653 with parameters {'n_estimators': 387, 'max_depth': 15, 'min_samples_split': 0.146398788362281, 'min_samples_leaf': 0.11973169683940732, 'max_features': 0.24041677639819287, 'criterion': 'log_loss', 'class_weight': 'balanced_subsample', 'oob_score': False, 'max_samples': 0.8341182143924175}\n",
      "[2024-12-09 12:11:12,515] - [   OPTUNA   ] - Trial 1. New best score 0.9263328250938618 with parameters {'n_estimators': 228, 'max_depth': 4, 'min_samples_split': 0.03668090197068676, 'min_samples_leaf': 0.06084844859190755, 'max_features': 0.5722807884690141, 'criterion': 'log_loss', 'class_weight': 'balanced_subsample', 'oob_score': False, 'max_samples': 0.7873242017790835}\n",
      "[2024-12-09 12:11:14,670] - [   OPTUNA   ] - Trial 2. New best score 0.9477634583392849 with parameters {'n_estimators': 215, 'max_depth': 9, 'min_samples_split': 0.1184829137724085, 'min_samples_leaf': 0.009290082543999545, 'max_features': 0.6467903667112945, 'criterion': 'log_loss', 'class_weight': 'balanced', 'oob_score': True, 'max_samples': 0.6873906962470353}\n",
      "[2024-12-09 12:11:18,083] - [   OPTUNA   ] - Trial 3. New best score 0.949041230062974 with parameters {'n_estimators': 451, 'max_depth': 3, 'min_samples_split': 0.09903538202225404, 'min_samples_leaf': 0.006877704223043679, 'max_features': 0.9183883618709039, 'criterion': 'entropy', 'class_weight': 'balanced_subsample', 'oob_score': False, 'max_samples': 0.7773814951275034}\n",
      "[2024-12-09 12:11:48,946] - [   OPTUNA   ] - Trial 11. New best score 0.9609443695947201 with parameters {'n_estimators': 32, 'max_depth': 10, 'min_samples_split': 0.07121824466699872, 'min_samples_leaf': 0.004689401807340943, 'max_features': 0.7134393876140748, 'criterion': 'entropy', 'class_weight': 'balanced_subsample', 'oob_score': True, 'max_samples': 0.6405508745066752}\n",
      "[2024-12-09 12:11:49,727] - [   OPTUNA   ] - Trial 13. New best score 0.9615169111056907 with parameters {'n_estimators': 36, 'max_depth': 7, 'min_samples_split': 0.054273833433723856, 'min_samples_leaf': 0.0003893728893889538, 'max_features': 0.8460708041987088, 'criterion': 'entropy', 'class_weight': 'balanced_subsample', 'oob_score': False, 'max_samples': 0.36629114865941276}\n",
      "[2024-12-09 12:12:00,389] - [   OPTUNA   ] - Trial 18. New best score 0.9806906463793504 with parameters {'n_estimators': 736, 'max_depth': 8, 'min_samples_split': 0.020097467198428025, 'min_samples_leaf': 7.804930399116401e-05, 'max_features': 0.6982270461963013, 'criterion': 'entropy', 'class_weight': 'balanced_subsample', 'oob_score': False, 'max_samples': 0.5724800915555452}\n",
      "[2024-12-09 12:12:09,028] - [   OPTUNA   ] - 21 trials completed\n",
      "[2024-12-09 12:12:09,029] - [BEST PARAMS ] - {'n_estimators': 736, 'criterion': 'entropy', 'max_depth': 8, 'min_samples_split': 0.020097467198428025, 'min_samples_leaf': 7.804930399116401e-05, 'max_features': 0.6982270461963013, 'bootstrap': True, 'oob_score': False, 'max_samples': 0.5724800915555452, 'class_weight': 'balanced_subsample', 'n_jobs': 5, 'random_state': 42, 'verbose': 0, 'time_series': False}\n",
      "[2024-12-09 12:12:09,029] - [    END     ] - Tuning RandomForestClassification\n",
      "[2024-12-09 12:12:09,030] - [   START    ] - Fitting RandomForestClassification\n",
      "[2024-12-09 12:12:09,035] - [    FIT     ] - RandomForestClassification fold 0\n",
      "[2024-12-09 12:12:11,972] - [    FIT     ] - RandomForestClassification fold 1\n",
      "[2024-12-09 12:12:14,832] - [    FIT     ] - RandomForestClassification fold 2\n",
      "[2024-12-09 12:12:17,697] - [    FIT     ] - RandomForestClassification fold 3\n",
      "[2024-12-09 12:12:20,961] - [    FIT     ] - RandomForestClassification fold 4\n",
      "[2024-12-09 12:12:24,457] - [    END     ] - Fitting RandomForestClassification\n",
      "[2024-12-09 12:12:25,396] - [   SCORE    ] - Train: 0.9823976922821341\n",
      "[2024-12-09 12:12:25,400] - [   SCORE    ] - OOF: 0.9804762669828871\n",
      "[2024-12-09 12:12:26,230] - [   SCORE    ] - Test: 0.9825429349985924\n",
      "[2024-12-09 12:12:26,231] - [   SCORE    ] - Overfit: 0.01 %\n",
      "[2024-12-09 12:12:26,231] - [    END     ] - Working with RandomForestClassification\n",
      "[2024-12-09 12:12:26,231] - [  NEW BEST  ] - RandomForestClassification. Best score: 0.9825429349985924 \n",
      "\n",
      "[2024-12-09 12:12:26,232] - [   MODEL    ] - 3 out of 10. ExtraTreesClassification\n",
      "[2024-12-09 12:12:26,233] - [   START    ] - Working with ExtraTreesClassification\n",
      "[2024-12-09 12:12:26,233] - [   START    ] - Tuning ExtraTreesClassification\n",
      "[2024-12-09 12:12:28,627] - [   OPTUNA   ] - Trial 0. New best score 0.9101031994057276 with parameters {'n_estimators': 387, 'max_depth': 15, 'min_samples_split': 0.146398788362281, 'min_samples_leaf': 0.11973169683940732, 'max_features': 0.24041677639819287, 'criterion': 'log_loss', 'class_weight': 'balanced_subsample', 'oob_score': False, 'max_samples': 0.8341182143924175}\n",
      "[2024-12-09 12:12:30,489] - [   OPTUNA   ] - Trial 1. New best score 0.9284892937646102 with parameters {'n_estimators': 228, 'max_depth': 4, 'min_samples_split': 0.03668090197068676, 'min_samples_leaf': 0.06084844859190755, 'max_features': 0.5722807884690141, 'criterion': 'log_loss', 'class_weight': 'balanced_subsample', 'oob_score': False, 'max_samples': 0.7873242017790835}\n",
      "[2024-12-09 12:12:32,619] - [   OPTUNA   ] - Trial 2. New best score 0.9464257008269529 with parameters {'n_estimators': 215, 'max_depth': 9, 'min_samples_split': 0.1184829137724085, 'min_samples_leaf': 0.009290082543999545, 'max_features': 0.6467903667112945, 'criterion': 'log_loss', 'class_weight': 'balanced', 'oob_score': True, 'max_samples': 0.6873906962470353}\n",
      "[2024-12-09 12:12:35,803] - [   OPTUNA   ] - Trial 3. New best score 0.9495153049028039 with parameters {'n_estimators': 451, 'max_depth': 3, 'min_samples_split': 0.09903538202225404, 'min_samples_leaf': 0.006877704223043679, 'max_features': 0.9183883618709039, 'criterion': 'entropy', 'class_weight': 'balanced_subsample', 'oob_score': False, 'max_samples': 0.7773814951275034}\n",
      "[2024-12-09 12:13:05,886] - [   OPTUNA   ] - Trial 11. New best score 0.9577087894641464 with parameters {'n_estimators': 32, 'max_depth': 10, 'min_samples_split': 0.07121824466699872, 'min_samples_leaf': 0.004689401807340943, 'max_features': 0.7134393876140748, 'criterion': 'entropy', 'class_weight': 'balanced_subsample', 'oob_score': True, 'max_samples': 0.6405508745066752}\n",
      "[2024-12-09 12:13:06,636] - [   OPTUNA   ] - Trial 13. New best score 0.9650705714946699 with parameters {'n_estimators': 36, 'max_depth': 7, 'min_samples_split': 0.054273833433723856, 'min_samples_leaf': 0.0003893728893889538, 'max_features': 0.8460708041987088, 'criterion': 'entropy', 'class_weight': 'balanced_subsample', 'oob_score': False, 'max_samples': 0.36629114865941276}\n",
      "[2024-12-09 12:13:15,948] - [   OPTUNA   ] - Trial 18. New best score 0.9798347397517162 with parameters {'n_estimators': 736, 'max_depth': 8, 'min_samples_split': 0.020097467198428025, 'min_samples_leaf': 7.804930399116401e-05, 'max_features': 0.6982270461963013, 'criterion': 'entropy', 'class_weight': 'balanced_subsample', 'oob_score': False, 'max_samples': 0.5724800915555452}\n",
      "[2024-12-09 12:13:29,021] - [   OPTUNA   ] - 22 trials completed\n",
      "[2024-12-09 12:13:29,022] - [BEST PARAMS ] - {'n_estimators': 736, 'criterion': 'entropy', 'max_depth': 8, 'min_samples_split': 0.020097467198428025, 'min_samples_leaf': 7.804930399116401e-05, 'max_features': 0.6982270461963013, 'bootstrap': True, 'oob_score': False, 'max_samples': 0.5724800915555452, 'class_weight': 'balanced_subsample', 'n_jobs': 5, 'random_state': 42, 'verbose': 0, 'time_series': False}\n",
      "[2024-12-09 12:13:29,022] - [    END     ] - Tuning ExtraTreesClassification\n",
      "[2024-12-09 12:13:29,023] - [   START    ] - Fitting ExtraTreesClassification\n",
      "[2024-12-09 12:13:29,026] - [    FIT     ] - ExtraTreesClassification fold 0\n",
      "[2024-12-09 12:13:31,896] - [    FIT     ] - ExtraTreesClassification fold 1\n",
      "[2024-12-09 12:13:34,761] - [    FIT     ] - ExtraTreesClassification fold 2\n",
      "[2024-12-09 12:13:37,621] - [    FIT     ] - ExtraTreesClassification fold 3\n",
      "[2024-12-09 12:13:40,501] - [    FIT     ] - ExtraTreesClassification fold 4\n",
      "[2024-12-09 12:13:43,355] - [    END     ] - Fitting ExtraTreesClassification\n",
      "[2024-12-09 12:13:44,271] - [   SCORE    ] - Train: 0.9813554405559168\n",
      "[2024-12-09 12:13:44,275] - [   SCORE    ] - OOF: 0.9798198250051346\n",
      "[2024-12-09 12:13:45,120] - [   SCORE    ] - Test: 0.9811779186499044\n",
      "[2024-12-09 12:13:45,121] - [   SCORE    ] - Overfit: 0.02 %\n",
      "[2024-12-09 12:13:45,121] - [    END     ] - Working with ExtraTreesClassification\n",
      "[2024-12-09 12:13:45,122] - [BEST  MODEL ] - RandomForestClassification. Best score: 0.9825429349985924 \n",
      "\n",
      "[2024-12-09 12:13:45,122] - [   MODEL    ] - 4 out of 10. CatBoostClassification\n",
      "[2024-12-09 12:13:45,122] - [   START    ] - Working with CatBoostClassification\n",
      "[2024-12-09 12:13:45,123] - [   START    ] - Tuning CatBoostClassification\n",
      "[2024-12-09 12:14:07,668] - [   OPTUNA   ] - Trial 0. New best score 0.990382740677339 with parameters {'boosting_type': 'Plain', 'depth': 6, 'l2_leaf_reg': 190.14286128198324, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 222, 'rsm': 0.7606690070459252, 'subsample': 0.8248435466776274, 'model_size_reg': 4.116898859160489, 'auto_class_weights': None, 'iterations': 1641}\n",
      "[2024-12-09 12:14:56,180] - [   OPTUNA   ] - 3 trials completed\n",
      "[2024-12-09 12:14:56,181] - [BEST PARAMS ] - {'boosting_type': 'Plain', 'max_leaves': None, 'grow_policy': 'SymmetricTree', 'depth': 6, 'l2_leaf_reg': 190.14286128198324, 'model_size_reg': 4.116898859160489, 'bootstrap_type': 'Bernoulli', 'rsm': 0.7606690070459252, 'subsample': 0.8248435466776274, 'min_data_in_leaf': 222, 'auto_class_weights': None, 'iterations': 1641, 'one_hot_max_size': 10, 'learning_rate': 0.03, 'random_state': 42, 'thread_count': 5, 'verbose': False, 'allow_writing_files': False, 'od_type': 'Iter', 'od_wait': 100, 'task_type': None, 'od_pval': 0, 'eval_metric': 'AUC', 'time_series': False}\n",
      "[2024-12-09 12:14:56,182] - [    END     ] - Tuning CatBoostClassification\n",
      "[2024-12-09 12:14:56,182] - [   START    ] - Fitting CatBoostClassification\n",
      "[2024-12-09 12:14:56,185] - [    FIT     ] - CatBoostClassification fold 0\n",
      "[2024-12-09 12:15:00,509] - [    FIT     ] - CatBoostClassification fold 1\n",
      "[2024-12-09 12:15:04,751] - [    FIT     ] - CatBoostClassification fold 2\n",
      "[2024-12-09 12:15:08,657] - [    FIT     ] - CatBoostClassification fold 3\n",
      "[2024-12-09 12:15:12,581] - [    FIT     ] - CatBoostClassification fold 4\n",
      "[2024-12-09 12:15:16,651] - [    END     ] - Fitting CatBoostClassification\n",
      "[2024-12-09 12:15:16,782] - [   SCORE    ] - Train: 0.9943163102484677\n",
      "[2024-12-09 12:15:16,787] - [   SCORE    ] - OOF: 0.9903523104337174\n",
      "[2024-12-09 12:15:16,825] - [   SCORE    ] - Test: 0.9898660495125885\n",
      "[2024-12-09 12:15:16,826] - [   SCORE    ] - Overfit: 0.45 %\n",
      "[2024-12-09 12:15:16,827] - [    END     ] - Working with CatBoostClassification\n",
      "[2024-12-09 12:15:16,827] - [  NEW BEST  ] - CatBoostClassification. Best score: 0.9898660495125885 \n",
      "\n",
      "[2024-12-09 12:15:16,828] - [   MODEL    ] - 5 out of 10. XGBClassification\n",
      "[2024-12-09 12:15:16,829] - [   START    ] - Working with XGBClassification\n",
      "[2024-12-09 12:15:16,829] - [   START    ] - Tuning XGBClassification\n",
      "[2024-12-09 12:15:17,283] - [   OPTUNA   ] - Trial 0. New best score 0.9549575536218693 with parameters {'max_depth': 6, 'grow_policy': 'depthwise', 'max_leaves': 311, 'gamma': 3.1203728088487304, 'subsample': 0.2403950683025824, 'colsample_bytree': 0.15227525095137953, 'colsample_bylevel': 0.8795585311974417, 'reg_lambda': 6.011150117432088, 'reg_alpha': 7.080725777960454, 'min_child_weight': 0, 'class_weight': None, 'n_estimators': 41}\n",
      "[2024-12-09 12:15:18,951] - [   OPTUNA   ] - Trial 1. New best score 0.9550447467520797 with parameters {'max_depth': 4, 'grow_policy': 'lossguide', 'max_leaves': 163, 'gamma': 10.495128632644757, 'subsample': 0.48875051677790415, 'colsample_bytree': 0.36210622617823773, 'colsample_bylevel': 0.6506676052501416, 'reg_lambda': 1.3949386065204183, 'reg_alpha': 2.9214464853521815, 'min_child_weight': 7, 'class_weight': 'balanced', 'n_estimators': 580}\n",
      "[2024-12-09 12:15:21,001] - [   OPTUNA   ] - Trial 3. New best score 0.9705975553269793 with parameters {'max_depth': 8, 'grow_policy': 'lossguide', 'max_leaves': 27, 'gamma': 18.186408041575643, 'subsample': 0.3329019834400152, 'colsample_bytree': 0.6962700559185838, 'colsample_bylevel': 0.3805399684804699, 'reg_lambda': 5.200680211778108, 'reg_alpha': 5.4671027934327965, 'min_child_weight': 3, 'class_weight': None, 'n_estimators': 500}\n",
      "[2024-12-09 12:15:24,203] - [   OPTUNA   ] - Trial 5. New best score 0.9710234516802989 with parameters {'max_depth': 9, 'grow_policy': 'lossguide', 'max_leaves': 47, 'gamma': 19.737738732010346, 'subsample': 0.7950202923669917, 'colsample_bytree': 0.2788441133807552, 'colsample_bylevel': 0.10496990541124217, 'reg_lambda': 8.154614284548341, 'reg_alpha': 7.068573438476172, 'min_child_weight': 15, 'class_weight': None, 'n_estimators': 990}\n",
      "[2024-12-09 12:15:29,080] - [   OPTUNA   ] - Trial 7. New best score 0.9770583280429815 with parameters {'max_depth': 12, 'grow_policy': 'depthwise', 'max_leaves': 397, 'gamma': 9.875911927287815, 'subsample': 0.5704595464437947, 'colsample_bytree': 0.4847869165226947, 'colsample_bylevel': 0.12287721406968567, 'reg_lambda': 1.0789142699330445, 'reg_alpha': 0.3142918568673425, 'min_child_weight': 13, 'class_weight': 'balanced', 'n_estimators': 1303}\n",
      "[2024-12-09 12:15:32,663] - [   OPTUNA   ] - Trial 10. New best score 0.9844831804293002 with parameters {'max_depth': 12, 'grow_policy': 'depthwise', 'max_leaves': 195, 'gamma': 13.425377296354338, 'subsample': 0.7436526509771155, 'colsample_bytree': 0.9168983157542658, 'colsample_bylevel': 0.6466974055799068, 'reg_lambda': 0.11062173712008272, 'reg_alpha': 0.3432449879508877, 'min_child_weight': 11, 'class_weight': 'balanced', 'n_estimators': 262}\n",
      "[2024-12-09 12:15:35,112] - [   OPTUNA   ] - Trial 12. New best score 0.9850954064371973 with parameters {'max_depth': 12, 'grow_policy': 'depthwise', 'max_leaves': 184, 'gamma': 14.430294063976282, 'subsample': 0.8133778989170452, 'colsample_bytree': 0.996414878572692, 'colsample_bylevel': 0.6859142228544352, 'reg_lambda': 0.029518907931165836, 'reg_alpha': 0.018424983032520194, 'min_child_weight': 9, 'class_weight': 'balanced', 'n_estimators': 202}\n",
      "[2024-12-09 12:16:05,711] - [   OPTUNA   ] - Trial 34. New best score 0.9875941169635649 with parameters {'max_depth': 12, 'grow_policy': 'lossguide', 'max_leaves': 182, 'gamma': 1.7870717556872329, 'subsample': 0.6332492623229783, 'colsample_bytree': 0.8500721420709655, 'colsample_bylevel': 0.9190803400954554, 'reg_lambda': 2.1508775275660934, 'reg_alpha': 2.127715422478941, 'min_child_weight': 10, 'class_weight': 'balanced', 'n_estimators': 442}\n",
      "[2024-12-09 12:16:18,858] - [   OPTUNA   ] - 38 trials completed\n",
      "[2024-12-09 12:16:18,859] - [BEST PARAMS ] - {'max_depth': 12, 'max_leaves': 182, 'grow_policy': 'lossguide', 'gamma': 1.7870717556872329, 'min_child_weight': 10, 'subsample': 0.6332492623229783, 'colsample_bytree': 0.8500721420709655, 'colsample_bylevel': 0.9190803400954554, 'reg_lambda': 2.1508775275660934, 'reg_alpha': 2.127715422478941, 'class_weight': 'balanced', 'n_estimators': 442, 'learning_rate': 0.03, 'verbosity': 0, 'early_stopping_rounds': 100, 'enable_categorical': True, 'max_cat_to_onehot': 5, 'n_jobs': 5, 'random_state': 42, 'device': 'cpu', 'eval_metric': 'auc', 'time_series': False}\n",
      "[2024-12-09 12:16:18,859] - [    END     ] - Tuning XGBClassification\n",
      "[2024-12-09 12:16:18,860] - [   START    ] - Fitting XGBClassification\n",
      "[2024-12-09 12:16:18,869] - [    FIT     ] - XGBClassification fold 0\n",
      "[2024-12-09 12:16:19,315] - [    FIT     ] - XGBClassification fold 1\n",
      "[2024-12-09 12:16:19,681] - [    FIT     ] - XGBClassification fold 2\n",
      "[2024-12-09 12:16:20,054] - [    FIT     ] - XGBClassification fold 3\n",
      "[2024-12-09 12:16:20,419] - [    FIT     ] - XGBClassification fold 4\n",
      "[2024-12-09 12:16:20,782] - [    END     ] - Fitting XGBClassification\n",
      "[2024-12-09 12:16:20,935] - [   SCORE    ] - Train: 0.9895381902416244\n",
      "[2024-12-09 12:16:20,941] - [   SCORE    ] - OOF: 0.9875583503097881\n",
      "[2024-12-09 12:16:20,999] - [   SCORE    ] - Test: 0.9882581151390782\n",
      "[2024-12-09 12:16:20,999] - [   SCORE    ] - Overfit: 0.13 %\n",
      "[2024-12-09 12:16:21,000] - [    END     ] - Working with XGBClassification\n",
      "[2024-12-09 12:16:21,000] - [BEST  MODEL ] - CatBoostClassification. Best score: 0.9898660495125885 \n",
      "\n",
      "[2024-12-09 12:16:21,001] - [   MODEL    ] - 6 out of 10. LightGBMClassification\n",
      "[2024-12-09 12:16:21,001] - [   START    ] - Working with LightGBMClassification\n",
      "[2024-12-09 12:16:21,002] - [   START    ] - Tuning LightGBMClassification\n",
      "[2024-12-09 12:16:21,695] - [   OPTUNA   ] - Trial 0. New best score 0.9806563072969247 with parameters {'max_depth': 6, 'num_leaves': 488, 'min_data_in_leaf': 188, 'bagging_fraction': 0.7993292420985183, 'bagging_freq': 0, 'feature_fraction': 0.49359671220172163, 'lambda_l1': 0.5808361216819946, 'lambda_l2': 8.661761457749352, 'min_gain_to_split': 12.022300234864176, 'is_unbalance': True, 'num_iterations': 205}\n",
      "[2024-12-09 12:16:22,405] - [   OPTUNA   ] - Trial 1. New best score 0.9834973421818637 with parameters {'max_depth': 16, 'num_leaves': 428, 'min_data_in_leaf': 55, 'bagging_fraction': 0.5909124836035503, 'bagging_freq': 0, 'feature_fraction': 0.5825453457757226, 'lambda_l1': 5.247564316322379, 'lambda_l2': 4.319450186421157, 'min_gain_to_split': 5.824582803960839, 'is_unbalance': True, 'num_iterations': 187}\n",
      "[2024-12-09 12:16:30,562] - [   OPTUNA   ] - Trial 12. New best score 0.9838720344091727 with parameters {'max_depth': 11, 'num_leaves': 430, 'min_data_in_leaf': 100, 'bagging_fraction': 0.6372424866412405, 'bagging_freq': 5, 'feature_fraction': 0.9083849912724661, 'lambda_l1': 4.142039029458583, 'lambda_l2': 2.2713901165087846, 'min_gain_to_split': 1.6853644183695988, 'is_unbalance': False, 'num_iterations': 233}\n",
      "[2024-12-09 12:16:31,897] - [   OPTUNA   ] - Trial 13. New best score 0.9862001386323124 with parameters {'max_depth': 10, 'num_leaves': 399, 'min_data_in_leaf': 97, 'bagging_fraction': 0.6193053264920616, 'bagging_freq': 5, 'feature_fraction': 0.9987425185303543, 'lambda_l1': 3.3091284180681475, 'lambda_l2': 2.956878545838243, 'min_gain_to_split': 0.35783721990331774, 'is_unbalance': False, 'num_iterations': 356}\n",
      "[2024-12-09 12:16:33,474] - [   OPTUNA   ] - Trial 14. New best score 0.9870799474922651 with parameters {'max_depth': 9, 'num_leaves': 322, 'min_data_in_leaf': 109, 'bagging_fraction': 0.6999903496918574, 'bagging_freq': 5, 'feature_fraction': 0.9912353152955465, 'lambda_l1': 2.6425101938009625, 'lambda_l2': 2.557685604637157, 'min_gain_to_split': 0.21978378487542294, 'is_unbalance': False, 'num_iterations': 399}\n",
      "[2024-12-09 12:16:36,255] - [   OPTUNA   ] - Trial 15. New best score 0.9884565507261678 with parameters {'max_depth': 8, 'num_leaves': 308, 'min_data_in_leaf': 142, 'bagging_fraction': 0.7082907622168072, 'bagging_freq': 5, 'feature_fraction': 0.9791686150900022, 'lambda_l1': 2.406493421980318, 'lambda_l2': 3.03217920890346, 'min_gain_to_split': 0.05866463645244052, 'is_unbalance': False, 'num_iterations': 698}\n",
      "[2024-12-09 12:17:23,746] - [   OPTUNA   ] - Trial 55. New best score 0.988456931898322 with parameters {'max_depth': 10, 'num_leaves': 262, 'min_data_in_leaf': 130, 'bagging_fraction': 0.7119376637060894, 'bagging_freq': 5, 'feature_fraction': 0.8760233345994594, 'lambda_l1': 1.4884436736330031, 'lambda_l2': 9.206887497976238, 'min_gain_to_split': 0.11967851708034812, 'is_unbalance': False, 'num_iterations': 740}\n",
      "[2024-12-09 12:17:23,756] - [   OPTUNA   ] - 56 trials completed\n",
      "[2024-12-09 12:17:23,757] - [BEST PARAMS ] - {'max_depth': 10, 'num_leaves': 262, 'min_data_in_leaf': 130, 'bagging_fraction': 0.7119376637060894, 'bagging_freq': 5, 'feature_fraction': 0.8760233345994594, 'lambda_l1': 1.4884436736330031, 'lambda_l2': 9.206887497976238, 'min_gain_to_split': 0.11967851708034812, 'is_unbalance': False, 'class_weight': None, 'num_iterations': 740, 'boosting': 'gbdt', 'learning_rate': 0.03, 'early_stopping_round': 100, 'n_jobs': 5, 'random_state': 42, 'verbose': -1, 'eval_metric': 'auc', 'time_series': False}\n",
      "[2024-12-09 12:17:23,757] - [    END     ] - Tuning LightGBMClassification\n",
      "[2024-12-09 12:17:23,758] - [   START    ] - Fitting LightGBMClassification\n",
      "[2024-12-09 12:17:23,761] - [    FIT     ] - LightGBMClassification fold 0\n",
      "[2024-12-09 12:17:24,312] - [    FIT     ] - LightGBMClassification fold 1\n",
      "[2024-12-09 12:17:24,843] - [    FIT     ] - LightGBMClassification fold 2\n",
      "[2024-12-09 12:17:25,364] - [    FIT     ] - LightGBMClassification fold 3\n",
      "[2024-12-09 12:17:25,913] - [    FIT     ] - LightGBMClassification fold 4\n",
      "[2024-12-09 12:17:26,440] - [    END     ] - Fitting LightGBMClassification\n",
      "[2024-12-09 12:17:26,975] - [   SCORE    ] - Train: 0.9910301615807819\n",
      "[2024-12-09 12:17:26,982] - [   SCORE    ] - OOF: 0.9884181793960061\n",
      "[2024-12-09 12:17:27,120] - [   SCORE    ] - Test: 0.9888516888901087\n",
      "[2024-12-09 12:17:27,121] - [   SCORE    ] - Overfit: 0.22 %\n",
      "[2024-12-09 12:17:27,122] - [    END     ] - Working with LightGBMClassification\n",
      "[2024-12-09 12:17:27,122] - [BEST  MODEL ] - CatBoostClassification. Best score: 0.9898660495125885 \n",
      "\n",
      "[2024-12-09 12:17:27,123] - [   MODEL    ] - 7 out of 10. TabularLama\n",
      "[2024-12-09 12:17:27,124] - [   START    ] - Working with TabularLama\n",
      "[2024-12-09 12:17:27,124] - [   START    ] - Fitting TabularLama\n",
      "[2024-12-09 12:17:27,159] - [12:17:27] Stdout logging level is INFO.\n",
      "[2024-12-09 12:17:27,160] - [12:17:27] Copying TaskTimer may affect the parent PipelineTimer, so copy will create new unlimited TaskTimer\n",
      "[2024-12-09 12:17:27,161] - [12:17:27] Task: binary\n",
      "\n",
      "[2024-12-09 12:17:27,161] - [12:17:27] Start automl preset with listed constraints:\n",
      "[2024-12-09 12:17:27,162] - [12:17:27] - time: 120.00 seconds\n",
      "[2024-12-09 12:17:27,163] - [12:17:27] - CPU: 5 cores\n",
      "[2024-12-09 12:17:27,164] - [12:17:27] - memory: 16 GB\n",
      "\n",
      "[2024-12-09 12:17:27,165] - [12:17:27] \u001b[1mTrain data shape: (8000, 11)\u001b[0m\n",
      "\n",
      "[2024-12-09 12:17:27,380] - [12:17:27] Layer \u001b[1m1\u001b[0m train process start. Time left 119.78 secs\n",
      "[2024-12-09 12:17:27,754] - [12:17:27] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "[2024-12-09 12:17:30,511] - [12:17:30] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.9753162760065025\u001b[0m\n",
      "[2024-12-09 12:17:30,511] - [12:17:30] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "[2024-12-09 12:17:30,512] - [12:17:30] Time left 116.65 secs\n",
      "\n",
      "[2024-12-09 12:17:32,975] - [12:17:32] \u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n",
      "[2024-12-09 12:17:33,331] - [12:17:33] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "[2024-12-09 12:17:43,442] - [12:17:43] Time limit exceeded after calculating fold 2\n",
      "\n",
      "[2024-12-09 12:17:43,450] - [12:17:43] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.9900429975906949\u001b[0m\n",
      "[2024-12-09 12:17:43,451] - [12:17:43] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "[2024-12-09 12:17:43,452] - [12:17:43] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 1.00 secs\n",
      "[2024-12-09 12:17:47,826] - [12:17:47] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n",
      "[2024-12-09 12:17:47,826] - [12:17:47] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[2024-12-09 12:17:53,117] - [12:17:53] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.9897161341088154\u001b[0m\n",
      "[2024-12-09 12:17:53,117] - [12:17:53] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[2024-12-09 12:17:53,130] - [12:17:53] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n",
      "[2024-12-09 12:18:00,170] - [12:18:00] Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m0.9895102376170031\u001b[0m\n",
      "[2024-12-09 12:18:00,171] - [12:18:00] \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n",
      "[2024-12-09 12:18:00,171] - [12:18:00] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 36.69 secs\n",
      "[2024-12-09 12:18:39,081] - [12:18:39] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n",
      "[2024-12-09 12:18:39,082] - [12:18:39] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[2024-12-09 12:18:48,578] - [12:18:48] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.9895571217919361\u001b[0m\n",
      "[2024-12-09 12:18:48,579] - [12:18:48] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[2024-12-09 12:18:48,580] - [12:18:48] Time left 38.58 secs\n",
      "\n",
      "[2024-12-09 12:18:48,580] - [12:18:48] Time limit exceeded in one of the tasks. AutoML will blend level 1 models.\n",
      "\n",
      "[2024-12-09 12:18:48,581] - [12:18:48] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[2024-12-09 12:18:48,586] - [12:18:48] Blending: optimization starts with equal weights and score \u001b[1m0.9888426145894024\u001b[0m\n",
      "[2024-12-09 12:18:48,727] - [12:18:48] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.9901032779598192\u001b[0m, weights = \u001b[1m[0.         0.3933402  0.32499623 0.15816733 0.12349623]\u001b[0m\n",
      "[2024-12-09 12:18:48,861] - [12:18:48] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.9901107743455131\u001b[0m, weights = \u001b[1m[0.         0.25526413 0.39896554 0.1941663  0.15160403]\u001b[0m\n",
      "[2024-12-09 12:18:48,995] - [12:18:48] Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.9901107743455131\u001b[0m, weights = \u001b[1m[0.         0.25526413 0.39896554 0.1941663  0.15160403]\u001b[0m\n",
      "[2024-12-09 12:18:48,996] - [12:18:48] Blending: no score update. Terminated\n",
      "\n",
      "[2024-12-09 12:18:48,998] - [12:18:48] \u001b[1mAutoml preset training completed in 81.83 seconds\u001b[0m\n",
      "\n",
      "[2024-12-09 12:18:48,999] - [12:18:48] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.25526 * (3 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) +\n",
      "\t 0.39897 * (5 averaged models Lvl_0_Pipe_1_Mod_1_Tuned_LightGBM) +\n",
      "\t 0.19417 * (5 averaged models Lvl_0_Pipe_1_Mod_2_CatBoost) +\n",
      "\t 0.15160 * (5 averaged models Lvl_0_Pipe_1_Mod_3_Tuned_CatBoost) \n",
      "\n",
      "[2024-12-09 12:18:49,000] - [    END     ] - Fitting TabularLama\n",
      "[2024-12-09 12:18:50,036] - [   SCORE    ] - Train: 0.9958683797305607\n",
      "[2024-12-09 12:18:50,040] - [   SCORE    ] - OOF: 0.9901107743455131\n",
      "[2024-12-09 12:18:50,306] - [   SCORE    ] - Test: 0.9906344429300182\n",
      "[2024-12-09 12:18:50,307] - [   SCORE    ] - Overfit: 0.53 %\n",
      "[2024-12-09 12:18:50,307] - [    END     ] - Working with TabularLama\n",
      "[2024-12-09 12:18:50,308] - [  NEW BEST  ] - TabularLama. Best score: 0.9906344429300182 \n",
      "\n",
      "[2024-12-09 12:18:50,308] - [   MODEL    ] - 8 out of 10. TabularLamaUtilized\n",
      "[2024-12-09 12:18:50,309] - [   START    ] - Working with TabularLamaUtilized\n",
      "[2024-12-09 12:18:50,309] - [   START    ] - Fitting TabularLamaUtilized\n",
      "[2024-12-09 12:18:50,345] - [12:18:50] Start automl \u001b[1mutilizator\u001b[0m with listed constraints:\n",
      "[2024-12-09 12:18:50,346] - [12:18:50] - time: 120.00 seconds\n",
      "[2024-12-09 12:18:50,349] - [12:18:50] - CPU: 5 cores\n",
      "[2024-12-09 12:18:50,350] - [12:18:50] - memory: 16 GB\n",
      "\n",
      "[2024-12-09 12:18:50,351] - [12:18:50] \u001b[1mIf one preset completes earlier, next preset configuration will be started\u001b[0m\n",
      "\n",
      "[2024-12-09 12:18:50,352] - [12:18:50] ==================================================\n",
      "[2024-12-09 12:18:50,353] - [12:18:50] Start 0 automl preset configuration:\n",
      "[2024-12-09 12:18:50,353] - [12:18:50] \u001b[1mconf_0_sel_type_0.yml\u001b[0m, random state: {'reader_params': {'random_state': 42}, 'nn_params': {'random_state': 42}, 'general_params': {'return_all_predictions': False}}\n",
      "[2024-12-09 12:18:50,376] - [12:18:50] Stdout logging level is INFO.\n",
      "[2024-12-09 12:18:50,381] - [12:18:50] Task: binary\n",
      "\n",
      "[2024-12-09 12:18:50,382] - [12:18:50] Start automl preset with listed constraints:\n",
      "[2024-12-09 12:18:50,382] - [12:18:50] - time: 120.00 seconds\n",
      "[2024-12-09 12:18:50,384] - [12:18:50] - CPU: 5 cores\n",
      "[2024-12-09 12:18:50,385] - [12:18:50] - memory: 16 GB\n",
      "\n",
      "[2024-12-09 12:18:50,386] - [12:18:50] \u001b[1mTrain data shape: (8000, 11)\u001b[0m\n",
      "\n",
      "[2024-12-09 12:18:50,580] - [12:18:50] Layer \u001b[1m1\u001b[0m train process start. Time left 119.80 secs\n",
      "[2024-12-09 12:18:50,953] - [12:18:50] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "[2024-12-09 12:18:53,153] - [12:18:53] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.9753162760065025\u001b[0m\n",
      "[2024-12-09 12:18:53,154] - [12:18:53] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "[2024-12-09 12:18:53,154] - [12:18:53] Time left 117.23 secs\n",
      "\n",
      "[2024-12-09 12:18:53,504] - [12:18:53] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "[2024-12-09 12:19:02,589] - [12:19:02] Time limit exceeded after calculating fold 2\n",
      "\n",
      "[2024-12-09 12:19:02,593] - [12:19:02] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.9900429975906949\u001b[0m\n",
      "[2024-12-09 12:19:02,593] - [12:19:02] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "[2024-12-09 12:19:02,593] - [12:19:02] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 1.00 secs\n",
      "[2024-12-09 12:19:05,632] - [12:19:05] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n",
      "[2024-12-09 12:19:05,633] - [12:19:05] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[2024-12-09 12:19:09,941] - [12:19:09] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.9897161341088154\u001b[0m\n",
      "[2024-12-09 12:19:09,941] - [12:19:09] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[2024-12-09 12:19:09,948] - [12:19:09] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n",
      "[2024-12-09 12:19:16,819] - [12:19:16] Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m0.9895102376170031\u001b[0m\n",
      "[2024-12-09 12:19:16,819] - [12:19:16] \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n",
      "[2024-12-09 12:19:16,820] - [12:19:16] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 53.80 secs\n",
      "[2024-12-09 12:20:11,344] - [12:20:11] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n",
      "[2024-12-09 12:20:11,346] - [12:20:11] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[2024-12-09 12:20:21,049] - [12:20:21] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.9895571217919361\u001b[0m\n",
      "[2024-12-09 12:20:21,049] - [12:20:21] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[2024-12-09 12:20:21,050] - [12:20:21] Time left 29.33 secs\n",
      "\n",
      "[2024-12-09 12:20:21,050] - [12:20:21] Time limit exceeded in one of the tasks. AutoML will blend level 1 models.\n",
      "\n",
      "[2024-12-09 12:20:21,051] - [12:20:21] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[2024-12-09 12:20:21,057] - [12:20:21] Blending: optimization starts with equal weights and score \u001b[1m0.9888426145894024\u001b[0m\n",
      "[2024-12-09 12:20:21,239] - [12:20:21] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.9901032779598192\u001b[0m, weights = \u001b[1m[0.         0.3933402  0.32499623 0.15816733 0.12349623]\u001b[0m\n",
      "[2024-12-09 12:20:21,387] - [12:20:21] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.9901107743455131\u001b[0m, weights = \u001b[1m[0.         0.25526413 0.39896554 0.1941663  0.15160403]\u001b[0m\n",
      "[2024-12-09 12:20:21,529] - [12:20:21] Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.9901107743455131\u001b[0m, weights = \u001b[1m[0.         0.25526413 0.39896554 0.1941663  0.15160403]\u001b[0m\n",
      "[2024-12-09 12:20:21,530] - [12:20:21] Blending: no score update. Terminated\n",
      "\n",
      "[2024-12-09 12:20:21,532] - [12:20:21] \u001b[1mAutoml preset training completed in 91.15 seconds\u001b[0m\n",
      "\n",
      "[2024-12-09 12:20:21,533] - [12:20:21] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.25526 * (3 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) +\n",
      "\t 0.39897 * (5 averaged models Lvl_0_Pipe_1_Mod_1_Tuned_LightGBM) +\n",
      "\t 0.19417 * (5 averaged models Lvl_0_Pipe_1_Mod_2_CatBoost) +\n",
      "\t 0.15160 * (5 averaged models Lvl_0_Pipe_1_Mod_3_Tuned_CatBoost) \n",
      "\n",
      "[2024-12-09 12:20:21,533] - [12:20:21] ==================================================\n",
      "[2024-12-09 12:20:21,534] - [    END     ] - Fitting TabularLamaUtilized\n",
      "[2024-12-09 12:20:22,398] - [   SCORE    ] - Train: 0.9958683797305607\n",
      "[2024-12-09 12:20:22,403] - [   SCORE    ] - OOF: 0.9901107743455131\n",
      "[2024-12-09 12:20:22,677] - [   SCORE    ] - Test: 0.9906344429300182\n",
      "[2024-12-09 12:20:22,678] - [   SCORE    ] - Overfit: 0.53 %\n",
      "[2024-12-09 12:20:22,678] - [    END     ] - Working with TabularLamaUtilized\n",
      "[2024-12-09 12:20:22,678] - [BEST  MODEL ] - TabularLama. Best score: 0.9906344429300182 \n",
      "\n",
      "[2024-12-09 12:20:22,679] - [   MODEL    ] - 9 out of 10. Stacker\n",
      "[2024-12-09 12:20:22,682] - [   START    ] - Working with Stacker\n",
      "[2024-12-09 12:20:22,683] - [   START    ] - Tuning Stacker\n",
      "[2024-12-09 12:20:23,296] - [   OPTUNA   ] - Trial 0. New best score 0.9896146152584866 with parameters {'max_depth': 6, 'num_leaves': 488, 'min_data_in_leaf': 188, 'bagging_fraction': 0.7993292420985183, 'bagging_freq': 0, 'feature_fraction': 0.49359671220172163, 'lambda_l1': 0.5808361216819946, 'lambda_l2': 8.661761457749352, 'min_gain_to_split': 12.022300234864176, 'is_unbalance': True, 'num_iterations': 136}\n",
      "[2024-12-09 12:20:24,397] - [   OPTUNA   ] - Trial 2. New best score 0.9897055248171978 with parameters {'max_depth': 5, 'num_leaves': 194, 'min_data_in_leaf': 117, 'bagging_fraction': 0.8925879806965068, 'bagging_freq': 0, 'feature_fraction': 0.708540663048167, 'lambda_l1': 5.924145688620425, 'lambda_l2': 0.46450412719997725, 'min_gain_to_split': 12.150897038028766, 'is_unbalance': True, 'num_iterations': 115}\n",
      "[2024-12-09 12:20:25,095] - [   OPTUNA   ] - Trial 3. New best score 0.989800595505256 with parameters {'max_depth': 16, 'num_leaves': 495, 'min_data_in_leaf': 207, 'bagging_fraction': 0.6523068845866853, 'bagging_freq': 0, 'feature_fraction': 0.8105398159072941, 'lambda_l1': 4.4015249373960135, 'lambda_l2': 1.2203823484477883, 'min_gain_to_split': 9.903538202225404, 'is_unbalance': False, 'num_iterations': 111}\n",
      "[2024-12-09 12:20:36,118] - [   OPTUNA   ] - Trial 21. New best score 0.9898564689901523 with parameters {'max_depth': 1, 'num_leaves': 176, 'min_data_in_leaf': 110, 'bagging_fraction': 0.8539591619601078, 'bagging_freq': 0, 'feature_fraction': 0.673536676839942, 'lambda_l1': 5.767248905348699, 'lambda_l2': 0.28737218602766035, 'min_gain_to_split': 11.845413816617286, 'is_unbalance': True, 'num_iterations': 198}\n",
      "[2024-12-09 12:21:00,783] - [   OPTUNA   ] - Trial 59. New best score 0.9898906156622748 with parameters {'max_depth': 11, 'num_leaves': 259, 'min_data_in_leaf': 112, 'bagging_fraction': 0.9137394890304309, 'bagging_freq': 0, 'feature_fraction': 0.647475572480905, 'lambda_l1': 3.1181549857394044, 'lambda_l2': 1.7358930524305678, 'min_gain_to_split': 4.096843306115986, 'is_unbalance': True, 'num_iterations': 144}\n",
      "[2024-12-09 12:21:02,256] - [   OPTUNA   ] - Trial 61. New best score 0.990074499462198 with parameters {'max_depth': 11, 'num_leaves': 330, 'min_data_in_leaf': 111, 'bagging_fraction': 0.9189681970111063, 'bagging_freq': 0, 'feature_fraction': 0.6618126856805862, 'lambda_l1': 3.425276371323765, 'lambda_l2': 1.6832479745403488, 'min_gain_to_split': 4.121976936992778, 'is_unbalance': True, 'num_iterations': 165}\n",
      "[2024-12-09 12:21:02,872] - [   OPTUNA   ] - Trial 62. New best score 0.9900855534546616 with parameters {'max_depth': 11, 'num_leaves': 381, 'min_data_in_leaf': 108, 'bagging_fraction': 0.9140774575323629, 'bagging_freq': 0, 'feature_fraction': 0.6401036803580498, 'lambda_l1': 3.268145648069943, 'lambda_l2': 1.453992449888162, 'min_gain_to_split': 4.06984590920416, 'is_unbalance': True, 'num_iterations': 159}\n",
      "[2024-12-09 12:21:03,491] - [   OPTUNA   ] - Trial 63. New best score 0.9901638525679473 with parameters {'max_depth': 11, 'num_leaves': 366, 'min_data_in_leaf': 111, 'bagging_fraction': 0.9158881387650052, 'bagging_freq': 0, 'feature_fraction': 0.6457070262553888, 'lambda_l1': 3.113756142771791, 'lambda_l2': 1.6429061386114836, 'min_gain_to_split': 3.920684097366572, 'is_unbalance': True, 'num_iterations': 158}\n",
      "[2024-12-09 12:21:08,791] - [   OPTUNA   ] - Trial 71. New best score 0.9901700466154485 with parameters {'max_depth': 10, 'num_leaves': 360, 'min_data_in_leaf': 98, 'bagging_fraction': 0.9091745618575022, 'bagging_freq': 0, 'feature_fraction': 0.6550045985281799, 'lambda_l1': 3.976109740613395, 'lambda_l2': 1.6136183992947608, 'min_gain_to_split': 3.340294108212133, 'is_unbalance': True, 'num_iterations': 160}\n",
      "[2024-12-09 12:21:23,619] - [   OPTUNA   ] - 92 trials completed\n",
      "[2024-12-09 12:21:23,621] - [BEST PARAMS ] - {'max_depth': 10, 'num_leaves': 360, 'min_data_in_leaf': 98, 'bagging_fraction': 0.9091745618575022, 'bagging_freq': 0, 'feature_fraction': 0.6550045985281799, 'lambda_l1': 3.976109740613395, 'lambda_l2': 1.6136183992947608, 'min_gain_to_split': 3.340294108212133, 'is_unbalance': True, 'class_weight': None, 'num_iterations': 160, 'boosting': 'gbdt', 'learning_rate': 0.03, 'early_stopping_round': 100, 'n_jobs': 5, 'random_state': 42, 'verbose': -1, 'eval_metric': 'auc', 'time_series': False}\n",
      "[2024-12-09 12:21:23,622] - [    END     ] - Tuning Stacker\n",
      "[2024-12-09 12:21:23,624] - [   START    ] - Fitting Stacker\n",
      "[2024-12-09 12:21:23,628] - [    FIT     ] - Stacker fold 0\n",
      "[2024-12-09 12:21:23,774] - [    FIT     ] - Stacker fold 1\n",
      "[2024-12-09 12:21:23,911] - [    FIT     ] - Stacker fold 2\n",
      "[2024-12-09 12:21:24,057] - [    FIT     ] - Stacker fold 3\n",
      "[2024-12-09 12:21:24,207] - [    FIT     ] - Stacker fold 4\n",
      "[2024-12-09 12:21:24,354] - [    END     ] - Fitting Stacker\n",
      "[2024-12-09 12:21:24,423] - [   SCORE    ] - Train: 0.9915752377608955\n",
      "[2024-12-09 12:21:24,433] - [   SCORE    ] - OOF: 0.9895224986546212\n",
      "[2024-12-09 12:21:24,467] - [   SCORE    ] - Test: 0.9906720494861624\n",
      "[2024-12-09 12:21:24,468] - [   SCORE    ] - Overfit: 0.09 %\n",
      "[2024-12-09 12:21:24,470] - [    END     ] - Working with Stacker\n",
      "[2024-12-09 12:21:24,471] - [  NEW BEST  ] - Stacker. Best score: 0.9906720494861624 \n",
      "\n",
      "[2024-12-09 12:21:24,472] - [   MODEL    ] - 10 out of 10. Blender\n",
      "[2024-12-09 12:21:24,473] - [   START    ] - Working with Blender\n",
      "[2024-12-09 12:21:24,476] - [   START    ] - Tuning Blender\n",
      "[2024-12-09 12:21:24,720] - [   OPTUNA   ] - Best score 0.9903893476613405 with weights [0.0, 0.0, 0.0, 0.1938430136364032, 0.0, 0.10264152284090286, 0.703515463522694, 0.0]\n",
      "[2024-12-09 12:21:24,884] - [   OPTUNA   ] - Best score 0.9904461423122753 with weights [0.0, 0.0, 0.0, 0.26507322415257806, 0.0, 0.0, 0.7349267758474219, 0.0]\n",
      "[2024-12-09 12:21:25,023] - [   OPTUNA   ] - Best score 0.9904461423122753 with weights [0.0, 0.0, 0.0, 0.26507322415257806, 0.0, 0.0, 0.7349267758474219, 0.0]\n",
      "[2024-12-09 12:21:25,023] - [BEST PARAMS ] - {'weights': [0.0, 0.0, 0.0, 0.26507322415257806, 0.0, 0.0, 0.7349267758474219, 0.0], 'n': 8, 'random_state': 42, 'n_iters': 10, 'n_inner_iters': 3}\n",
      "[2024-12-09 12:21:25,024] - [    END     ] - Tuning Blender\n",
      "[2024-12-09 12:21:25,033] - [   SCORE    ] - Train: 0.9904461423122753\n",
      "[2024-12-09 12:21:25,039] - [   SCORE    ] - OOF: 0.9904461423122753\n",
      "[2024-12-09 12:21:25,043] - [   SCORE    ] - Test: 0.9906293609629719\n",
      "[2024-12-09 12:21:25,044] - [   SCORE    ] - Overfit: 0.02 %\n",
      "[2024-12-09 12:21:25,045] - [    END     ] - Working with Blender\n",
      "[2024-12-09 12:21:25,045] - [BEST  MODEL ] - Stacker. Best score: 0.9906720494861624 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<src.automl.model.main.AutoML at 0xfffe9efa12b0>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    X_test, y_test,\n",
    "    save_test=False,\n",
    "    save_oof=False,\n",
    "    save_models=False,\n",
    "    save_params=False,\n",
    "    categorical_features=cat_features\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9f55b811-8215-4774-b9f9-86c95a1e3ab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.98294761, 0.01705239],\n",
       "       [0.71917787, 0.28082213],\n",
       "       [0.98286915, 0.01713085],\n",
       "       ...,\n",
       "       [0.98294761, 0.01705239],\n",
       "       [0.98294761, 0.01705239],\n",
       "       [0.98294761, 0.01705239]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31de6fc4-e76b-4614-9d16-799d769e7183",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
