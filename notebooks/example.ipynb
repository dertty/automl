{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# libs\n",
    "Аналоги:  \n",
    "- https://mlbox.readthedocs.io/en/latest/  \n",
    "- https://lightautoml.readthedocs.io/  \n",
    "- https://automl.github.io/auto-sklearn/master/  \n",
    "\n",
    "Tюнинг:\n",
    "- https://optuna.org/\n",
    "- https://hyperopt.github.io/hyperopt/\n",
    "- https://docs.ray.io/en/latest/tune/index.html \n",
    "- https://oss-vizier.readthedocs.io/en/latest/ \n",
    "\n",
    "Работа с фичами:\n",
    "- https://scikit-learn.org/1.5/modules/feature_selection.html\n",
    "- https://feature-engine.trainindata.com/en/1.7.x/api_doc/selection/index.html\n",
    "- https://github.com/AutoViML/featurewiz\n",
    "- https://github.com/scikit-learn-contrib/boruta_py\n",
    "\n",
    "Прочее:\n",
    "- https://unit8co.github.io/darts/\n",
    "- https://epistasislab.github.io/tpot/  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# datasets\n",
    "Сберовский датасет:\n",
    "- https://huggingface.co/datasets/ai-lab/MBD (14,6 GB, основной датасет)\n",
    "- https://huggingface.co/datasets/ai-lab/MBD-mini (3,38 GB, уменьшенная версия, 10% клиентов из основного датасета)  \n",
    "\n",
    "Kaggle datasets:\n",
    "- https://www.kaggle.com/datasets/yasserh/titanic-dataset\n",
    "- https://www.kaggle.com/datasets/rabieelkharoua/predict-liver-disease-1700-records-dataset\n",
    "- https://www.kaggle.com/datasets/devzohaib/eligibility-prediction-for-loan\n",
    "- https://www.kaggle.com/datasets/deepcontractor/smoke-detection-dataset\n",
    "- https://www.kaggle.com/datasets/stealthtechnologies/employee-attrition-dataset\n",
    "- https://www.kaggle.com/datasets/rabieelkharoua/cancer-prediction-dataset\n",
    "- https://www.kaggle.com/datasets/yasserh/heart-disease-dataset\n",
    "- https://www.kaggle.com/datasets/rabieelkharoua/predict-online-course-engagement-dataset\n",
    "- https://www.kaggle.com/datasets/rabieelkharoua/predicting-hiring-decisions-in-recruitment-data\n",
    "- https://www.kaggle.com/datasets/barun2104/telecom-churn\n",
    "- https://www.kaggle.com/datasets/rabieelkharoua/predicting-manufacturing-defects-dataset\n",
    "- https://www.kaggle.com/datasets/rabieelkharoua/predict-customer-purchase-behavior-dataset\n",
    "- https://www.kaggle.com/datasets/teejmahal20/airline-passenger-satisfaction\n",
    "- https://www.kaggle.com/datasets/dhanushnarayananr/credit-card-fraud\n",
    "- https://www.kaggle.com/datasets/rameshmehta/credit-risk-analysis\n",
    "- https://www.kaggle.com/datasets/marcpaulo/titanic-huge-dataset-1m-passengers\n",
    "- https://www.kaggle.com/datasets/manishtripathi86/fedex-data\n",
    "- https://www.kaggle.com/datasets/ban7002/fraud-challenge-data\n",
    "- https://www.kaggle.com/datasets/ulrikthygepedersen/kickstarter-projects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "\n",
    "import kaggle\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "kaggle.api.authenticate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\n",
    "    {\n",
    "        'link': 'https://www.kaggle.com/datasets/yasserh/titanic-dataset', \n",
    "        'target': 'Survived',\n",
    "        'id_cols': ['PassengerId',],\n",
    "    },\n",
    "    {\n",
    "        'link': 'https://www.kaggle.com/datasets/rabieelkharoua/predict-liver-disease-1700-records-dataset', \n",
    "        'target': 'Diagnosis',\n",
    "    },\n",
    "    {\n",
    "        'link': 'https://www.kaggle.com/datasets/devzohaib/eligibility-prediction-for-loan', \n",
    "        'target': 'Loan_Status',\n",
    "        'id_cols': ['Loan_ID',],\n",
    "    },\n",
    "    {\n",
    "        'link': 'https://www.kaggle.com/datasets/deepcontractor/smoke-detection-dataset', \n",
    "        'target': 'Fire Alarm',\n",
    "        'id_cols': ['index',],\n",
    "    },\n",
    "    {\n",
    "        'link': 'https://www.kaggle.com/datasets/stealthtechnologies/employee-attrition-dataset', \n",
    "        'target': 'Attrition',\n",
    "        'id_cols': ['Employee ID',],\n",
    "    },\n",
    "    {\n",
    "        'link': 'https://www.kaggle.com/datasets/rabieelkharoua/cancer-prediction-dataset', \n",
    "        'target': 'Diagnosis',\n",
    "    },\n",
    "    {\n",
    "        'link': 'https://www.kaggle.com/datasets/yasserh/heart-disease-dataset', \n",
    "        'target': 'target',\n",
    "    },\n",
    "    {\n",
    "        'link': 'https://www.kaggle.com/datasets/rabieelkharoua/predict-online-course-engagement-dataset', \n",
    "        'target': 'CourseCompletion',\n",
    "        'id_cols': ['UserID',],\n",
    "    },\n",
    "    {\n",
    "        'link': 'https://www.kaggle.com/datasets/rabieelkharoua/predicting-hiring-decisions-in-recruitment-data', \n",
    "        'target': 'HiringDecision',\n",
    "    },\n",
    "    {\n",
    "        'link': 'https://www.kaggle.com/datasets/barun2104/telecom-churn', \n",
    "        'target': 'Churn',\n",
    "    },\n",
    "    {\n",
    "        'link': 'https://www.kaggle.com/datasets/rabieelkharoua/predicting-manufacturing-defects-dataset', \n",
    "        'target': 'DefectStatus',\n",
    "    },\n",
    "    {\n",
    "        'link': 'https://www.kaggle.com/datasets/rabieelkharoua/predict-customer-purchase-behavior-dataset',\n",
    "        'target': 'PurchaseStatus',\n",
    "    },\n",
    "    {\n",
    "        'link': 'https://www.kaggle.com/datasets/teejmahal20/airline-passenger-satisfaction', \n",
    "        'target': 'Satisfaction',\n",
    "    },\n",
    "    {\n",
    "        'link': 'https://www.kaggle.com/datasets/dhanushnarayananr/credit-card-fraud', \n",
    "        'target': 'fraud',\n",
    "    },\n",
    "    {\n",
    "        'link': 'https://www.kaggle.com/datasets/rameshmehta/credit-risk-analysis', \n",
    "        'target': 'default_ind',\n",
    "        'id_cols': ['id', 'member_id',],\n",
    "        'time_col': 'issue_d',\n",
    "    },\n",
    "    {\n",
    "        'link': 'https://www.kaggle.com/datasets/marcpaulo/titanic-huge-dataset-1m-passengers', \n",
    "        'target': 'Survived',\n",
    "        'id_cols': ['PassengerId',],\n",
    "    },\n",
    "    # {\n",
    "    #     'link': 'https://www.kaggle.com/datasets/manishtripathi86/fedex-data', \n",
    "    #     'target': 'Delivery_Status',\n",
    "    #     'time_col': 'Year',\n",
    "    # },\n",
    "    {\n",
    "        'link': 'https://www.kaggle.com/datasets/ban7002/fraud-challenge-data', \n",
    "        'target': 'EVENT_LABEL',\n",
    "        'time_col': 'EVENT_TIMESTAMP',\n",
    "    },\n",
    "    {\n",
    "        'link': 'https://www.kaggle.com/datasets/ulrikthygepedersen/kickstarter-projects', \n",
    "        'target': 'State',\n",
    "        'id_cols': ['ID',],\n",
    "        'time_col': 'Launched',\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in datasets:\n",
    "    dataset_name = dataset['link'].replace('https://www.kaggle.com/datasets/', '')\n",
    "    dataset_path = Path(f'./datasets/{dataset_name}')\n",
    "    if not dataset_path.exists():\n",
    "        if len(dataset_path.glob('*.csv')) == 0:\n",
    "            kaggle.api.dataset_download_files(dataset_name, path=dataset_path, unzip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_datasets(datasets, datasets_path, test_size=0.3, random_state=0):\n",
    "    from tqdm import tqdm\n",
    "    from pathlib import Path\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    \n",
    "    \n",
    "    for dataset in tqdm(datasets):\n",
    "        dataset_name = dataset['link'].replace('https://www.kaggle.com/datasets/', '')\n",
    "        files = list((Path(datasets_path) / dataset_name).glob('*.csv'))\n",
    "        if len(files) == 1:\n",
    "            dataset_path = files[0]\n",
    "            data = pd.read_csv(dataset_path)\n",
    "            target_name = dataset['target']\n",
    "            data = data.dropna(subset=[target_name])\n",
    "            \n",
    "            if dataset.get('id_cols'):\n",
    "                data = data.drop(columns=[dataset['id_cols']], errors='ignore')\n",
    "\n",
    "            le = LabelEncoder()\n",
    "            data[target_name] = le.fit_transform(data[target_name])\n",
    "            data = data.select_dtypes(include=[np.number]).dropna(how='all', axis='columns').fillna(0)\n",
    "            train_data, test_data = train_test_split(\n",
    "                data, \n",
    "                test_size=test_size, \n",
    "                stratify=data[target_name], \n",
    "                random_state=random_state\n",
    "            )\n",
    "            yield train_data, test_data, target_name, dataset_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from automl.model import AutoML\n",
    "from automl.model.metrics import RocAuc\n",
    "\n",
    "\n",
    "for train, test, target_name in get_train_test_datasets(datasets, datasets_path='./datasets', test_size=0.3, random_state=0):\n",
    "    start_time = time.perf_counter()\n",
    "    automl = AutoML(task='classification', n_jobs=12, metric=metric, tuning_timeout=30,)\n",
    "    automl = automl.fit(\n",
    "        train.drop(columns=[target_name,]), train[target_name].to_numpy(), \n",
    "        test.drop(columns=[target_name,]), test[target_name].to_numpy(),\n",
    "    )\n",
    "    train_time = time.perf_counter() - start_time\n",
    "    \n",
    "    test_predictions = automl.predict(test.drop(columns=[target_name,]))\n",
    "    predict_time = time.perf_counter() - start_time - train_time\n",
    "    all_time = train_time + predict_time\n",
    "    \n",
    "    train_score = roc_auc_score(train[target_name], train_predictions)\n",
    "    test_score = roc_auc_score(test[target_name], test_predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
