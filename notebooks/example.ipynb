{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# libs\n",
    "Аналоги:  \n",
    "- https://mlbox.readthedocs.io/en/latest/  \n",
    "- https://lightautoml.readthedocs.io/  \n",
    "- https://automl.github.io/auto-sklearn/master/  \n",
    "\n",
    "Tюнинг:\n",
    "- https://optuna.org/\n",
    "- https://hyperopt.github.io/hyperopt/\n",
    "- https://docs.ray.io/en/latest/tune/index.html \n",
    "- https://oss-vizier.readthedocs.io/en/latest/ \n",
    "\n",
    "Работа с фичами:\n",
    "- https://scikit-learn.org/1.5/modules/feature_selection.html\n",
    "- https://feature-engine.trainindata.com/en/1.7.x/api_doc/selection/index.html\n",
    "- https://github.com/AutoViML/featurewiz\n",
    "- https://github.com/scikit-learn-contrib/boruta_py\n",
    "\n",
    "Прочее:\n",
    "- https://unit8co.github.io/darts/\n",
    "- https://epistasislab.github.io/tpot/  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# datasets\n",
    "Сберовский датасет:\n",
    "- https://huggingface.co/datasets/ai-lab/MBD (14,6 GB, основной датасет)\n",
    "- https://huggingface.co/datasets/ai-lab/MBD-mini (3,38 GB, уменьшенная версия, 10% клиентов из основного датасета)  \n",
    "\n",
    "Kaggle datasets:\n",
    "- https://www.kaggle.com/datasets/yasserh/titanic-dataset\n",
    "- https://www.kaggle.com/datasets/rabieelkharoua/predict-liver-disease-1700-records-dataset\n",
    "- https://www.kaggle.com/datasets/devzohaib/eligibility-prediction-for-loan\n",
    "- https://www.kaggle.com/datasets/deepcontractor/smoke-detection-dataset\n",
    "- https://www.kaggle.com/datasets/stealthtechnologies/employee-attrition-dataset\n",
    "- https://www.kaggle.com/datasets/rabieelkharoua/cancer-prediction-dataset\n",
    "- https://www.kaggle.com/datasets/yasserh/heart-disease-dataset\n",
    "- https://www.kaggle.com/datasets/rabieelkharoua/predict-online-course-engagement-dataset\n",
    "- https://www.kaggle.com/datasets/rabieelkharoua/predicting-hiring-decisions-in-recruitment-data\n",
    "- https://www.kaggle.com/datasets/barun2104/telecom-churn\n",
    "- https://www.kaggle.com/datasets/rabieelkharoua/predicting-manufacturing-defects-dataset\n",
    "- https://www.kaggle.com/datasets/rabieelkharoua/predict-customer-purchase-behavior-dataset\n",
    "- https://www.kaggle.com/datasets/teejmahal20/airline-passenger-satisfaction\n",
    "- https://www.kaggle.com/datasets/dhanushnarayananr/credit-card-fraud\n",
    "- https://www.kaggle.com/datasets/rameshmehta/credit-risk-analysis\n",
    "- https://www.kaggle.com/datasets/marcpaulo/titanic-huge-dataset-1m-passengers\n",
    "- https://www.kaggle.com/datasets/manishtripathi86/fedex-data\n",
    "- https://www.kaggle.com/datasets/ban7002/fraud-challenge-data\n",
    "- https://www.kaggle.com/datasets/ulrikthygepedersen/kickstarter-projects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "\n",
    "import kaggle\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "kaggle.api.authenticate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\n",
    "    {\n",
    "        'link': 'https://www.kaggle.com/datasets/yasserh/titanic-dataset', \n",
    "        'target': 'Survived',\n",
    "        'id_cols': ['PassengerId',],\n",
    "    },\n",
    "    {\n",
    "        'link': 'https://www.kaggle.com/datasets/rabieelkharoua/predict-liver-disease-1700-records-dataset', \n",
    "        'target': 'Diagnosis',\n",
    "    },\n",
    "    {\n",
    "        'link': 'https://www.kaggle.com/datasets/devzohaib/eligibility-prediction-for-loan', \n",
    "        'target': 'Loan_Status',\n",
    "        'id_cols': ['Loan_ID',],\n",
    "    },\n",
    "    {\n",
    "        'link': 'https://www.kaggle.com/datasets/deepcontractor/smoke-detection-dataset', \n",
    "        'target': 'Fire Alarm',\n",
    "        'id_cols': ['index',],\n",
    "    },\n",
    "    {\n",
    "        'link': 'https://www.kaggle.com/datasets/stealthtechnologies/employee-attrition-dataset', \n",
    "        'target': 'Attrition',\n",
    "        'id_cols': ['Employee ID',],\n",
    "    },\n",
    "    {\n",
    "        'link': 'https://www.kaggle.com/datasets/rabieelkharoua/cancer-prediction-dataset', \n",
    "        'target': 'Diagnosis',\n",
    "    },\n",
    "    {\n",
    "        'link': 'https://www.kaggle.com/datasets/yasserh/heart-disease-dataset', \n",
    "        'target': 'target',\n",
    "    },\n",
    "    {\n",
    "        'link': 'https://www.kaggle.com/datasets/rabieelkharoua/predict-online-course-engagement-dataset', \n",
    "        'target': 'CourseCompletion',\n",
    "        'id_cols': ['UserID',],\n",
    "    },\n",
    "    {\n",
    "        'link': 'https://www.kaggle.com/datasets/rabieelkharoua/predicting-hiring-decisions-in-recruitment-data', \n",
    "        'target': 'HiringDecision',\n",
    "    },\n",
    "    {\n",
    "        'link': 'https://www.kaggle.com/datasets/barun2104/telecom-churn', \n",
    "        'target': 'Churn',\n",
    "    },\n",
    "    {\n",
    "        'link': 'https://www.kaggle.com/datasets/rabieelkharoua/predicting-manufacturing-defects-dataset', \n",
    "        'target': 'DefectStatus',\n",
    "    },\n",
    "    {\n",
    "        'link': 'https://www.kaggle.com/datasets/rabieelkharoua/predict-customer-purchase-behavior-dataset',\n",
    "        'target': 'PurchaseStatus',\n",
    "    },\n",
    "    {\n",
    "        'link': 'https://www.kaggle.com/datasets/teejmahal20/airline-passenger-satisfaction', \n",
    "        'target': 'Satisfaction',\n",
    "    },\n",
    "    {\n",
    "        'link': 'https://www.kaggle.com/datasets/dhanushnarayananr/credit-card-fraud', \n",
    "        'target': 'fraud',\n",
    "    },\n",
    "    {\n",
    "        'link': 'https://www.kaggle.com/datasets/rameshmehta/credit-risk-analysis', \n",
    "        'target': 'default_ind',\n",
    "        'id_cols': ['id', 'member_id',],\n",
    "        'time_col': 'issue_d',\n",
    "    },\n",
    "    {\n",
    "        'link': 'https://www.kaggle.com/datasets/marcpaulo/titanic-huge-dataset-1m-passengers', \n",
    "        'target': 'Survived',\n",
    "        'id_cols': ['PassengerId',],\n",
    "    },\n",
    "    # {\n",
    "    #     'link': 'https://www.kaggle.com/datasets/manishtripathi86/fedex-data', \n",
    "    #     'target': 'Delivery_Status',\n",
    "    #     'time_col': 'Year',\n",
    "    # },\n",
    "    {\n",
    "        'link': 'https://www.kaggle.com/datasets/ban7002/fraud-challenge-data', \n",
    "        'target': 'EVENT_LABEL',\n",
    "        'time_col': 'EVENT_TIMESTAMP',\n",
    "    },\n",
    "    {\n",
    "        'link': 'https://www.kaggle.com/datasets/ulrikthygepedersen/kickstarter-projects', \n",
    "        'target': 'State',\n",
    "        'id_cols': ['ID',],\n",
    "        'time_col': 'Launched',\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in datasets:\n",
    "    dataset_name = dataset['link'].replace('https://www.kaggle.com/datasets/', '')\n",
    "    dataset_path = Path(f'./datasets/{dataset_name}')\n",
    "    if not dataset_path.exists():\n",
    "        if len(dataset_path.glob('*.csv')) == 0:\n",
    "            kaggle.api.dataset_download_files(dataset_name, path=dataset_path, unzip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_datasets(datasets, datasets_path, test_size=0.3, random_state=0):\n",
    "    from tqdm import tqdm\n",
    "    from pathlib import Path\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    \n",
    "    \n",
    "    for dataset in tqdm(datasets):\n",
    "        dataset_name = dataset['link'].replace('https://www.kaggle.com/datasets/', '')\n",
    "        files = list((Path(datasets_path) / dataset_name).glob('*.csv'))\n",
    "        if len(files) == 1:\n",
    "            dataset_path = files[0]\n",
    "            data = pd.read_csv(dataset_path)\n",
    "            target_name = dataset['target']\n",
    "            data = data.dropna(subset=[target_name])\n",
    "            \n",
    "            if dataset.get('id_cols'):\n",
    "                data = data.drop(columns=[dataset['id_cols']], errors='ignore')\n",
    "\n",
    "            le = LabelEncoder()\n",
    "            data[target_name] = le.fit_transform(data[target_name])\n",
    "            data = data.select_dtypes(include=[np.number]).dropna(how='any')\n",
    "            train_data, test_data = train_test_split(\n",
    "                data, \n",
    "                test_size=test_size, \n",
    "                stratify=data[target_name], \n",
    "                random_state=random_state\n",
    "            )\n",
    "            yield train_data, test_data, target_name, dataset_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Модуль model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.21060752, 0.78939248],\n",
       "       [0.50827819, 0.49172181],\n",
       "       [0.67088648, 0.32911352],\n",
       "       [0.73358437, 0.26641563],\n",
       "       [0.49856997, 0.50143003],\n",
       "       [0.76683811, 0.23316189],\n",
       "       [0.69474077, 0.30525923],\n",
       "       [0.1730164 , 0.8269836 ],\n",
       "       [0.77385516, 0.22614484],\n",
       "       [0.2689698 , 0.7310302 ],\n",
       "       [0.18184703, 0.81815297],\n",
       "       [0.33173854, 0.66826146],\n",
       "       [0.35925747, 0.64074253],\n",
       "       [0.93523607, 0.06476393],\n",
       "       [0.85052498, 0.14947502],\n",
       "       [0.56674735, 0.43325265],\n",
       "       [0.20575057, 0.79424943],\n",
       "       [0.76029504, 0.23970496],\n",
       "       [0.68943632, 0.31056368],\n",
       "       [0.76367958, 0.23632042],\n",
       "       [0.47531394, 0.52468606],\n",
       "       [0.7441298 , 0.2558702 ],\n",
       "       [0.63660115, 0.36339885],\n",
       "       [0.45629803, 0.54370197],\n",
       "       [0.78542199, 0.21457801],\n",
       "       [0.89731191, 0.10268809],\n",
       "       [0.62602671, 0.37397329],\n",
       "       [0.79800846, 0.20199154],\n",
       "       [0.31241991, 0.68758009],\n",
       "       [0.81522236, 0.18477764],\n",
       "       [0.78717267, 0.21282733],\n",
       "       [0.1969664 , 0.8030336 ],\n",
       "       [0.78107913, 0.21892087],\n",
       "       [0.74011577, 0.25988423],\n",
       "       [0.83260095, 0.16739905],\n",
       "       [0.87770485, 0.12229515],\n",
       "       [0.67289795, 0.32710205],\n",
       "       [0.40083399, 0.59916601],\n",
       "       [0.60397234, 0.39602766],\n",
       "       [0.74858606, 0.25141394],\n",
       "       [0.57775353, 0.42224647],\n",
       "       [0.63775497, 0.36224503],\n",
       "       [0.36099705, 0.63900295],\n",
       "       [0.14367081, 0.85632919],\n",
       "       [0.74447858, 0.25552142],\n",
       "       [0.7179516 , 0.2820484 ],\n",
       "       [0.78638935, 0.21361065],\n",
       "       [0.65580424, 0.34419576],\n",
       "       [0.28245512, 0.71754488],\n",
       "       [0.66093108, 0.33906892],\n",
       "       [0.58194084, 0.41805916],\n",
       "       [0.70604515, 0.29395485],\n",
       "       [0.84130417, 0.15869583],\n",
       "       [0.61367238, 0.38632762],\n",
       "       [0.7383013 , 0.2616987 ],\n",
       "       [0.81257693, 0.18742307],\n",
       "       [0.84596656, 0.15403344],\n",
       "       [0.88948455, 0.11051545],\n",
       "       [0.79210283, 0.20789717],\n",
       "       [0.79877355, 0.20122645],\n",
       "       [0.79831443, 0.20168557],\n",
       "       [0.72629682, 0.27370318],\n",
       "       [0.75197364, 0.24802636],\n",
       "       [0.82994234, 0.17005766],\n",
       "       [0.76083709, 0.23916291],\n",
       "       [0.78501395, 0.21498605],\n",
       "       [0.65626975, 0.34373025],\n",
       "       [0.52910827, 0.47089173],\n",
       "       [0.71913364, 0.28086636],\n",
       "       [0.63207735, 0.36792265],\n",
       "       [0.78365671, 0.21634329],\n",
       "       [0.76097551, 0.23902449],\n",
       "       [0.83168751, 0.16831249],\n",
       "       [0.84468109, 0.15531891],\n",
       "       [0.44836203, 0.55163797],\n",
       "       [0.84859591, 0.15140409],\n",
       "       [0.87152855, 0.12847145],\n",
       "       [0.36272251, 0.63727749],\n",
       "       [0.2551895 , 0.7448105 ],\n",
       "       [0.75383406, 0.24616594],\n",
       "       [0.57022936, 0.42977064],\n",
       "       [0.57215249, 0.42784751],\n",
       "       [0.54144052, 0.45855948],\n",
       "       [0.34782242, 0.65217758],\n",
       "       [0.86461754, 0.13538246],\n",
       "       [0.68177992, 0.31822008],\n",
       "       [0.40461968, 0.59538032],\n",
       "       [0.12708102, 0.87291898],\n",
       "       [0.82889144, 0.17110856],\n",
       "       [0.79262653, 0.20737347],\n",
       "       [0.78723742, 0.21276258],\n",
       "       [0.66260768, 0.33739232],\n",
       "       [0.77218612, 0.22781388],\n",
       "       [0.54517181, 0.45482819],\n",
       "       [0.65609742, 0.34390258],\n",
       "       [0.42294076, 0.57705924],\n",
       "       [0.48884192, 0.51115808],\n",
       "       [0.5611828 , 0.4388172 ],\n",
       "       [0.38137731, 0.61862269],\n",
       "       [0.37913345, 0.62086655],\n",
       "       [0.19451522, 0.80548478],\n",
       "       [0.52813508, 0.47186492],\n",
       "       [0.19441532, 0.80558468],\n",
       "       [0.37946172, 0.62053828],\n",
       "       [0.61789274, 0.38210726],\n",
       "       [0.27711029, 0.72288971],\n",
       "       [0.66748947, 0.33251053],\n",
       "       [0.89752365, 0.10247635],\n",
       "       [0.43826203, 0.56173797],\n",
       "       [0.64845281, 0.35154719],\n",
       "       [0.62660963, 0.37339037],\n",
       "       [0.4802238 , 0.5197762 ],\n",
       "       [0.64742841, 0.35257159],\n",
       "       [0.66273711, 0.33726289],\n",
       "       [0.75308946, 0.24691054],\n",
       "       [0.5809386 , 0.4190614 ],\n",
       "       [0.2225395 , 0.7774605 ],\n",
       "       [0.89273961, 0.10726039],\n",
       "       [0.68244789, 0.31755211],\n",
       "       [0.78475072, 0.21524928],\n",
       "       [0.76226226, 0.23773774],\n",
       "       [0.62550549, 0.37449451],\n",
       "       [0.81491385, 0.18508615],\n",
       "       [0.79772699, 0.20227301],\n",
       "       [0.64938355, 0.35061645],\n",
       "       [0.31363575, 0.68636425],\n",
       "       [0.30561519, 0.69438481],\n",
       "       [0.76984675, 0.23015325],\n",
       "       [0.29594771, 0.70405229],\n",
       "       [0.64859012, 0.35140988],\n",
       "       [0.81517135, 0.18482865],\n",
       "       [0.78912771, 0.21087229],\n",
       "       [0.61075288, 0.38924712],\n",
       "       [0.73169465, 0.26830535],\n",
       "       [0.31290184, 0.68709816],\n",
       "       [0.85517406, 0.14482594],\n",
       "       [0.61899345, 0.38100655],\n",
       "       [0.80197004, 0.19802996],\n",
       "       [0.36796882, 0.63203118],\n",
       "       [0.77380829, 0.22619171],\n",
       "       [0.79549925, 0.20450075],\n",
       "       [0.66742327, 0.33257673],\n",
       "       [0.80525994, 0.19474006],\n",
       "       [0.77170805, 0.22829195],\n",
       "       [0.85232004, 0.14767996],\n",
       "       [0.72820789, 0.27179211],\n",
       "       [0.86957282, 0.13042718],\n",
       "       [0.44223311, 0.55776689],\n",
       "       [0.25123639, 0.74876361],\n",
       "       [0.71815956, 0.28184044],\n",
       "       [0.73939159, 0.26060841],\n",
       "       [0.83445811, 0.16554189],\n",
       "       [0.22201793, 0.77798207],\n",
       "       [0.25687311, 0.74312689],\n",
       "       [0.92346073, 0.07653927],\n",
       "       [0.63367938, 0.36632062],\n",
       "       [0.83059025, 0.16940975],\n",
       "       [0.79832003, 0.20167997],\n",
       "       [0.18813168, 0.81186832],\n",
       "       [0.63513996, 0.36486004],\n",
       "       [0.87932144, 0.12067856],\n",
       "       [0.22051046, 0.77948954],\n",
       "       [0.76282891, 0.23717109],\n",
       "       [0.79382002, 0.20617998],\n",
       "       [0.3506229 , 0.6493771 ],\n",
       "       [0.70812136, 0.29187864],\n",
       "       [0.34008475, 0.65991525],\n",
       "       [0.52341676, 0.47658324],\n",
       "       [0.67842804, 0.32157196],\n",
       "       [0.83114416, 0.16885584],\n",
       "       [0.82996512, 0.17003488],\n",
       "       [0.74881757, 0.25118243],\n",
       "       [0.16719623, 0.83280377],\n",
       "       [0.61195472, 0.38804528],\n",
       "       [0.45753092, 0.54246908],\n",
       "       [0.62335296, 0.37664704],\n",
       "       [0.3648577 , 0.6351423 ],\n",
       "       [0.64553805, 0.35446195],\n",
       "       [0.30098392, 0.69901608],\n",
       "       [0.79274937, 0.20725063],\n",
       "       [0.39374024, 0.60625976],\n",
       "       [0.72506311, 0.27493689],\n",
       "       [0.90467536, 0.09532464],\n",
       "       [0.82564116, 0.17435884],\n",
       "       [0.78509375, 0.21490625],\n",
       "       [0.54743961, 0.45256039],\n",
       "       [0.2148798 , 0.7851202 ],\n",
       "       [0.82538432, 0.17461568],\n",
       "       [0.23811457, 0.76188543],\n",
       "       [0.26771116, 0.73228884],\n",
       "       [0.35219906, 0.64780094],\n",
       "       [0.76190866, 0.23809134],\n",
       "       [0.8241093 , 0.1758907 ],\n",
       "       [0.28584127, 0.71415873],\n",
       "       [0.87124244, 0.12875756],\n",
       "       [0.77017851, 0.22982149],\n",
       "       [0.72311551, 0.27688449],\n",
       "       [0.80960195, 0.19039805],\n",
       "       [0.7211433 , 0.2788567 ],\n",
       "       [0.91782938, 0.08217062],\n",
       "       [0.26275693, 0.73724307],\n",
       "       [0.83734378, 0.16265622],\n",
       "       [0.3428788 , 0.6571212 ],\n",
       "       [0.56722343, 0.43277657],\n",
       "       [0.87768426, 0.12231574],\n",
       "       [0.55610271, 0.44389729],\n",
       "       [0.20199794, 0.79800206],\n",
       "       [0.62543212, 0.37456788],\n",
       "       [0.91852588, 0.08147412],\n",
       "       [0.32389942, 0.67610058],\n",
       "       [0.20944775, 0.79055225],\n",
       "       [0.759343  , 0.240657  ],\n",
       "       [0.856507  , 0.143493  ],\n",
       "       [0.84241891, 0.15758109],\n",
       "       [0.46161582, 0.53838418]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-10-30 18:59:04,621] - [   MODEL   ] - 1 out of 15. LogisticRegression\n",
      "[2024-10-30 18:59:04,623] - [   START   ] - Working with LogisticRegression\n",
      "[2024-10-30 18:59:04,626] - [   START   ] - Tuning LogisticRegression\n",
      "[2024-10-30 18:59:19,648] - [BEST PARAMS] - {'C': 0.046415888336127774, 'class_weight': 'balanced', 'max_iter': 1000, 'n_jobs': 6, 'random_state': 42}\n",
      "[2024-10-30 18:59:19,650] - [    END    ] - Tuning LogisticRegression\n",
      "[2024-10-30 18:59:19,651] - [   START   ] - Fitting LogisticRegression\n",
      "[2024-10-30 18:59:19,654] - [    FIT    ] - LogisticRegression fold 0\n",
      "[2024-10-30 18:59:19,672] - [    FIT    ] - LogisticRegression fold 1\n",
      "[2024-10-30 18:59:19,692] - [    FIT    ] - LogisticRegression fold 2\n",
      "[2024-10-30 18:59:19,707] - [    FIT    ] - LogisticRegression fold 3\n",
      "[2024-10-30 18:59:19,722] - [    FIT    ] - LogisticRegression fold 4\n",
      "[2024-10-30 18:59:19,741] - [    END    ] - Fitting LogisticRegression\n",
      "[2024-10-30 18:59:19,746] - [   SCORE   ] - Train: 0.7727666089735055\n",
      "[2024-10-30 18:59:19,750] - [   SCORE   ] - OOF: 0.7662095593130076\n",
      "[2024-10-30 18:59:19,754] - [   SCORE   ] - Test: 0.7017780172413792\n",
      "[2024-10-30 18:59:19,756] - [   SCORE   ] - Overfit: 9.19 %\n",
      "[2024-10-30 18:59:19,769] - [    END    ] - Working with LogisticRegression\n",
      "[2024-10-30 18:59:19,780] - [  NEW BEST ] - LogisticRegression. Best score: 0.7017780172413792 \n",
      "\n",
      "[2024-10-30 18:59:19,782] - [   MODEL   ] - 2 out of 15. RandomForestClassification\n",
      "[2024-10-30 18:59:19,784] - [   START   ] - Working with RandomForestClassification\n",
      "[2024-10-30 18:59:19,786] - [   START   ] - Tuning RandomForestClassification\n",
      "[2024-10-30 18:59:21,880] - [   OPTUNA  ] - Trial 0. New best score 0.7303706076891278 with parameters {'n_estimators': 387, 'max_depth': 15, 'min_samples_split': 0.146398788362281, 'min_samples_leaf': 0.11973169683940732, 'max_features': 0.24041677639819287, 'criterion': 'log_loss', 'class_weight': 'balanced_subsample', 'oob_score': False, 'max_samples': 0.8341182143924175}\n",
      "[2024-10-30 18:59:23,001] - [   OPTUNA  ] - Trial 1. New best score 0.7457954388865924 with parameters {'n_estimators': 228, 'max_depth': 4, 'min_samples_split': 0.03668090197068676, 'min_samples_leaf': 0.06084844859190755, 'max_features': 0.5722807884690141, 'criterion': 'log_loss', 'class_weight': 'balanced_subsample', 'oob_score': False, 'max_samples': 0.7873242017790835}\n",
      "[2024-10-30 18:59:24,336] - [   OPTUNA  ] - Trial 2. New best score 0.7616601557117266 with parameters {'n_estimators': 215, 'max_depth': 9, 'min_samples_split': 0.1184829137724085, 'min_samples_leaf': 0.009290082543999545, 'max_features': 0.6467903667112945, 'criterion': 'log_loss', 'class_weight': 'balanced', 'oob_score': True, 'max_samples': 0.6873906962470353}\n",
      "[2024-10-30 18:59:47,490] - [   OPTUNA  ] - Trial 11. New best score 0.7659221441366957 with parameters {'n_estimators': 561, 'max_depth': 8, 'min_samples_split': 0.07121824466699872, 'min_samples_leaf': 0.004689401807340943, 'max_features': 0.7827408179970072, 'criterion': 'entropy', 'class_weight': 'balanced_subsample', 'oob_score': False, 'max_samples': 0.6405508745066752}\n",
      "[2024-10-30 18:59:51,269] - [   OPTUNA  ] - 13 trials completed\n",
      "[2024-10-30 18:59:51,270] - [BEST PARAMS] - {'n_estimators': 561, 'criterion': 'entropy', 'max_depth': 8, 'min_samples_split': 0.07121824466699872, 'min_samples_leaf': 0.004689401807340943, 'max_features': 0.7827408179970072, 'bootstrap': True, 'oob_score': False, 'max_samples': 0.6405508745066752, 'n_jobs': 6, 'random_state': 42, 'class_weight': 'balanced_subsample'}\n",
      "[2024-10-30 18:59:51,272] - [    END    ] - Tuning RandomForestClassification\n",
      "[2024-10-30 18:59:51,275] - [   START   ] - Fitting RandomForestClassification\n",
      "[2024-10-30 18:59:51,277] - [    FIT    ] - RandomForestClassification fold 0\n",
      "[2024-10-30 18:59:53,415] - [    FIT    ] - RandomForestClassification fold 1\n",
      "[2024-10-30 18:59:55,551] - [    FIT    ] - RandomForestClassification fold 2\n",
      "[2024-10-30 18:59:57,682] - [    FIT    ] - RandomForestClassification fold 3\n",
      "[2024-10-30 18:59:59,814] - [    FIT    ] - RandomForestClassification fold 4\n",
      "[2024-10-30 19:00:01,933] - [    END    ] - Fitting RandomForestClassification\n",
      "[2024-10-30 19:00:03,261] - [   SCORE   ] - Train: 0.8617860471308747\n",
      "[2024-10-30 19:00:03,264] - [   SCORE   ] - OOF: 0.7628644654506722\n",
      "[2024-10-30 19:00:04,143] - [   SCORE   ] - Test: 0.7449712643678161\n",
      "[2024-10-30 19:00:04,145] - [   SCORE   ] - Overfit: 13.55 %\n",
      "[2024-10-30 19:00:05,560] - [    END    ] - Working with RandomForestClassification\n",
      "[2024-10-30 19:00:05,562] - [  NEW BEST ] - RandomForestClassification. Best score: 0.7449712643678161 \n",
      "\n",
      "[2024-10-30 19:00:05,564] - [   MODEL   ] - 3 out of 15. ExtraTreesClassification\n",
      "[2024-10-30 19:00:05,566] - [   START   ] - Working with ExtraTreesClassification\n",
      "[2024-10-30 19:00:05,568] - [   START   ] - Tuning ExtraTreesClassification\n",
      "[2024-10-30 19:00:07,136] - [   OPTUNA  ] - Trial 0. New best score 0.7249109824996556 with parameters {'n_estimators': 387, 'max_depth': 15, 'min_samples_split': 0.146398788362281, 'min_samples_leaf': 0.11973169683940732, 'max_features': 0.24041677639819287, 'criterion': 'log_loss', 'class_weight': 'balanced_subsample', 'oob_score': False, 'max_samples': 0.8341182143924175}\n",
      "[2024-10-30 19:00:08,211] - [   OPTUNA  ] - Trial 1. New best score 0.7424320311423454 with parameters {'n_estimators': 228, 'max_depth': 4, 'min_samples_split': 0.03668090197068676, 'min_samples_leaf': 0.06084844859190755, 'max_features': 0.5722807884690141, 'criterion': 'log_loss', 'class_weight': 'balanced_subsample', 'oob_score': False, 'max_samples': 0.7873242017790835}\n",
      "[2024-10-30 19:00:09,500] - [   OPTUNA  ] - Trial 2. New best score 0.7626321827201322 with parameters {'n_estimators': 215, 'max_depth': 9, 'min_samples_split': 0.1184829137724085, 'min_samples_leaf': 0.009290082543999545, 'max_features': 0.6467903667112945, 'criterion': 'log_loss', 'class_weight': 'balanced', 'oob_score': True, 'max_samples': 0.6873906962470353}\n",
      "[2024-10-30 19:00:32,156] - [   OPTUNA  ] - Trial 11. New best score 0.7736552983326443 with parameters {'n_estimators': 561, 'max_depth': 8, 'min_samples_split': 0.07121824466699872, 'min_samples_leaf': 0.004689401807340943, 'max_features': 0.7827408179970072, 'criterion': 'entropy', 'class_weight': 'balanced_subsample', 'oob_score': False, 'max_samples': 0.6405508745066752}\n",
      "[2024-10-30 19:00:35,893] - [   OPTUNA  ] - 13 trials completed\n",
      "[2024-10-30 19:00:35,895] - [BEST PARAMS] - {'n_estimators': 561, 'criterion': 'entropy', 'max_depth': 8, 'min_samples_split': 0.07121824466699872, 'min_samples_leaf': 0.004689401807340943, 'max_features': 0.7827408179970072, 'bootstrap': True, 'oob_score': False, 'max_samples': 0.6405508745066752, 'n_jobs': 6, 'random_state': 42, 'class_weight': 'balanced_subsample', 'verbose': 0}\n",
      "[2024-10-30 19:00:35,897] - [    END    ] - Tuning ExtraTreesClassification\n",
      "[2024-10-30 19:00:35,899] - [   START   ] - Fitting ExtraTreesClassification\n",
      "[2024-10-30 19:00:35,901] - [    FIT    ] - ExtraTreesClassification fold 0\n",
      "[2024-10-30 19:00:38,042] - [    FIT    ] - ExtraTreesClassification fold 1\n",
      "[2024-10-30 19:00:40,186] - [    FIT    ] - ExtraTreesClassification fold 2\n",
      "[2024-10-30 19:00:42,324] - [    FIT    ] - ExtraTreesClassification fold 3\n",
      "[2024-10-30 19:00:44,493] - [    FIT    ] - ExtraTreesClassification fold 4\n",
      "[2024-10-30 19:00:46,701] - [    END    ] - Fitting ExtraTreesClassification\n",
      "[2024-10-30 19:00:48,062] - [   SCORE   ] - Train: 0.812574890161097\n",
      "[2024-10-30 19:00:48,065] - [   SCORE   ] - OOF: 0.7665756889894819\n",
      "[2024-10-30 19:00:48,961] - [   SCORE   ] - Test: 0.7361709770114944\n",
      "[2024-10-30 19:00:48,964] - [   SCORE   ] - Overfit: 9.40 %\n",
      "[2024-10-30 19:00:50,428] - [    END    ] - Working with ExtraTreesClassification\n",
      "[2024-10-30 19:00:50,430] - [BEST  MODEL] - RandomForestClassification. Best score: 0.7449712643678161 \n",
      "\n",
      "[2024-10-30 19:00:50,432] - [   MODEL   ] - 4 out of 15. CatBoostClassification\n",
      "[2024-10-30 19:00:50,434] - [   START   ] - Working with CatBoostClassification\n",
      "[2024-10-30 19:00:50,436] - [   START   ] - Tuning CatBoostClassification\n",
      "[2024-10-30 19:00:52,410] - [   OPTUNA  ] - Trial 0. New best score 0.7690171558495246 with parameters {'boosting_type': 'Plain', 'depth': 6, 'l2_leaf_reg': 190.14286128198324, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 222, 'rsm': 0.7606690070459252, 'subsample': 0.8248435466776274, 'model_size_reg': 4.116898859160489, 'auto_class_weights': None, 'iterations': 531}\n",
      "[2024-10-30 19:00:56,444] - [   OPTUNA  ] - Trial 5. New best score 0.7765060975609756 with parameters {'boosting_type': 'Plain', 'depth': 4, 'l2_leaf_reg': 1.1044234247204798, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'Depthwise', 'min_data_in_leaf': 92, 'rsm': 0.4695214357150779, 'subsample': 0.9178620555253562, 'model_size_reg': 124.65962536551159, 'auto_class_weights': None, 'iterations': 213}\n",
      "[2024-10-30 19:01:33,556] - [   OPTUNA  ] - 12 trials completed\n",
      "[2024-10-30 19:01:33,558] - [BEST PARAMS] - {'boosting_type': 'Plain', 'iterations': 213, 'learning_rate': 0.03, 'max_leaves': None, 'grow_policy': 'Depthwise', 'depth': 4, 'l2_leaf_reg': 1.1044234247204798, 'model_size_reg': 124.65962536551159, 'od_wait': 100, 'bootstrap_type': 'Bernoulli', 'rsm': 0.4695214357150779, 'subsample': 0.9178620555253562, 'min_data_in_leaf': 92, 'one_hot_max_size': 10, 'auto_class_weights': None, 'thread_count': 6, 'random_state': 42, 'verbose': False, 'allow_writing_files': False}\n",
      "[2024-10-30 19:01:33,561] - [    END    ] - Tuning CatBoostClassification\n",
      "[2024-10-30 19:01:33,563] - [   START   ] - Fitting CatBoostClassification\n",
      "[2024-10-30 19:01:33,566] - [    FIT    ] - CatBoostClassification fold 0\n",
      "[2024-10-30 19:01:33,678] - [    FIT    ] - CatBoostClassification fold 1\n",
      "[2024-10-30 19:01:33,785] - [    FIT    ] - CatBoostClassification fold 2\n",
      "[2024-10-30 19:01:33,897] - [    FIT    ] - CatBoostClassification fold 3\n",
      "[2024-10-30 19:01:33,999] - [    FIT    ] - CatBoostClassification fold 4\n",
      "[2024-10-30 19:01:34,104] - [    END    ] - Fitting CatBoostClassification\n",
      "[2024-10-30 19:01:34,116] - [   SCORE   ] - Train: 0.8428305152443083\n",
      "[2024-10-30 19:01:34,120] - [   SCORE   ] - OOF: 0.7686393289841567\n",
      "[2024-10-30 19:01:34,128] - [   SCORE   ] - Test: 0.7544899425287356\n",
      "[2024-10-30 19:01:34,130] - [   SCORE   ] - Overfit: 10.48 %\n",
      "[2024-10-30 19:01:34,146] - [    END    ] - Working with CatBoostClassification\n",
      "[2024-10-30 19:01:34,148] - [  NEW BEST ] - CatBoostClassification. Best score: 0.7544899425287356 \n",
      "\n",
      "[2024-10-30 19:01:34,150] - [   MODEL   ] - 5 out of 15. LightGBMClassification\n",
      "[2024-10-30 19:01:34,152] - [   START   ] - Working with LightGBMClassification\n",
      "[2024-10-30 19:01:34,155] - [   START   ] - Tuning LightGBMClassification\n",
      "[2024-10-30 19:01:34,236] - [   OPTUNA  ] - Trial 0. New best score 0.6738008646823757 with parameters {'max_depth': 6, 'num_leaves': 488, 'min_data_in_leaf': 188, 'bagging_fraction': 0.7993292420985183, 'bagging_freq': 0, 'feature_fraction': 0.49359671220172163, 'lambda_l1': 0.5808361216819946, 'lambda_l2': 8.661761457749352, 'min_gain_to_split': 12.022300234864176, 'is_unbalance': True, 'num_iterations': 41}\n",
      "[2024-10-30 19:01:34,366] - [   OPTUNA  ] - Trial 1. New best score 0.7296570724817417 with parameters {'max_depth': 16, 'num_leaves': 428, 'min_data_in_leaf': 55, 'bagging_fraction': 0.5909124836035503, 'bagging_freq': 0, 'feature_fraction': 0.5825453457757226, 'lambda_l1': 5.247564316322379, 'lambda_l2': 4.319450186421157, 'min_gain_to_split': 5.824582803960839, 'is_unbalance': True, 'num_iterations': 80}\n",
      "[2024-10-30 19:01:34,811] - [   OPTUNA  ] - Trial 7. New best score 0.7369016122364613 with parameters {'max_depth': 2, 'num_leaves': 190, 'min_data_in_leaf': 30, 'bagging_fraction': 0.9315517129377968, 'bagging_freq': 10, 'feature_fraction': 0.5985388149115896, 'lambda_l1': 0.6355835028602363, 'lambda_l2': 3.109823217156622, 'min_gain_to_split': 6.503666440534941, 'is_unbalance': True, 'num_iterations': 61}\n",
      "[2024-10-30 19:01:35,423] - [   OPTUNA  ] - Trial 13. New best score 0.7388406366267054 with parameters {'max_depth': 12, 'num_leaves': 302, 'min_data_in_leaf': 65, 'bagging_fraction': 0.700465267822002, 'bagging_freq': 0, 'feature_fraction': 0.8113027648773605, 'lambda_l1': 7.298348295317013, 'lambda_l2': 6.2093686675641955, 'min_gain_to_split': 1.0004229129601017, 'is_unbalance': True, 'num_iterations': 99}\n",
      "[2024-10-30 19:01:38,011] - [   OPTUNA  ] - Trial 31. New best score 0.7390325203252033 with parameters {'max_depth': 6, 'num_leaves': 153, 'min_data_in_leaf': 73, 'bagging_fraction': 0.768827702615302, 'bagging_freq': 0, 'feature_fraction': 0.4015220208361536, 'lambda_l1': 3.4204266696179007, 'lambda_l2': 0.21891514820133207, 'min_gain_to_split': 2.0472123675227767, 'is_unbalance': True, 'num_iterations': 151}\n",
      "[2024-10-30 19:01:38,478] - [   OPTUNA  ] - Trial 34. New best score 0.7450138142483118 with parameters {'max_depth': 8, 'num_leaves': 83, 'min_data_in_leaf': 56, 'bagging_fraction': 0.610031957196443, 'bagging_freq': 0, 'feature_fraction': 0.403791862050096, 'lambda_l1': 3.2074425872921304, 'lambda_l2': 0.0003670872070183073, 'min_gain_to_split': 1.985697076753496, 'is_unbalance': True, 'num_iterations': 201}\n",
      "[2024-10-30 19:01:38,647] - [   OPTUNA  ] - Trial 35. New best score 0.7509982603003996 with parameters {'max_depth': 8, 'num_leaves': 15, 'min_data_in_leaf': 57, 'bagging_fraction': 0.5949149030444254, 'bagging_freq': 0, 'feature_fraction': 0.5453510012659264, 'lambda_l1': 3.181873613419713, 'lambda_l2': 0.38094369245929927, 'min_gain_to_split': 0.5941792653078877, 'is_unbalance': True, 'num_iterations': 122}\n",
      "[2024-10-30 19:01:38,861] - [   OPTUNA  ] - Trial 36. New best score 0.7521210210830922 with parameters {'max_depth': 8, 'num_leaves': 22, 'min_data_in_leaf': 57, 'bagging_fraction': 0.5758699830271408, 'bagging_freq': 0, 'feature_fraction': 0.5403764058116077, 'lambda_l1': 4.7978476317339585, 'lambda_l2': 1.477248896129733, 'min_gain_to_split': 0.07870146814009837, 'is_unbalance': True, 'num_iterations': 182}\n",
      "[2024-10-30 19:01:44,558] - [   OPTUNA  ] - Trial 73. New best score 0.7585813008130081 with parameters {'max_depth': 7, 'num_leaves': 41, 'min_data_in_leaf': 29, 'bagging_fraction': 0.6295971606147858, 'bagging_freq': 0, 'feature_fraction': 0.5093427292878415, 'lambda_l1': 2.9126251098958593, 'lambda_l2': 0.7184962101315919, 'min_gain_to_split': 0.20740469068336145, 'is_unbalance': False, 'num_iterations': 133}\n",
      "[2024-10-30 19:01:45,059] - [   OPTUNA  ] - Trial 75. New best score 0.758913755684167 with parameters {'max_depth': 5, 'num_leaves': 43, 'min_data_in_leaf': 15, 'bagging_fraction': 0.5943948868826926, 'bagging_freq': 0, 'feature_fraction': 0.5140460749931549, 'lambda_l1': 2.0630131086578114, 'lambda_l2': 0.11662152189271824, 'min_gain_to_split': 0.01281271122502653, 'is_unbalance': True, 'num_iterations': 151}\n",
      "[2024-10-30 19:01:45,587] - [   OPTUNA  ] - Trial 77. New best score 0.7630592359101557 with parameters {'max_depth': 4, 'num_leaves': 26, 'min_data_in_leaf': 9, 'bagging_fraction': 0.662499360369761, 'bagging_freq': 0, 'feature_fraction': 0.4522725675547421, 'lambda_l1': 2.3029806726119584, 'lambda_l2': 0.02361172060163981, 'min_gain_to_split': 0.01585073399226153, 'is_unbalance': True, 'num_iterations': 159}\n",
      "[2024-10-30 19:01:52,815] - [   OPTUNA  ] - Trial 116. New best score 0.7634638452528593 with parameters {'max_depth': 5, 'num_leaves': 345, 'min_data_in_leaf': 23, 'bagging_fraction': 0.7873414998736394, 'bagging_freq': 0, 'feature_fraction': 0.7211645982121927, 'lambda_l1': 0.6874713759263651, 'lambda_l2': 7.968554774508279, 'min_gain_to_split': 0.47032217879284477, 'is_unbalance': True, 'num_iterations': 140}\n",
      "[2024-10-30 19:01:59,756] - [   OPTUNA  ] - Trial 150. New best score 0.7656284621744522 with parameters {'max_depth': 7, 'num_leaves': 311, 'min_data_in_leaf': 19, 'bagging_fraction': 0.7206762376718947, 'bagging_freq': 0, 'feature_fraction': 0.7770515406588118, 'lambda_l1': 0.07070291864688319, 'lambda_l2': 5.596660059082361, 'min_gain_to_split': 0.0647789374680609, 'is_unbalance': True, 'num_iterations': 129}\n",
      "[2024-10-30 19:02:00,399] - [   OPTUNA  ] - Trial 152. New best score 0.7657109342703597 with parameters {'max_depth': 7, 'num_leaves': 309, 'min_data_in_leaf': 19, 'bagging_fraction': 0.7264191310029375, 'bagging_freq': 0, 'feature_fraction': 0.8162617150429773, 'lambda_l1': 0.00069866305643701, 'lambda_l2': 5.858174132709117, 'min_gain_to_split': 0.06161357431692843, 'is_unbalance': True, 'num_iterations': 127}\n",
      "[2024-10-30 19:02:02,216] - [   OPTUNA  ] - Trial 158. New best score 0.7685534656194019 with parameters {'max_depth': 8, 'num_leaves': 446, 'min_data_in_leaf': 19, 'bagging_fraction': 0.7226280333408298, 'bagging_freq': 0, 'feature_fraction': 0.7849134403063075, 'lambda_l1': 0.33859378107419796, 'lambda_l2': 4.640686710728847, 'min_gain_to_split': 0.0771701017541865, 'is_unbalance': True, 'num_iterations': 117}\n",
      "[2024-10-30 19:02:04,318] - [   OPTUNA  ] - 165 trials completed\n",
      "[2024-10-30 19:02:04,320] - [BEST PARAMS] - {'objective_type': 'binary', 'boosting': 'gbdt', 'num_iterations': 117, 'max_depth': 8, 'learning_rate': 0.03, 'num_leaves': 446, 'min_data_in_leaf': 19, 'bagging_fraction': 0.7226280333408298, 'bagging_freq': 0, 'feature_fraction': 0.7849134403063075, 'early_stopping_round': 100, 'lambda_l1': 0.33859378107419796, 'lambda_l2': 4.640686710728847, 'min_gain_to_split': 0.0771701017541865, 'num_threads': 6, 'random_state': 42, 'is_unbalance': True, 'num_classes': 1, 'verbose': -1}\n",
      "[2024-10-30 19:02:04,322] - [    END    ] - Tuning LightGBMClassification\n",
      "[2024-10-30 19:02:04,324] - [   START   ] - Fitting LightGBMClassification\n",
      "[2024-10-30 19:02:04,326] - [    FIT    ] - LightGBMClassification fold 0\n",
      "[2024-10-30 19:02:04,361] - [    FIT    ] - LightGBMClassification fold 1\n",
      "[2024-10-30 19:02:04,395] - [    FIT    ] - LightGBMClassification fold 2\n",
      "[2024-10-30 19:02:04,429] - [    FIT    ] - LightGBMClassification fold 3\n",
      "[2024-10-30 19:02:04,461] - [    FIT    ] - LightGBMClassification fold 4\n",
      "[2024-10-30 19:02:04,493] - [    END    ] - Fitting LightGBMClassification\n",
      "[2024-10-30 19:02:04,503] - [   SCORE   ] - Train: 0.8659798961523099\n",
      "[2024-10-30 19:02:04,506] - [   SCORE   ] - OOF: 0.7633803754493409\n",
      "[2024-10-30 19:02:04,513] - [   SCORE   ] - Test: 0.7374730603448276\n",
      "[2024-10-30 19:02:04,516] - [   SCORE   ] - Overfit: 14.84 %\n",
      "[2024-10-30 19:02:04,549] - [    END    ] - Working with LightGBMClassification\n",
      "[2024-10-30 19:02:04,551] - [BEST  MODEL] - CatBoostClassification. Best score: 0.7544899425287356 \n",
      "\n",
      "[2024-10-30 19:02:04,553] - [   MODEL   ] - 6 out of 15. XGBClassification\n",
      "[2024-10-30 19:02:04,555] - [   START   ] - Working with XGBClassification\n",
      "[2024-10-30 19:02:04,557] - [   START   ] - Tuning XGBClassification\n",
      "[2024-10-30 19:02:05,731] - [   OPTUNA  ] - Trial 0. New best score 0.7040463862477607 with parameters {'max_depth': 6, 'grow_policy': 'depthwise', 'max_leaves': 311, 'gamma': 3.1203728088487304, 'subsample': 0.2403950683025824, 'colsample_bytree': 0.15227525095137953, 'colsample_bylevel': 0.8795585311974417, 'reg_lambda': 6.011150117432088, 'reg_alpha': 7.080725777960454, 'min_child_weight': 0, 'class_weight': None, 'n_estimators': 344}\n",
      "[2024-10-30 19:02:06,905] - [   OPTUNA  ] - Trial 1. New best score 0.7258356931238803 with parameters {'max_depth': 4, 'grow_policy': 'lossguide', 'max_leaves': 163, 'gamma': 10.495128632644757, 'subsample': 0.48875051677790415, 'colsample_bytree': 0.36210622617823773, 'colsample_bylevel': 0.6506676052501416, 'reg_lambda': 1.3949386065204183, 'reg_alpha': 2.9214464853521815, 'min_child_weight': 7, 'class_weight': 'balanced', 'n_estimators': 430}\n",
      "[2024-10-30 19:02:13,546] - [   OPTUNA  ] - Trial 7. New best score 0.7344059356483396 with parameters {'max_depth': 12, 'grow_policy': 'depthwise', 'max_leaves': 397, 'gamma': 9.875911927287815, 'subsample': 0.5704595464437947, 'colsample_bytree': 0.4847869165226947, 'colsample_bylevel': 0.12287721406968567, 'reg_lambda': 1.0789142699330445, 'reg_alpha': 0.3142918568673425, 'min_child_weight': 13, 'class_weight': 'balanced', 'n_estimators': 597}\n",
      "[2024-10-30 19:02:17,113] - [   OPTUNA  ] - Trial 10. New best score 0.7395459728537963 with parameters {'max_depth': 12, 'grow_policy': 'depthwise', 'max_leaves': 195, 'gamma': 13.425377296354338, 'subsample': 0.7436526509771155, 'colsample_bytree': 0.9168983157542658, 'colsample_bylevel': 0.6466974055799068, 'reg_lambda': 0.11062173712008272, 'reg_alpha': 0.3432449879508877, 'min_child_weight': 11, 'class_weight': 'balanced', 'n_estimators': 507}\n",
      "[2024-10-30 19:02:25,484] - [   OPTUNA  ] - Trial 18. New best score 0.7402509473611685 with parameters {'max_depth': 11, 'grow_policy': 'depthwise', 'max_leaves': 107, 'gamma': 7.732582647779751, 'subsample': 0.7089405934804249, 'colsample_bytree': 0.723570788017085, 'colsample_bylevel': 0.7418440646263058, 'reg_lambda': 3.7440755482517565, 'reg_alpha': 1.0049507358013174, 'min_child_weight': 13, 'class_weight': 'balanced', 'n_estimators': 582}\n",
      "[2024-10-30 19:02:26,563] - [   OPTUNA  ] - Trial 19. New best score 0.7426546093427036 with parameters {'max_depth': 1, 'grow_policy': 'depthwise', 'max_leaves': 96, 'gamma': 7.295438446635259, 'subsample': 0.6814123238590616, 'colsample_bytree': 0.6375440325650863, 'colsample_bylevel': 0.8424930324098573, 'reg_lambda': 6.4054133334039385, 'reg_alpha': 1.2072842128405208, 'min_child_weight': 13, 'class_weight': 'balanced', 'n_estimators': 448}\n",
      "[2024-10-30 19:02:32,877] - [   OPTUNA  ] - Trial 24. New best score 0.7458284242800055 with parameters {'max_depth': 8, 'grow_policy': 'depthwise', 'max_leaves': 144, 'gamma': 0.02579312450700666, 'subsample': 0.6119811645404927, 'colsample_bytree': 0.5074053912039583, 'colsample_bylevel': 0.8561925581743707, 'reg_lambda': 4.569269203585623, 'reg_alpha': 3.5981096710114007, 'min_child_weight': 16, 'class_weight': 'balanced', 'n_estimators': 644}\n",
      "[2024-10-30 19:02:35,514] - [   OPTUNA  ] - 27 trials completed\n",
      "[2024-10-30 19:02:35,516] - [BEST PARAMS] - {'objective': 'binary:logistic', 'n_estimators': 644, 'learning_rate': 0.03, 'max_depth': 8, 'max_leaves': 144, 'grow_policy': 'depthwise', 'gamma': 0.02579312450700666, 'min_child_weight': 16, 'subsample': 0.6119811645404927, 'colsample_bytree': 0.5074053912039583, 'colsample_bylevel': 0.8561925581743707, 'reg_lambda': 4.569269203585623, 'reg_alpha': 3.5981096710114007, 'enable_categorical': True, 'max_cat_to_onehot': 5, 'n_jobs': 6, 'random_state': 42, 'verbosity': 0, 'early_stopping_rounds': 100, 'class_weight': 'balanced'}\n",
      "[2024-10-30 19:02:35,518] - [    END    ] - Tuning XGBClassification\n",
      "[2024-10-30 19:02:35,520] - [   START   ] - Fitting XGBClassification\n",
      "[2024-10-30 19:02:35,523] - [    FIT    ] - XGBClassification fold 0\n",
      "[2024-10-30 19:02:35,777] - [    FIT    ] - XGBClassification fold 1\n",
      "[2024-10-30 19:02:35,966] - [    FIT    ] - XGBClassification fold 2\n",
      "[2024-10-30 19:02:36,226] - [    FIT    ] - XGBClassification fold 3\n",
      "[2024-10-30 19:02:36,492] - [    FIT    ] - XGBClassification fold 4\n",
      "[2024-10-30 19:02:36,717] - [    END    ] - Fitting XGBClassification\n",
      "[2024-10-30 19:02:36,734] - [   SCORE   ] - Train: 0.778682931700173\n",
      "[2024-10-30 19:02:36,738] - [   SCORE   ] - OOF: 0.7416123019571295\n",
      "[2024-10-30 19:02:36,755] - [   SCORE   ] - Test: 0.7130028735632185\n",
      "[2024-10-30 19:02:36,757] - [   SCORE   ] - Overfit: 8.43 %\n",
      "[2024-10-30 19:02:36,801] - [    END    ] - Working with XGBClassification\n",
      "[2024-10-30 19:02:36,802] - [BEST  MODEL] - CatBoostClassification. Best score: 0.7544899425287356 \n",
      "\n",
      "[2024-10-30 19:02:36,804] - [   MODEL   ] - 7 out of 15. TabularLama\n",
      "[2024-10-30 19:02:36,806] - [   START   ] - Working with TabularLama\n",
      "[2024-10-30 19:02:36,808] - [   START   ] - Fitting TabularLama\n",
      "[19:02:36] Stdout logging level is INFO.\n",
      "[19:02:36] Task: binary\n",
      "\n",
      "[19:02:36] Start automl preset with listed constraints:\n",
      "[19:02:36] - time: 60.00 seconds\n",
      "[19:02:36] - CPU: 6 cores\n",
      "[19:02:36] - memory: 16 GB\n",
      "\n",
      "[19:02:36] \u001b[1mTrain data shape: (499, 7)\u001b[0m\n",
      "\n",
      "[19:02:36] Layer \u001b[1m1\u001b[0m train process start. Time left 59.94 secs\n",
      "[19:02:36] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "[19:02:37] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.7680734922114232\u001b[0m\n",
      "[19:02:37] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "[19:02:37] Time left 58.98 secs\n",
      "\n",
      "[19:02:38] \u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n",
      "[19:02:38] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "[19:02:41] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.7470876048462256\u001b[0m\n",
      "[19:02:41] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "[19:02:41] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 1.00 secs\n",
      "[19:02:42] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n",
      "[19:02:42] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[19:02:43] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.7516891891891891\u001b[0m\n",
      "[19:02:43] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[19:02:43] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n",
      "[19:02:43] Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m0.7675908667287978\u001b[0m\n",
      "[19:02:43] \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n",
      "[19:02:43] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 38.23 secs\n",
      "[19:02:55] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n",
      "[19:02:55] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[19:02:55] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.7589618559446146\u001b[0m\n",
      "[19:02:55] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[19:02:55] Time left 41.36 secs\n",
      "\n",
      "[19:02:55] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[19:02:55] Blending: optimization starts with equal weights and score \u001b[1m0.7737817867128213\u001b[0m\n",
      "[19:02:55] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.7761283450938624\u001b[0m, weights = \u001b[1m[0.27805442 0.11514667 0.11226632 0.3939819  0.10055065]\u001b[0m\n",
      "[19:02:55] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.7768938889628545\u001b[0m, weights = \u001b[1m[0.31301817 0.1002042  0.10052795 0.3962124  0.09003725]\u001b[0m\n",
      "[19:02:55] Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.7768938889628546\u001b[0m, weights = \u001b[1m[0.32234183 0.10318891 0.07373604 0.4080141  0.09271912]\u001b[0m\n",
      "[19:02:55] Blending: iteration \u001b[1m3\u001b[0m: score = \u001b[1m0.7769937425109841\u001b[0m, weights = \u001b[1m[0.31919307 0.1119493  0.07301576 0.40402845 0.09181341]\u001b[0m\n",
      "[19:02:55] Blending: iteration \u001b[1m4\u001b[0m: score = \u001b[1m0.7769937425109841\u001b[0m, weights = \u001b[1m[0.31919307 0.1119493  0.07301576 0.40402848 0.09181342]\u001b[0m\n",
      "[19:02:55] Blending: no score update. Terminated\n",
      "\n",
      "[19:02:55] \u001b[1mAutoml preset training completed in 18.93 seconds\u001b[0m\n",
      "\n",
      "[19:02:55] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.31919 * (5 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
      "\t 0.11195 * (5 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) +\n",
      "\t 0.07302 * (5 averaged models Lvl_0_Pipe_1_Mod_1_Tuned_LightGBM) +\n",
      "\t 0.40403 * (5 averaged models Lvl_0_Pipe_1_Mod_2_CatBoost) +\n",
      "\t 0.09181 * (5 averaged models Lvl_0_Pipe_1_Mod_3_Tuned_CatBoost) \n",
      "\n",
      "[2024-10-30 19:02:55,769] - [    END    ] - Fitting TabularLama\n",
      "[2024-10-30 19:02:55,831] - [   SCORE   ] - Train: 0.8641159632538943\n",
      "[2024-10-30 19:02:55,835] - [   SCORE   ] - OOF: 0.7769937425109841\n",
      "[2024-10-30 19:02:55,892] - [   SCORE   ] - Test: 0.7464978448275862\n",
      "[2024-10-30 19:02:55,894] - [   SCORE   ] - Overfit: 13.61 %\n",
      "[2024-10-30 19:02:56,001] - [    END    ] - Working with TabularLama\n",
      "[2024-10-30 19:02:56,003] - [BEST  MODEL] - CatBoostClassification. Best score: 0.7544899425287356 \n",
      "\n",
      "[2024-10-30 19:02:56,006] - [   MODEL   ] - 8 out of 15. TabularLamaUtilized\n",
      "[2024-10-30 19:02:56,007] - [   START   ] - Working with TabularLamaUtilized\n",
      "[2024-10-30 19:02:56,009] - [   START   ] - Fitting TabularLamaUtilized\n",
      "[19:02:56] Start automl \u001b[1mutilizator\u001b[0m with listed constraints:\n",
      "[19:02:56] - time: 60.00 seconds\n",
      "[19:02:56] - CPU: 6 cores\n",
      "[19:02:56] - memory: 16 GB\n",
      "\n",
      "[19:02:56] \u001b[1mIf one preset completes earlier, next preset configuration will be started\u001b[0m\n",
      "\n",
      "[19:02:56] ==================================================\n",
      "[19:02:56] Start 0 automl preset configuration:\n",
      "[19:02:56] \u001b[1mconf_0_sel_type_0.yml\u001b[0m, random state: {'reader_params': {'random_state': 42}, 'nn_params': {'random_state': 42}, 'general_params': {'return_all_predictions': False}}\n",
      "[19:02:56] Stdout logging level is INFO.\n",
      "[19:02:56] Task: binary\n",
      "\n",
      "[19:02:56] Start automl preset with listed constraints:\n",
      "[19:02:56] - time: 60.00 seconds\n",
      "[19:02:56] - CPU: 6 cores\n",
      "[19:02:56] - memory: 16 GB\n",
      "\n",
      "[19:02:56] \u001b[1mTrain data shape: (499, 7)\u001b[0m\n",
      "\n",
      "[19:02:56] Layer \u001b[1m1\u001b[0m train process start. Time left 59.93 secs\n",
      "[19:02:56] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "[19:02:57] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.7680734922114232\u001b[0m\n",
      "[19:02:57] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "[19:02:57] Time left 58.80 secs\n",
      "\n",
      "[19:02:57] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "[19:02:58] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.730220676341366\u001b[0m\n",
      "[19:02:58] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "[19:02:58] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 7.71 secs\n",
      "[19:03:06] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n",
      "[19:03:06] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[19:03:08] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.72007722007722\u001b[0m\n",
      "[19:03:08] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[19:03:08] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n",
      "[19:03:08] Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m0.7780588470243643\u001b[0m\n",
      "[19:03:08] \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n",
      "[19:03:08] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 39.27 secs\n",
      "[19:03:22] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n",
      "[19:03:22] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[19:03:22] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.7736569697776593\u001b[0m\n",
      "[19:03:22] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[19:03:22] Time left 33.08 secs\n",
      "\n",
      "[19:03:22] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[19:03:22] Blending: optimization starts with equal weights and score \u001b[1m0.7755458660631073\u001b[0m\n",
      "[19:03:23] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.7817867128211956\u001b[0m, weights = \u001b[1m[0.17175044 0.0744385  0.         0.45346835 0.3003427 ]\u001b[0m\n",
      "[19:03:23] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.7820529889495407\u001b[0m, weights = \u001b[1m[0.24984062 0.06742018 0.         0.4107138  0.27202538]\u001b[0m\n",
      "[19:03:23] Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.7820529889495407\u001b[0m, weights = \u001b[1m[0.24984062 0.06742018 0.         0.4107138  0.27202538]\u001b[0m\n",
      "[19:03:23] Blending: no score update. Terminated\n",
      "\n",
      "[19:03:23] \u001b[1mAutoml preset training completed in 27.10 seconds\u001b[0m\n",
      "\n",
      "[19:03:23] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.24984 * (5 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
      "\t 0.06742 * (5 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) +\n",
      "\t 0.41071 * (5 averaged models Lvl_0_Pipe_1_Mod_2_CatBoost) +\n",
      "\t 0.27203 * (5 averaged models Lvl_0_Pipe_1_Mod_3_Tuned_CatBoost) \n",
      "\n",
      "[19:03:23] ==================================================\n",
      "[19:03:23] Start 1 automl preset configuration:\n",
      "[19:03:23] \u001b[1mconf_1_sel_type_1.yml\u001b[0m, random state: {'reader_params': {'random_state': 43}, 'nn_params': {'random_state': 43}, 'general_params': {'return_all_predictions': False}}\n",
      "[19:03:23] Stdout logging level is INFO.\n",
      "[19:03:23] Task: binary\n",
      "\n",
      "[19:03:23] Start automl preset with listed constraints:\n",
      "[19:03:23] - time: 32.86 seconds\n",
      "[19:03:23] - CPU: 6 cores\n",
      "[19:03:23] - memory: 16 GB\n",
      "\n",
      "[19:03:23] \u001b[1mTrain data shape: (499, 7)\u001b[0m\n",
      "\n",
      "[19:03:23] Layer \u001b[1m1\u001b[0m train process start. Time left 32.80 secs\n",
      "[19:03:23] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m ...\n",
      "[19:03:24] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m finished. score = \u001b[1m0.7468712554919451\u001b[0m\n",
      "[19:03:24] \u001b[1mLvl_0_Pipe_0_Mod_0_LinearL2\u001b[0m fitting and predicting completed\n",
      "[19:03:24] Time left 31.95 secs\n",
      "\n",
      "[19:03:24] \u001b[1mSelector_LightGBM\u001b[0m fitting and predicting completed\n",
      "[19:03:24] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m ...\n",
      "[19:03:26] Fitting \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m finished. score = \u001b[1m0.7246371987751298\u001b[0m\n",
      "[19:03:26] \u001b[1mLvl_0_Pipe_1_Mod_0_LightGBM\u001b[0m fitting and predicting completed\n",
      "[19:03:26] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ... Time budget is 1.00 secs\n",
      "[19:03:27] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m completed\n",
      "[19:03:27] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m ...\n",
      "[19:03:28] Fitting \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m finished. score = \u001b[1m0.7576554386899215\u001b[0m\n",
      "[19:03:28] \u001b[1mLvl_0_Pipe_1_Mod_1_Tuned_LightGBM\u001b[0m fitting and predicting completed\n",
      "[19:03:28] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m ...\n",
      "[19:03:29] Fitting \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m finished. score = \u001b[1m0.7618243243243243\u001b[0m\n",
      "[19:03:29] \u001b[1mLvl_0_Pipe_1_Mod_2_CatBoost\u001b[0m fitting and predicting completed\n",
      "[19:03:29] Start hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ... Time budget is 18.43 secs\n",
      "[19:03:44] Hyperparameters optimization for \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m completed\n",
      "[19:03:44] Start fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m ...\n",
      "[19:03:45] Fitting \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m finished. score = \u001b[1m0.7689638530155771\u001b[0m\n",
      "[19:03:45] \u001b[1mLvl_0_Pipe_1_Mod_3_Tuned_CatBoost\u001b[0m fitting and predicting completed\n",
      "[19:03:45] Time left 11.03 secs\n",
      "\n",
      "[19:03:45] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[19:03:45] Blending: optimization starts with equal weights and score \u001b[1m0.7744141925176408\u001b[0m\n",
      "[19:03:45] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.7766109705764878\u001b[0m, weights = \u001b[1m[0.17861821 0.22078425 0.21863154 0.         0.38196602]\u001b[0m\n",
      "[19:03:45] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.7768273199307683\u001b[0m, weights = \u001b[1m[0.19903529 0.2011544  0.21784426 0.         0.38196597]\u001b[0m\n",
      "[19:03:45] Blending: iteration \u001b[1m2\u001b[0m: score = \u001b[1m0.7768273199307683\u001b[0m, weights = \u001b[1m[0.1990353  0.20115441 0.21784428 0.         0.381966  ]\u001b[0m\n",
      "[19:03:45] Blending: no score update. Terminated\n",
      "\n",
      "[19:03:45] \u001b[1mAutoml preset training completed in 22.02 seconds\u001b[0m\n",
      "\n",
      "[19:03:45] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 0.19904 * (5 averaged models Lvl_0_Pipe_0_Mod_0_LinearL2) +\n",
      "\t 0.20115 * (5 averaged models Lvl_0_Pipe_1_Mod_0_LightGBM) +\n",
      "\t 0.21784 * (5 averaged models Lvl_0_Pipe_1_Mod_1_Tuned_LightGBM) +\n",
      "\t 0.38197 * (5 averaged models Lvl_0_Pipe_1_Mod_3_Tuned_CatBoost) \n",
      "\n",
      "[19:03:45] ==================================================\n",
      "[19:03:45] Blending: optimization starts with equal weights and score \u001b[1m0.7831347357209427\u001b[0m\n",
      "[19:03:45] Blending: iteration \u001b[1m0\u001b[0m: score = \u001b[1m0.7833178005591799\u001b[0m, weights = \u001b[1m[0.40842158 0.5915784 ]\u001b[0m\n",
      "[19:03:45] Blending: iteration \u001b[1m1\u001b[0m: score = \u001b[1m0.7833178005591799\u001b[0m, weights = \u001b[1m[0.40842158 0.5915784 ]\u001b[0m\n",
      "[19:03:45] Blending: no score update. Terminated\n",
      "\n",
      "[2024-10-30 19:03:45,284] - [    END    ] - Fitting TabularLamaUtilized\n",
      "[2024-10-30 19:03:45,389] - [   SCORE   ] - Train: 0.8649813606710159\n",
      "[2024-10-30 19:03:45,393] - [   SCORE   ] - OOF: 0.7833178005591799\n",
      "[2024-10-30 19:03:45,500] - [   SCORE   ] - Test: 0.7540409482758621\n",
      "[2024-10-30 19:03:45,502] - [   SCORE   ] - Overfit: 12.83 %\n",
      "[2024-10-30 19:03:45,636] - [    END    ] - Working with TabularLamaUtilized\n",
      "[2024-10-30 19:03:45,638] - [BEST  MODEL] - CatBoostClassification. Best score: 0.7544899425287356 \n",
      "\n",
      "[2024-10-30 19:03:45,639] - [   MODEL   ] - 9 out of 15. TabularLamaNN_mlp\n",
      "[2024-10-30 19:03:45,642] - [   START   ] - Working with TabularLamaNN_mlp\n",
      "[2024-10-30 19:03:45,644] - [   START   ] - Fitting TabularLamaNN_mlp\n",
      "[19:03:45] Stdout logging level is INFO.\n",
      "[19:03:45] Task: binary\n",
      "\n",
      "[19:03:45] Start automl preset with listed constraints:\n",
      "[19:03:45] - time: 60.00 seconds\n",
      "[19:03:45] - CPU: 6 cores\n",
      "[19:03:45] - memory: 16 GB\n",
      "\n",
      "[19:03:45] \u001b[1mTrain data shape: (499, 7)\u001b[0m\n",
      "\n",
      "[19:03:45] Layer \u001b[1m1\u001b[0m train process start. Time left 59.94 secs\n",
      "[19:03:45] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_mlp_0\u001b[0m ...\n",
      "[19:03:52] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_mlp_0\u001b[0m finished. score = \u001b[1m0.7158334442817201\u001b[0m\n",
      "[19:03:52] \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_mlp_0\u001b[0m fitting and predicting completed\n",
      "[19:03:52] Time left 53.53 secs\n",
      "\n",
      "[19:03:52] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[19:03:52] \u001b[1mAutoml preset training completed in 6.47 seconds\u001b[0m\n",
      "\n",
      "[19:03:52] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 1.00000 * (5 averaged models Lvl_0_Pipe_0_Mod_0_TorchNN_mlp_0) \n",
      "\n",
      "[2024-10-30 19:03:52,142] - [    END    ] - Fitting TabularLamaNN_mlp\n",
      "[2024-10-30 19:03:53,831] - [   SCORE   ] - Train: 0.750998535481294\n",
      "[2024-10-30 19:03:53,835] - [   SCORE   ] - OOF: 0.7158334442817201\n",
      "[2024-10-30 19:03:55,464] - [   SCORE   ] - Test: 0.6798670977011494\n",
      "[2024-10-30 19:03:55,465] - [   SCORE   ] - Overfit: 9.47 %\n",
      "[2024-10-30 19:03:55,613] - [    END    ] - Working with TabularLamaNN_mlp\n",
      "[2024-10-30 19:03:55,615] - [BEST  MODEL] - CatBoostClassification. Best score: 0.7544899425287356 \n",
      "\n",
      "[2024-10-30 19:03:55,618] - [   MODEL   ] - 10 out of 15. TabularLamaNN_denselight\n",
      "[2024-10-30 19:03:55,620] - [   START   ] - Working with TabularLamaNN_denselight\n",
      "[2024-10-30 19:03:55,622] - [   START   ] - Fitting TabularLamaNN_denselight\n",
      "[19:03:55] Stdout logging level is INFO.\n",
      "[19:03:55] Task: binary\n",
      "\n",
      "[19:03:55] Start automl preset with listed constraints:\n",
      "[19:03:55] - time: 60.00 seconds\n",
      "[19:03:55] - CPU: 6 cores\n",
      "[19:03:55] - memory: 16 GB\n",
      "\n",
      "[19:03:55] \u001b[1mTrain data shape: (499, 7)\u001b[0m\n",
      "\n",
      "[19:03:55] Layer \u001b[1m1\u001b[0m train process start. Time left 59.93 secs\n",
      "[19:03:55] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_denselight_0\u001b[0m ...\n",
      "[19:04:01] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_denselight_0\u001b[0m finished. score = \u001b[1m0.7220077220077221\u001b[0m\n",
      "[19:04:01] \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_denselight_0\u001b[0m fitting and predicting completed\n",
      "[19:04:01] Time left 54.48 secs\n",
      "\n",
      "[19:04:01] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[19:04:01] \u001b[1mAutoml preset training completed in 5.53 seconds\u001b[0m\n",
      "\n",
      "[19:04:01] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 1.00000 * (5 averaged models Lvl_0_Pipe_0_Mod_0_TorchNN_denselight_0) \n",
      "\n",
      "[2024-10-30 19:04:01,181] - [    END    ] - Fitting TabularLamaNN_denselight\n",
      "[2024-10-30 19:04:02,865] - [   SCORE   ] - Train: 0.7607342564239117\n",
      "[2024-10-30 19:04:02,868] - [   SCORE   ] - OOF: 0.7220077220077221\n",
      "[2024-10-30 19:04:04,555] - [   SCORE   ] - Test: 0.6869612068965517\n",
      "[2024-10-30 19:04:04,557] - [   SCORE   ] - Overfit: 9.70 %\n",
      "[2024-10-30 19:04:04,680] - [    END    ] - Working with TabularLamaNN_denselight\n",
      "[2024-10-30 19:04:04,682] - [BEST  MODEL] - CatBoostClassification. Best score: 0.7544899425287356 \n",
      "\n",
      "[2024-10-30 19:04:04,684] - [   MODEL   ] - 11 out of 15. TabularLamaNN_dense\n",
      "[2024-10-30 19:04:04,686] - [   START   ] - Working with TabularLamaNN_dense\n",
      "[2024-10-30 19:04:04,688] - [   START   ] - Fitting TabularLamaNN_dense\n",
      "[19:04:04] Stdout logging level is INFO.\n",
      "[19:04:04] Task: binary\n",
      "\n",
      "[19:04:04] Start automl preset with listed constraints:\n",
      "[19:04:04] - time: 60.00 seconds\n",
      "[19:04:04] - CPU: 6 cores\n",
      "[19:04:04] - memory: 16 GB\n",
      "\n",
      "[19:04:04] \u001b[1mTrain data shape: (499, 7)\u001b[0m\n",
      "\n",
      "[19:04:04] Layer \u001b[1m1\u001b[0m train process start. Time left 59.94 secs\n",
      "[19:04:04] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_dense_0\u001b[0m ...\n",
      "[19:04:13] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_dense_0\u001b[0m finished. score = \u001b[1m0.7367361203568099\u001b[0m\n",
      "[19:04:13] \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_dense_0\u001b[0m fitting and predicting completed\n",
      "[19:04:13] Time left 51.07 secs\n",
      "\n",
      "[19:04:13] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[19:04:13] \u001b[1mAutoml preset training completed in 8.93 seconds\u001b[0m\n",
      "\n",
      "[19:04:13] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 1.00000 * (5 averaged models Lvl_0_Pipe_0_Mod_0_TorchNN_dense_0) \n",
      "\n",
      "[2024-10-30 19:04:13,654] - [    END    ] - Fitting TabularLamaNN_dense\n",
      "[2024-10-30 19:04:15,564] - [   SCORE   ] - Train: 0.8134569298362402\n",
      "[2024-10-30 19:04:15,568] - [   SCORE   ] - OOF: 0.7367361203568099\n",
      "[2024-10-30 19:04:17,391] - [   SCORE   ] - Test: 0.7286278735632183\n",
      "[2024-10-30 19:04:17,393] - [   SCORE   ] - Overfit: 10.43 %\n",
      "[2024-10-30 19:04:18,136] - [    END    ] - Working with TabularLamaNN_dense\n",
      "[2024-10-30 19:04:18,138] - [BEST  MODEL] - CatBoostClassification. Best score: 0.7544899425287356 \n",
      "\n",
      "[2024-10-30 19:04:18,140] - [   MODEL   ] - 12 out of 15. TabularLamaNN_resnet\n",
      "[2024-10-30 19:04:18,142] - [   START   ] - Working with TabularLamaNN_resnet\n",
      "[2024-10-30 19:04:18,147] - [   START   ] - Fitting TabularLamaNN_resnet\n",
      "[19:04:18] Stdout logging level is INFO.\n",
      "[19:04:18] Task: binary\n",
      "\n",
      "[19:04:18] Start automl preset with listed constraints:\n",
      "[19:04:18] - time: 60.00 seconds\n",
      "[19:04:18] - CPU: 6 cores\n",
      "[19:04:18] - memory: 16 GB\n",
      "\n",
      "[19:04:18] \u001b[1mTrain data shape: (499, 7)\u001b[0m\n",
      "\n",
      "[19:04:18] Layer \u001b[1m1\u001b[0m train process start. Time left 59.93 secs\n",
      "[19:04:18] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_resnet_0\u001b[0m ...\n",
      "[19:04:22] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_resnet_0\u001b[0m finished. score = \u001b[1m0.717347889761683\u001b[0m\n",
      "[19:04:22] \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_resnet_0\u001b[0m fitting and predicting completed\n",
      "[19:04:22] Time left 55.38 secs\n",
      "\n",
      "[19:04:22] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[19:04:22] \u001b[1mAutoml preset training completed in 4.62 seconds\u001b[0m\n",
      "\n",
      "[19:04:22] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 1.00000 * (5 averaged models Lvl_0_Pipe_0_Mod_0_TorchNN_resnet_0) \n",
      "\n",
      "[2024-10-30 19:04:22,800] - [    END    ] - Fitting TabularLamaNN_resnet\n",
      "[2024-10-30 19:04:24,492] - [   SCORE   ] - Train: 0.7347972972972974\n",
      "[2024-10-30 19:04:24,496] - [   SCORE   ] - OOF: 0.717347889761683\n",
      "[2024-10-30 19:04:26,191] - [   SCORE   ] - Test: 0.6726831896551724\n",
      "[2024-10-30 19:04:26,193] - [   SCORE   ] - Overfit: 8.45 %\n",
      "[2024-10-30 19:04:26,261] - [    END    ] - Working with TabularLamaNN_resnet\n",
      "[2024-10-30 19:04:26,262] - [BEST  MODEL] - CatBoostClassification. Best score: 0.7544899425287356 \n",
      "\n",
      "[2024-10-30 19:04:26,264] - [   MODEL   ] - 13 out of 15. TabularLamaNN_node\n",
      "[2024-10-30 19:04:26,267] - [   START   ] - Working with TabularLamaNN_node\n",
      "[2024-10-30 19:04:26,269] - [   START   ] - Fitting TabularLamaNN_node\n",
      "[19:04:26] Stdout logging level is INFO.\n",
      "[19:04:26] Task: binary\n",
      "\n",
      "[19:04:26] Start automl preset with listed constraints:\n",
      "[19:04:26] - time: 60.00 seconds\n",
      "[19:04:26] - CPU: 6 cores\n",
      "[19:04:26] - memory: 16 GB\n",
      "\n",
      "[19:04:26] \u001b[1mTrain data shape: (499, 7)\u001b[0m\n",
      "\n",
      "[19:04:26] Layer \u001b[1m1\u001b[0m train process start. Time left 59.94 secs\n",
      "[19:04:26] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_node_0\u001b[0m ...\n",
      "[19:05:42] Time limit exceeded after calculating fold 0\n",
      "\n",
      "[19:05:42] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_node_0\u001b[0m finished. score = \u001b[1m0.7725\u001b[0m\n",
      "[19:05:42] \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_node_0\u001b[0m fitting and predicting completed\n",
      "[19:05:42] Time left -15.72 secs\n",
      "\n",
      "[19:05:42] Time limit exceeded. Last level models will be blended and unused pipelines will be pruned.\n",
      "\n",
      "[19:05:42] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[19:05:42] \u001b[1mAutoml preset training completed in 75.73 seconds\u001b[0m\n",
      "\n",
      "[19:05:42] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 1.00000 * (1 averaged models Lvl_0_Pipe_0_Mod_0_TorchNN_node_0) \n",
      "\n",
      "[2024-10-30 19:05:42,029] - [    END    ] - Fitting TabularLamaNN_node\n",
      "[2024-10-30 19:05:42,843] - [   SCORE   ] - Train: 0.7815204366928505\n",
      "[2024-10-30 19:05:42,846] - [   SCORE   ] - OOF: 0.7725\n",
      "[2024-10-30 19:05:43,364] - [   SCORE   ] - Test: 0.7032147988505746\n",
      "[2024-10-30 19:05:43,366] - [   SCORE   ] - Overfit: 10.02 %\n",
      "[2024-10-30 19:05:43,413] - [    END    ] - Working with TabularLamaNN_node\n",
      "[2024-10-30 19:05:43,415] - [BEST  MODEL] - CatBoostClassification. Best score: 0.7544899425287356 \n",
      "\n",
      "[2024-10-30 19:05:43,418] - [   MODEL   ] - 14 out of 15. TabularLamaNN_autoint\n",
      "[2024-10-30 19:05:43,420] - [   START   ] - Working with TabularLamaNN_autoint\n",
      "[2024-10-30 19:05:43,422] - [   START   ] - Fitting TabularLamaNN_autoint\n",
      "[19:05:43] Stdout logging level is INFO.\n",
      "[19:05:43] Task: binary\n",
      "\n",
      "[19:05:43] Start automl preset with listed constraints:\n",
      "[19:05:43] - time: 60.00 seconds\n",
      "[19:05:43] - CPU: 6 cores\n",
      "[19:05:43] - memory: 16 GB\n",
      "\n",
      "[19:05:43] \u001b[1mTrain data shape: (499, 7)\u001b[0m\n",
      "\n",
      "[19:05:43] Layer \u001b[1m1\u001b[0m train process start. Time left 59.94 secs\n",
      "[19:05:43] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_autoint_0\u001b[0m ...\n",
      "[19:05:59] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_autoint_0\u001b[0m finished. score = \u001b[1m0.7603181999733725\u001b[0m\n",
      "[19:05:59] \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_autoint_0\u001b[0m fitting and predicting completed\n",
      "[19:05:59] Time left 43.83 secs\n",
      "\n",
      "[19:05:59] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[19:05:59] \u001b[1mAutoml preset training completed in 16.17 seconds\u001b[0m\n",
      "\n",
      "[19:05:59] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 1.00000 * (5 averaged models Lvl_0_Pipe_0_Mod_0_TorchNN_autoint_0) \n",
      "\n",
      "[2024-10-30 19:05:59,623] - [    END    ] - Fitting TabularLamaNN_autoint\n",
      "[2024-10-30 19:06:01,518] - [   SCORE   ] - Train: 0.8414658500865397\n",
      "[2024-10-30 19:06:01,521] - [   SCORE   ] - OOF: 0.7603181999733725\n",
      "[2024-10-30 19:06:03,308] - [   SCORE   ] - Test: 0.7326688218390806\n",
      "[2024-10-30 19:06:03,310] - [   SCORE   ] - Overfit: 12.93 %\n",
      "[2024-10-30 19:06:03,735] - [    END    ] - Working with TabularLamaNN_autoint\n",
      "[2024-10-30 19:06:03,736] - [BEST  MODEL] - CatBoostClassification. Best score: 0.7544899425287356 \n",
      "\n",
      "[2024-10-30 19:06:03,738] - [   MODEL   ] - 15 out of 15. TabularLamaNN_fttransformer\n",
      "[2024-10-30 19:06:03,740] - [   START   ] - Working with TabularLamaNN_fttransformer\n",
      "[2024-10-30 19:06:03,742] - [   START   ] - Fitting TabularLamaNN_fttransformer\n",
      "[19:06:03] Stdout logging level is INFO.\n",
      "[19:06:03] Task: binary\n",
      "\n",
      "[19:06:03] Start automl preset with listed constraints:\n",
      "[19:06:03] - time: 60.00 seconds\n",
      "[19:06:03] - CPU: 6 cores\n",
      "[19:06:03] - memory: 16 GB\n",
      "\n",
      "[19:06:03] \u001b[1mTrain data shape: (499, 7)\u001b[0m\n",
      "\n",
      "[19:06:03] Layer \u001b[1m1\u001b[0m train process start. Time left 59.94 secs\n",
      "[19:06:03] Start fitting \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_fttransformer_0\u001b[0m ...\n",
      "[19:06:20] Fitting \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_fttransformer_0\u001b[0m finished. score = \u001b[1m0.7120390094528026\u001b[0m\n",
      "[19:06:20] \u001b[1mLvl_0_Pipe_0_Mod_0_TorchNN_fttransformer_0\u001b[0m fitting and predicting completed\n",
      "[19:06:20] Time left 42.89 secs\n",
      "\n",
      "[19:06:20] \u001b[1mLayer 1 training completed.\u001b[0m\n",
      "\n",
      "[19:06:20] \u001b[1mAutoml preset training completed in 17.12 seconds\u001b[0m\n",
      "\n",
      "[19:06:20] Model description:\n",
      "Final prediction for new objects (level 0) = \n",
      "\t 1.00000 * (5 averaged models Lvl_0_Pipe_0_Mod_0_TorchNN_fttransformer_0) \n",
      "\n",
      "[2024-10-30 19:06:20,890] - [    END    ] - Fitting TabularLamaNN_fttransformer\n",
      "[2024-10-30 19:06:22,816] - [   SCORE   ] - Train: 0.7797230728265211\n",
      "[2024-10-30 19:06:22,820] - [   SCORE   ] - OOF: 0.7120390094528026\n",
      "[2024-10-30 19:06:24,720] - [   SCORE   ] - Test: 0.7070761494252874\n",
      "[2024-10-30 19:06:24,722] - [   SCORE   ] - Overfit: 9.32 %\n",
      "[2024-10-30 19:06:24,988] - [    END    ] - Working with TabularLamaNN_fttransformer\n",
      "[2024-10-30 19:06:24,990] - [BEST  MODEL] - CatBoostClassification. Best score: 0.7544899425287356 \n",
      "\n",
      "yasserh/titanic-dataset 0.7544899425287356 CatBoostClassification\n",
      "  0%|          | 0/18 [07:20<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "from automl.model import AutoML\n",
    "from automl.model.metrics import Accuracy, RocAuc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "for train, test, target_name, dataset_name in get_train_test_datasets(datasets, datasets_path='./datasets', test_size=0.3, random_state=0):\n",
    "    start_time = time.perf_counter()\n",
    "    automl = AutoML(task='classification', n_jobs=6, metric=RocAuc(), tuning_timeout=30)\n",
    "    automl = automl.fit(\n",
    "        train.drop(columns=[target_name,]), train[target_name].to_numpy(), \n",
    "        test.drop(columns=[target_name,]), test[target_name].to_numpy(),\n",
    "    )\n",
    "    train_time = time.perf_counter() - start_time\n",
    "    \n",
    "    test_predictions = automl.predict(test.drop(columns=[target_name,]))\n",
    "    predict_time = time.perf_counter() - start_time - train_time\n",
    "    all_time = train_time + predict_time\n",
    "    \n",
    "    test_score = roc_auc_score(test[target_name], test_predictions[:, 1])\n",
    "    \n",
    "    print(dataset_name, test_score, automl.best_model.name)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_predictions\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_predictions' is not defined"
     ]
    }
   ],
   "source": [
    "train_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
