{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# libs\n",
    "Аналоги:  \n",
    "- https://mlbox.readthedocs.io/en/latest/  \n",
    "- https://lightautoml.readthedocs.io/  \n",
    "- https://automl.github.io/auto-sklearn/master/  \n",
    "\n",
    "Tюнинг:\n",
    "- https://optuna.org/\n",
    "- https://hyperopt.github.io/hyperopt/\n",
    "- https://docs.ray.io/en/latest/tune/index.html \n",
    "- https://oss-vizier.readthedocs.io/en/latest/ \n",
    "\n",
    "Работа с фичами:\n",
    "- https://scikit-learn.org/1.5/modules/feature_selection.html\n",
    "- https://feature-engine.trainindata.com/en/1.7.x/api_doc/selection/index.html\n",
    "- https://github.com/AutoViML/featurewiz\n",
    "- https://github.com/scikit-learn-contrib/boruta_py\n",
    "\n",
    "Прочее:\n",
    "- https://unit8co.github.io/darts/\n",
    "- https://epistasislab.github.io/tpot/  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# datasets\n",
    "Сберовский датасет:\n",
    "- https://huggingface.co/datasets/ai-lab/MBD (14,6 GB, основной датасет)\n",
    "- https://huggingface.co/datasets/ai-lab/MBD-mini (3,38 GB, уменьшенная версия, 10% клиентов из основного датасета)  \n",
    "\n",
    "Kaggle datasets:\n",
    "- https://www.kaggle.com/datasets/yasserh/titanic-dataset\n",
    "- https://www.kaggle.com/datasets/rabieelkharoua/predict-liver-disease-1700-records-dataset\n",
    "- https://www.kaggle.com/datasets/devzohaib/eligibility-prediction-for-loan\n",
    "- https://www.kaggle.com/datasets/deepcontractor/smoke-detection-dataset\n",
    "- https://www.kaggle.com/datasets/stealthtechnologies/employee-attrition-dataset\n",
    "- https://www.kaggle.com/datasets/rabieelkharoua/cancer-prediction-dataset\n",
    "- https://www.kaggle.com/datasets/yasserh/heart-disease-dataset\n",
    "- https://www.kaggle.com/datasets/rabieelkharoua/predict-online-course-engagement-dataset\n",
    "- https://www.kaggle.com/datasets/rabieelkharoua/predicting-hiring-decisions-in-recruitment-data\n",
    "- https://www.kaggle.com/datasets/barun2104/telecom-churn\n",
    "- https://www.kaggle.com/datasets/rabieelkharoua/predicting-manufacturing-defects-dataset\n",
    "- https://www.kaggle.com/datasets/rabieelkharoua/predict-customer-purchase-behavior-dataset\n",
    "- https://www.kaggle.com/datasets/teejmahal20/airline-passenger-satisfaction\n",
    "- https://www.kaggle.com/datasets/dhanushnarayananr/credit-card-fraud\n",
    "- https://www.kaggle.com/datasets/rameshmehta/credit-risk-analysis\n",
    "- https://www.kaggle.com/datasets/marcpaulo/titanic-huge-dataset-1m-passengers\n",
    "- https://www.kaggle.com/datasets/manishtripathi86/fedex-data\n",
    "- https://www.kaggle.com/datasets/ban7002/fraud-challenge-data\n",
    "- https://www.kaggle.com/datasets/ulrikthygepedersen/kickstarter-projects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "\n",
    "import kaggle\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "kaggle.api.authenticate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\n",
    "    {\n",
    "        'link': 'https://www.kaggle.com/datasets/yasserh/titanic-dataset', \n",
    "        'target': 'Survived',\n",
    "        'id_cols': ['PassengerId',],\n",
    "    },\n",
    "    {\n",
    "        'link': 'https://www.kaggle.com/datasets/rabieelkharoua/predict-liver-disease-1700-records-dataset', \n",
    "        'target': 'Diagnosis',\n",
    "    },\n",
    "    {\n",
    "        'link': 'https://www.kaggle.com/datasets/devzohaib/eligibility-prediction-for-loan', \n",
    "        'target': 'Loan_Status',\n",
    "        'id_cols': ['Loan_ID',],\n",
    "    },\n",
    "    {\n",
    "        'link': 'https://www.kaggle.com/datasets/deepcontractor/smoke-detection-dataset', \n",
    "        'target': 'Fire Alarm',\n",
    "        'id_cols': ['index',],\n",
    "    },\n",
    "    {\n",
    "        'link': 'https://www.kaggle.com/datasets/stealthtechnologies/employee-attrition-dataset', \n",
    "        'target': 'Attrition',\n",
    "        'id_cols': ['Employee ID',],\n",
    "    },\n",
    "    {\n",
    "        'link': 'https://www.kaggle.com/datasets/rabieelkharoua/cancer-prediction-dataset', \n",
    "        'target': 'Diagnosis',\n",
    "    },\n",
    "    {\n",
    "        'link': 'https://www.kaggle.com/datasets/yasserh/heart-disease-dataset', \n",
    "        'target': 'target',\n",
    "    },\n",
    "    {\n",
    "        'link': 'https://www.kaggle.com/datasets/rabieelkharoua/predict-online-course-engagement-dataset', \n",
    "        'target': 'CourseCompletion',\n",
    "        'id_cols': ['UserID',],\n",
    "    },\n",
    "    {\n",
    "        'link': 'https://www.kaggle.com/datasets/rabieelkharoua/predicting-hiring-decisions-in-recruitment-data', \n",
    "        'target': 'HiringDecision',\n",
    "    },\n",
    "    {\n",
    "        'link': 'https://www.kaggle.com/datasets/barun2104/telecom-churn', \n",
    "        'target': 'Churn',\n",
    "    },\n",
    "    {\n",
    "        'link': 'https://www.kaggle.com/datasets/rabieelkharoua/predicting-manufacturing-defects-dataset', \n",
    "        'target': 'DefectStatus',\n",
    "    },\n",
    "    {\n",
    "        'link': 'https://www.kaggle.com/datasets/rabieelkharoua/predict-customer-purchase-behavior-dataset',\n",
    "        'target': 'PurchaseStatus',\n",
    "    },\n",
    "    {\n",
    "        'link': 'https://www.kaggle.com/datasets/teejmahal20/airline-passenger-satisfaction', \n",
    "        'target': 'Satisfaction',\n",
    "    },\n",
    "    {\n",
    "        'link': 'https://www.kaggle.com/datasets/dhanushnarayananr/credit-card-fraud', \n",
    "        'target': 'fraud',\n",
    "    },\n",
    "    {\n",
    "        'link': 'https://www.kaggle.com/datasets/rameshmehta/credit-risk-analysis', \n",
    "        'target': 'default_ind',\n",
    "        'id_cols': ['id', 'member_id',],\n",
    "        'time_col': 'issue_d',\n",
    "    },\n",
    "    {\n",
    "        'link': 'https://www.kaggle.com/datasets/marcpaulo/titanic-huge-dataset-1m-passengers', \n",
    "        'target': 'Survived',\n",
    "        'id_cols': ['PassengerId',],\n",
    "    },\n",
    "    # {\n",
    "    #     'link': 'https://www.kaggle.com/datasets/manishtripathi86/fedex-data', \n",
    "    #     'target': 'Delivery_Status',\n",
    "    #     'time_col': 'Year',\n",
    "    # },\n",
    "    {\n",
    "        'link': 'https://www.kaggle.com/datasets/ban7002/fraud-challenge-data', \n",
    "        'target': 'EVENT_LABEL',\n",
    "        'time_col': 'EVENT_TIMESTAMP',\n",
    "    },\n",
    "    # {\n",
    "    #     'link': 'https://www.kaggle.com/datasets/ulrikthygepedersen/kickstarter-projects', \n",
    "    #     'target': 'State',\n",
    "    #     'id_cols': ['ID',],\n",
    "    #     'time_col': 'Launched',\n",
    "    # },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in datasets:\n",
    "    dataset_name = dataset['link'].replace('https://www.kaggle.com/datasets/', '')\n",
    "    dataset_path = Path(f'./datasets/{dataset_name}')\n",
    "    if not dataset_path.exists():\n",
    "        if len(dataset_path.glob('*.csv')) == 0:\n",
    "            kaggle.api.dataset_download_files(dataset_name, path=dataset_path, unzip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_datasets(datasets, datasets_path, test_size=0.3, random_state=0):\n",
    "    from tqdm import tqdm\n",
    "    from pathlib import Path\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    \n",
    "    \n",
    "    for dataset in tqdm(datasets):\n",
    "        dataset_name = dataset['link'].replace('https://www.kaggle.com/datasets/', '')\n",
    "        files = list((Path(datasets_path) / dataset_name).glob('*.csv'))\n",
    "        if len(files) == 1:\n",
    "            dataset_path = files[0]\n",
    "            data = pd.read_csv(dataset_path)\n",
    "            target_name = dataset['target']\n",
    "            data = data.dropna(subset=[target_name])\n",
    "            \n",
    "            if dataset.get('id_cols'):\n",
    "                data = data.drop(columns=[dataset['id_cols']], errors='ignore')\n",
    "\n",
    "            le = LabelEncoder()\n",
    "            data[target_name] = le.fit_transform(data[target_name])\n",
    "            data = data.select_dtypes(include=[np.number]).dropna(how='all', axis='columns').fillna(0)\n",
    "            train_data, test_data = train_test_split(\n",
    "                data, \n",
    "                test_size=test_size, \n",
    "                stratify=data[target_name], \n",
    "                random_state=random_state\n",
    "            )\n",
    "            yield train_data, test_data, target_name, dataset_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Модуль model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## custom metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-11-08 19:11:07]\n",
      "[2024-11-08 19:11:07,240] - [   MODEL    ] - 1 out of 1. CatBoostClassification\n",
      "[2024-11-08 19:11:07,241] - [   START    ] - Working with CatBoostClassification\n",
      "[2024-11-08 19:11:07,242] - [   START    ] - Tuning CatBoostClassification\n",
      "[2024-11-08 19:11:09,508] - [   OPTUNA   ] - Trial 0. New best score 0.746415846191882 with parameters {'boosting_type': 'Plain', 'depth': 6, 'l2_leaf_reg': 190.14286128198324, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'SymmetricTree', 'min_data_in_leaf': 222, 'rsm': 0.7606690070459252, 'subsample': 0.8248435466776274, 'model_size_reg': 4.116898859160489, 'auto_class_weights': None, 'iterations': 369}\n",
      "[2024-11-08 19:11:10,485] - [   OPTUNA   ] - Trial 1. New best score 0.7519777290179026 with parameters {'boosting_type': 'Plain', 'depth': 3, 'l2_leaf_reg': 36.68090197068676, 'bootstrap_type': 'MVS', 'grow_policy': 'Lossguide', 'min_data_in_leaf': 36, 'rsm': 0.5752867891211308, 'subsample': 0.619817105976215, 'model_size_reg': 91.21399684340719, 'auto_class_weights': None, 'max_leaves': 307, 'iterations': 236}\n",
      "[2024-11-08 19:11:15,091] - [   OPTUNA   ] - Trial 5. New best score 0.7522360664717888 with parameters {'boosting_type': 'Plain', 'depth': 4, 'l2_leaf_reg': 1.1044234247204798, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'Depthwise', 'min_data_in_leaf': 92, 'rsm': 0.4695214357150779, 'subsample': 0.9178620555253562, 'model_size_reg': 124.65962536551159, 'auto_class_weights': None, 'iterations': 179}\n",
      "[2024-11-08 19:11:29,962] - [   OPTUNA   ] - Trial 11. New best score 0.758329288525957 with parameters {'boosting_type': 'Plain', 'depth': 4, 'l2_leaf_reg': 1.681410764787914, 'bootstrap_type': 'MVS', 'grow_policy': 'Lossguide', 'min_data_in_leaf': 13, 'rsm': 0.5872672912553432, 'subsample': 0.6453850087358457, 'model_size_reg': 128.50188633556886, 'auto_class_weights': None, 'max_leaves': 455, 'iterations': 111}\n",
      "[2024-11-08 19:11:44,502] - [   OPTUNA   ] - 19 trials completed\n",
      "[2024-11-08 19:11:44,503] - [BEST PARAMS ] - {'iterations': 111, 'one_hot_max_size': 10, 'learning_rate': 0.03, 'thread_count': 12, 'random_state': 42, 'verbose': False, 'allow_writing_files': False, 'od_type': 'Iter', 'od_wait': 100, 'use_best_model': True, 'od_pval': 0, 'boosting_type': 'Plain', 'max_leaves': 455, 'grow_policy': 'Lossguide', 'depth': 4, 'l2_leaf_reg': 1.681410764787914, 'model_size_reg': 128.50188633556886, 'bootstrap_type': 'MVS', 'rsm': 0.5872672912553432, 'subsample': 0.6453850087358457, 'min_data_in_leaf': 13, 'auto_class_weights': None}\n",
      "[2024-11-08 19:11:44,504] - [    END     ] - Tuning CatBoostClassification\n",
      "[2024-11-08 19:11:44,506] - [   START    ] - Fitting CatBoostClassification\n",
      "[2024-11-08 19:11:44,508] - [    FIT     ] - CatBoostClassification fold 0\n",
      "[2024-11-08 19:11:44,570] - [    FIT     ] - CatBoostClassification fold 1\n",
      "[2024-11-08 19:11:44,635] - [    FIT     ] - CatBoostClassification fold 2\n",
      "[2024-11-08 19:11:44,701] - [    FIT     ] - CatBoostClassification fold 3\n",
      "[2024-11-08 19:11:44,770] - [    FIT     ] - CatBoostClassification fold 4\n",
      "[2024-11-08 19:11:44,833] - [    END     ] - Fitting CatBoostClassification\n",
      "[2024-11-08 19:11:44,843] - [   SCORE    ] - Train: 0.8023012552301255\n",
      "[2024-11-08 19:11:44,846] - [   SCORE    ] - OOF: 0.7479406380753139\n",
      "[2024-11-08 19:11:44,853] - [   SCORE    ] - Test: 0.7449249779346867\n",
      "[2024-11-08 19:11:44,855] - [   SCORE    ] - Overfit: 7.15 %\n",
      "[2024-11-08 19:11:44,878] - [    END     ] - Working with CatBoostClassification\n",
      "[2024-11-08 19:11:44,879] - [  NEW BEST  ] - CatBoostClassification. Best score: 0.7449249779346867 \n",
      "\n",
      "100%|##########| 1/1 [00:37<00:00, 37.76s/it]\n"
     ]
    }
   ],
   "source": [
    "from automl.model import AutoML\n",
    "from automl.model.metrics import RocAuc\n",
    "\n",
    "\n",
    "results = []\n",
    "for train, test, target_name, dataset_name in get_train_test_datasets(datasets[:1], datasets_path='./datasets', test_size=0.3, random_state=0):\n",
    "    metric = RocAuc()\n",
    "    start_time = time.perf_counter()\n",
    "    automl = AutoML(task='classification', n_jobs=12, metric=metric, tuning_timeout=30,)\n",
    "    automl = automl.fit(\n",
    "        train.drop(columns=[target_name,]), train[target_name].to_numpy(), \n",
    "        test.drop(columns=[target_name,]), test[target_name].to_numpy(),\n",
    "    )\n",
    "    train_time = time.perf_counter() - start_time\n",
    "    \n",
    "    test_predictions = automl.predict(test.drop(columns=[target_name,]))\n",
    "    predict_time = time.perf_counter() - start_time - train_time\n",
    "    all_time = train_time + predict_time\n",
    "    \n",
    "    test_score = metric(test[target_name], test_predictions)\n",
    "    results.append((dataset_name, test_score, automl.best_model.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('yasserh/titanic-dataset', 0.7724036481318035, 'TabularLama')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
