{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# libs\n",
    "Аналоги:  \n",
    "- https://mlbox.readthedocs.io/en/latest/  \n",
    "- https://lightautoml.readthedocs.io/  \n",
    "- https://automl.github.io/auto-sklearn/master/  \n",
    "\n",
    "Tюнинг:\n",
    "- https://optuna.org/\n",
    "- https://hyperopt.github.io/hyperopt/\n",
    "- https://docs.ray.io/en/latest/tune/index.html \n",
    "- https://oss-vizier.readthedocs.io/en/latest/ \n",
    "\n",
    "Работа с фичами:\n",
    "- https://scikit-learn.org/1.5/modules/feature_selection.html\n",
    "- https://feature-engine.trainindata.com/en/1.7.x/api_doc/selection/index.html\n",
    "- https://github.com/AutoViML/featurewiz\n",
    "- https://github.com/scikit-learn-contrib/boruta_py\n",
    "\n",
    "Прочее:\n",
    "- https://unit8co.github.io/darts/\n",
    "- https://epistasislab.github.io/tpot/  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# datasets\n",
    "Сберовский датасет:\n",
    "- https://huggingface.co/datasets/ai-lab/MBD (14,6 GB, основной датасет)\n",
    "- https://huggingface.co/datasets/ai-lab/MBD-mini (3,38 GB, уменьшенная версия, 10% клиентов из основного датасета)  \n",
    "\n",
    "Kaggle datasets:\n",
    "- https://www.kaggle.com/datasets/yasserh/titanic-dataset\n",
    "- https://www.kaggle.com/datasets/rabieelkharoua/predict-liver-disease-1700-records-dataset\n",
    "- https://www.kaggle.com/datasets/devzohaib/eligibility-prediction-for-loan\n",
    "- https://www.kaggle.com/datasets/deepcontractor/smoke-detection-dataset\n",
    "- https://www.kaggle.com/datasets/stealthtechnologies/employee-attrition-dataset\n",
    "- https://www.kaggle.com/datasets/rabieelkharoua/cancer-prediction-dataset\n",
    "- https://www.kaggle.com/datasets/yasserh/heart-disease-dataset\n",
    "- https://www.kaggle.com/datasets/rabieelkharoua/predict-online-course-engagement-dataset\n",
    "- https://www.kaggle.com/datasets/rabieelkharoua/predicting-hiring-decisions-in-recruitment-data\n",
    "- https://www.kaggle.com/datasets/barun2104/telecom-churn\n",
    "- https://www.kaggle.com/datasets/rabieelkharoua/predicting-manufacturing-defects-dataset\n",
    "- https://www.kaggle.com/datasets/rabieelkharoua/predict-customer-purchase-behavior-dataset\n",
    "- https://www.kaggle.com/datasets/teejmahal20/airline-passenger-satisfaction\n",
    "- https://www.kaggle.com/datasets/dhanushnarayananr/credit-card-fraud\n",
    "- https://www.kaggle.com/datasets/rameshmehta/credit-risk-analysis\n",
    "- https://www.kaggle.com/datasets/marcpaulo/titanic-huge-dataset-1m-passengers\n",
    "- https://www.kaggle.com/datasets/manishtripathi86/fedex-data\n",
    "- https://www.kaggle.com/datasets/ban7002/fraud-challenge-data\n",
    "- https://www.kaggle.com/datasets/ulrikthygepedersen/kickstarter-projects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "\n",
    "import kaggle\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "kaggle.api.authenticate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\n",
    "    {\n",
    "        'link': 'https://www.kaggle.com/datasets/yasserh/titanic-dataset', \n",
    "        'target': 'Survived',\n",
    "        'id_cols': ['PassengerId',],\n",
    "    },\n",
    "    {\n",
    "        'link': 'https://www.kaggle.com/datasets/rabieelkharoua/predict-liver-disease-1700-records-dataset', \n",
    "        'target': 'Diagnosis',\n",
    "    },\n",
    "    {\n",
    "        'link': 'https://www.kaggle.com/datasets/devzohaib/eligibility-prediction-for-loan', \n",
    "        'target': 'Loan_Status',\n",
    "        'id_cols': ['Loan_ID',],\n",
    "    },\n",
    "    {\n",
    "        'link': 'https://www.kaggle.com/datasets/deepcontractor/smoke-detection-dataset', \n",
    "        'target': 'Fire Alarm',\n",
    "        'id_cols': ['index',],\n",
    "    },\n",
    "    {\n",
    "        'link': 'https://www.kaggle.com/datasets/stealthtechnologies/employee-attrition-dataset', \n",
    "        'target': 'Attrition',\n",
    "        'id_cols': ['Employee ID',],\n",
    "    },\n",
    "    {\n",
    "        'link': 'https://www.kaggle.com/datasets/rabieelkharoua/cancer-prediction-dataset', \n",
    "        'target': 'Diagnosis',\n",
    "    },\n",
    "    {\n",
    "        'link': 'https://www.kaggle.com/datasets/yasserh/heart-disease-dataset', \n",
    "        'target': 'target',\n",
    "    },\n",
    "    {\n",
    "        'link': 'https://www.kaggle.com/datasets/rabieelkharoua/predict-online-course-engagement-dataset', \n",
    "        'target': 'CourseCompletion',\n",
    "        'id_cols': ['UserID',],\n",
    "    },\n",
    "    {\n",
    "        'link': 'https://www.kaggle.com/datasets/rabieelkharoua/predicting-hiring-decisions-in-recruitment-data', \n",
    "        'target': 'HiringDecision',\n",
    "    },\n",
    "    {\n",
    "        'link': 'https://www.kaggle.com/datasets/barun2104/telecom-churn', \n",
    "        'target': 'Churn',\n",
    "    },\n",
    "    {\n",
    "        'link': 'https://www.kaggle.com/datasets/rabieelkharoua/predicting-manufacturing-defects-dataset', \n",
    "        'target': 'DefectStatus',\n",
    "    },\n",
    "    {\n",
    "        'link': 'https://www.kaggle.com/datasets/rabieelkharoua/predict-customer-purchase-behavior-dataset',\n",
    "        'target': 'PurchaseStatus',\n",
    "    },\n",
    "    {\n",
    "        'link': 'https://www.kaggle.com/datasets/teejmahal20/airline-passenger-satisfaction', \n",
    "        'target': 'Satisfaction',\n",
    "    },\n",
    "    {\n",
    "        'link': 'https://www.kaggle.com/datasets/dhanushnarayananr/credit-card-fraud', \n",
    "        'target': 'fraud',\n",
    "    },\n",
    "    {\n",
    "        'link': 'https://www.kaggle.com/datasets/rameshmehta/credit-risk-analysis', \n",
    "        'target': 'default_ind',\n",
    "        'id_cols': ['id', 'member_id',],\n",
    "        'time_col': 'issue_d',\n",
    "    },\n",
    "    {\n",
    "        'link': 'https://www.kaggle.com/datasets/marcpaulo/titanic-huge-dataset-1m-passengers', \n",
    "        'target': 'Survived',\n",
    "        'id_cols': ['PassengerId',],\n",
    "    },\n",
    "    # {\n",
    "    #     'link': 'https://www.kaggle.com/datasets/manishtripathi86/fedex-data', \n",
    "    #     'target': 'Delivery_Status',\n",
    "    #     'time_col': 'Year',\n",
    "    # },\n",
    "    {\n",
    "        'link': 'https://www.kaggle.com/datasets/ban7002/fraud-challenge-data', \n",
    "        'target': 'EVENT_LABEL',\n",
    "        'time_col': 'EVENT_TIMESTAMP',\n",
    "    },\n",
    "    # {\n",
    "    #     'link': 'https://www.kaggle.com/datasets/ulrikthygepedersen/kickstarter-projects', \n",
    "    #     'target': 'State',\n",
    "    #     'id_cols': ['ID',],\n",
    "    #     'time_col': 'Launched',\n",
    "    # },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset in datasets:\n",
    "    dataset_name = dataset['link'].replace('https://www.kaggle.com/datasets/', '')\n",
    "    dataset_path = Path(f'./datasets/{dataset_name}')\n",
    "    if not dataset_path.exists():\n",
    "        if len(dataset_path.glob('*.csv')) == 0:\n",
    "            kaggle.api.dataset_download_files(dataset_name, path=dataset_path, unzip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_datasets(datasets, datasets_path, test_size=0.3, random_state=0):\n",
    "    from tqdm import tqdm\n",
    "    from pathlib import Path\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    \n",
    "    \n",
    "    for dataset in tqdm(datasets):\n",
    "        dataset_name = dataset['link'].replace('https://www.kaggle.com/datasets/', '')\n",
    "        files = list((Path(datasets_path) / dataset_name).glob('*.csv'))\n",
    "        if len(files) == 1:\n",
    "            dataset_path = files[0]\n",
    "            data = pd.read_csv(dataset_path)\n",
    "            target_name = dataset['target']\n",
    "            data = data.dropna(subset=[target_name])\n",
    "            \n",
    "            if dataset.get('id_cols'):\n",
    "                data = data.drop(columns=[dataset['id_cols']], errors='ignore')\n",
    "\n",
    "            le = LabelEncoder()\n",
    "            data[target_name] = le.fit_transform(data[target_name])\n",
    "            data = data.select_dtypes(include=[np.number]).dropna(how='all', axis='columns').fillna(0)\n",
    "            train_data, test_data = train_test_split(\n",
    "                data, \n",
    "                test_size=test_size, \n",
    "                stratify=data[target_name], \n",
    "                random_state=random_state\n",
    "            )\n",
    "            yield train_data, test_data, target_name, dataset_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Модуль model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sklearn metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-02-14 13:19:03,772] - [   MODEL    ] - 1 out of 10. type\n",
      "[2025-02-14 13:19:03,774] - [   START    ] - Working with type\n",
      "[2025-02-14 13:19:03,775] - [   START    ] - Tuning type\n",
      "[2025-02-14 13:19:04,893] - [   OPTUNA   ] - Trial 0. New best score 0.7167475779632835 with parameters {'max_iter': 8277, 'fit_intercept': True, 'C': 1.8590843630169627, 'solver': 'saga', 'penalty': 'elasticnet', 'l1_ratio': 0.9636627605010293}\n",
      "[2025-02-14 13:19:05,955] - [   OPTUNA   ] - Trial 1. New best score 0.7170224127775919 with parameters {'max_iter': 5813, 'fit_intercept': True, 'C': 2.5601615250028704, 'solver': 'saga', 'penalty': 'none'}\n",
      "[2025-02-14 13:19:06,970] - [   OPTUNA   ] - Trial 2. New best score 0.7197683219169781 with parameters {'max_iter': 12506, 'fit_intercept': False, 'C': 744.2349368719797, 'solver': 'saga', 'penalty': 'none'}\n",
      "[2025-02-14 13:19:09,056] - [   OPTUNA   ] - Trial 4. New best score 0.7198240251256768 with parameters {'max_iter': 8570, 'fit_intercept': False, 'C': 4.705159350400544, 'solver': 'saga', 'penalty': 'l2'}\n",
      "[2025-02-14 13:19:14,521] - [   OPTUNA   ] - 12 trials completed\n",
      "[2025-02-14 13:19:14,522] - [BEST PARAMS ] - {'random_state': 0, 'n_jobs': 12, 'verbose': 0, 'max_iter': 8570, 'fit_intercept': False, 'C': 4.705159350400544, 'solver': 'saga', 'penalty': 'l2', 'time_series': False, 'model_type': 'classification', 'n_splits': 5, 'name': 'type', 'eval_metric': 'custom_metric'}\n",
      "[2025-02-14 13:19:14,524] - [    END     ] - Tuning type\n",
      "[2025-02-14 13:19:14,525] - [   START    ] - Fitting type\n",
      "[2025-02-14 13:19:15,593] - [    END     ] - Fitting type\n",
      "[2025-02-14 13:19:15,605] - [   SCORE    ] - Train: 0.7350069735006973\n",
      "[2025-02-14 13:19:15,609] - [   SCORE    ] - OOF: 0.7152850418410043\n",
      "[2025-02-14 13:19:15,618] - [   SCORE    ] - Test: 0.7058546631362166\n",
      "[2025-02-14 13:19:15,619] - [   SCORE    ] - Overfit: 3.97 %\n",
      "[2025-02-14 13:19:15,647] - [    END     ] - Working with type\n",
      "[2025-02-14 13:19:15,648] - [  NEW BEST  ] - type. Best score: 0.7058546631362166 \n",
      "\n",
      "[2025-02-14 13:19:15,649] - [   MODEL    ] - 2 out of 10. ABCMeta\n",
      "[2025-02-14 13:19:15,650] - [   START    ] - Working with ABCMeta\n",
      "[2025-02-14 13:19:15,651] - [   START    ] - Tuning ABCMeta\n",
      "[2025-02-14 13:19:20,433] - [   OPTUNA   ] - Trial 0. New best score 0.7199979972901305 with parameters {'n_estimators': 553, 'max_depth': 12, 'min_samples_split': 0.12055267521432877, 'min_samples_leaf': 0.10897663659937938, 'max_features': 0.4812893194050143, 'bootstrap': True, 'max_samples': 0.892855270774259, 'oob_score': True, 'criterion': 'gini', 'class_weight': 'balanced_subsample'}\n",
      "[2025-02-14 13:19:24,693] - [   OPTUNA   ] - Trial 2. New best score 0.7268781085935341 with parameters {'n_estimators': 644, 'max_depth': 4, 'min_samples_split': 0.1889337834099168, 'min_samples_leaf': 0.10436966435001434, 'max_features': 0.4731957459914713, 'bootstrap': False, 'criterion': 'entropy', 'class_weight': 'balanced_subsample'}\n",
      "[2025-02-14 13:19:27,894] - [   OPTUNA   ] - 4 trials completed\n",
      "[2025-02-14 13:19:27,895] - [BEST PARAMS ] - {'random_state': 0, 'n_jobs': 12, 'verbose': 0, 'n_estimators': 644, 'max_depth': 4, 'min_samples_split': 0.1889337834099168, 'min_samples_leaf': 0.10436966435001434, 'max_features': 0.4731957459914713, 'bootstrap': False, 'criterion': 'entropy', 'class_weight': 'balanced_subsample', 'time_series': False, 'model_type': 'classification', 'n_splits': 5, 'name': 'ABCMeta', 'eval_metric': 'custom_metric'}\n",
      "[2025-02-14 13:19:27,896] - [    END     ] - Tuning ABCMeta\n",
      "[2025-02-14 13:19:27,897] - [   START    ] - Fitting ABCMeta\n",
      "[2025-02-14 13:19:37,637] - [    END     ] - Fitting ABCMeta\n",
      "[2025-02-14 13:19:40,183] - [   SCORE    ] - Train: 0.7630698657601115\n",
      "[2025-02-14 13:19:40,186] - [   SCORE    ] - OOF: 0.7215611924686192\n",
      "[2025-02-14 13:19:42,322] - [   SCORE    ] - Test: 0.7107384524860253\n",
      "[2025-02-14 13:19:42,324] - [   SCORE    ] - Overfit: 6.86 %\n",
      "[2025-02-14 13:19:42,343] - [    END     ] - Working with ABCMeta\n",
      "[2025-02-14 13:19:42,344] - [  NEW BEST  ] - ABCMeta. Best score: 0.7107384524860253 \n",
      "\n",
      "[2025-02-14 13:19:42,345] - [   MODEL    ] - 3 out of 10. ABCMeta\n",
      "[2025-02-14 13:19:42,346] - [   START    ] - Working with ABCMeta\n",
      "[2025-02-14 13:19:42,347] - [   START    ] - Tuning ABCMeta\n",
      "[2025-02-14 13:19:47,109] - [   OPTUNA   ] - Trial 0. New best score 0.7047847344424893 with parameters {'n_estimators': 553, 'max_depth': 12, 'min_samples_split': 0.12055267521432877, 'min_samples_leaf': 0.10897663659937938, 'max_features': 0.4812893194050143, 'bootstrap': True, 'max_samples': 0.892855270774259, 'oob_score': True, 'criterion': 'gini', 'class_weight': 'balanced_subsample'}\n",
      "[2025-02-14 13:19:47,510] - [   OPTUNA   ] - Trial 1. New best score 0.71425003817571 with parameters {'n_estimators': 80, 'max_depth': 3, 'min_samples_split': 0.004043679488065144, 'min_samples_leaf': 0.1665239691095876, 'max_features': 0.8003410758548655, 'bootstrap': False, 'criterion': 'gini', 'class_weight': 'balanced'}\n",
      "[2025-02-14 13:19:53,118] - [   OPTUNA   ] - 4 trials completed\n",
      "[2025-02-14 13:19:53,119] - [BEST PARAMS ] - {'random_state': 0, 'n_jobs': 12, 'verbose': 0, 'n_estimators': 80, 'max_depth': 3, 'min_samples_split': 0.004043679488065144, 'min_samples_leaf': 0.1665239691095876, 'max_features': 0.8003410758548655, 'bootstrap': False, 'criterion': 'gini', 'class_weight': 'balanced', 'time_series': False, 'model_type': 'classification', 'n_splits': 5, 'name': 'ABCMeta', 'eval_metric': 'custom_metric'}\n",
      "[2025-02-14 13:19:53,120] - [    END     ] - Tuning ABCMeta\n",
      "[2025-02-14 13:19:53,121] - [   START    ] - Fitting ABCMeta\n",
      "[2025-02-14 13:19:54,349] - [    END     ] - Fitting ABCMeta\n",
      "[2025-02-14 13:19:54,717] - [   SCORE    ] - Train: 0.7313513336820083\n",
      "[2025-02-14 13:19:54,720] - [   SCORE    ] - OOF: 0.6957919281729429\n",
      "[2025-02-14 13:19:55,007] - [   SCORE    ] - Test: 0.7117975875257428\n",
      "[2025-02-14 13:19:55,008] - [   SCORE    ] - Overfit: 2.67 %\n",
      "[2025-02-14 13:19:55,020] - [    END     ] - Working with ABCMeta\n",
      "[2025-02-14 13:19:55,021] - [  NEW BEST  ] - ABCMeta. Best score: 0.7117975875257428 \n",
      "\n",
      "[2025-02-14 13:19:55,022] - [   MODEL    ] - 4 out of 10. CatBoostClassification\n",
      "[2025-02-14 13:19:55,023] - [   START    ] - Working with CatBoostClassification\n",
      "[2025-02-14 13:19:55,024] - [   START    ] - Tuning CatBoostClassification\n",
      "[2025-02-14 13:20:02,038] - [   OPTUNA   ] - Trial 0. New best score 0.574680255914151 with parameters {'boosting_type': 'Plain', 'depth': 9, 'l2_leaf_reg': 143.0378732744839, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'Depthwise', 'min_data_in_leaf': 229, 'rsm': 0.9781976563006176, 'subsample': 0.6300649112954666, 'model_size_reg': 158.3450076165329, 'auto_class_weights': None, 'iterations': 524}\n",
      "[2025-02-14 13:20:13,262] - [   OPTUNA   ] - 2 trials completed\n",
      "[2025-02-14 13:20:13,264] - [BEST PARAMS ] - {'iterations': 524, 'thread_count': 12, 'logging_level': 'Silent', 'task_type': 'CPU', 'od_type': 'Iter', 'od_wait': 100, 'random_state': 0, 'od_pval': None, 'cat_features': [], 'boosting_type': 'Plain', 'depth': 9, 'l2_leaf_reg': 143.0378732744839, 'bootstrap_type': 'Bernoulli', 'grow_policy': 'Depthwise', 'min_data_in_leaf': 229, 'rsm': 0.9781976563006176, 'subsample': 0.6300649112954666, 'model_size_reg': 158.3450076165329, 'auto_class_weights': None, 'time_series': False, 'model_type': 'classification', 'n_splits': 5, 'name': 'CatBoostClassification', 'eval_metric': None}\n",
      "[2025-02-14 13:20:13,265] - [    END     ] - Tuning CatBoostClassification\n",
      "[2025-02-14 13:20:13,266] - [   START    ] - Fitting CatBoostClassification\n",
      "[2025-02-14 13:20:26,031] - [    END     ] - Fitting CatBoostClassification\n",
      "[2025-02-14 13:20:26,104] - [   SCORE    ] - Train: 0.7763031729428173\n",
      "[2025-02-14 13:20:26,107] - [   SCORE    ] - OOF: 0.7352793758716876\n",
      "[2025-02-14 13:20:26,121] - [   SCORE    ] - Test: 0.7280376581347456\n",
      "[2025-02-14 13:20:26,122] - [   SCORE    ] - Overfit: 6.22 %\n",
      "[2025-02-14 13:20:26,143] - [    END     ] - Working with CatBoostClassification\n",
      "[2025-02-14 13:20:26,145] - [  NEW BEST  ] - CatBoostClassification. Best score: 0.7280376581347456 \n",
      "\n",
      "[2025-02-14 13:20:26,146] - [   MODEL    ] - 5 out of 10. XGBClassification\n",
      "[2025-02-14 13:20:26,147] - [   START    ] - Working with XGBClassification\n",
      "[2025-02-14 13:20:26,150] - [   START    ] - Tuning XGBClassification\n",
      "[2025-02-14 13:20:58,801] - [   OPTUNA   ] - Trial 0. New best score 0.6239624877687422 with parameters {'max_depth': 9, 'grow_policy': 'depthwise', 'max_leaves': 284, 'gamma': 8.473095986778095, 'subsample': 0.6813047017599905, 'colsample_bytree': 0.49382849013642327, 'colsample_bylevel': 0.9025957007038717, 'reg_lambda': 9.636627605010293, 'reg_alpha': 3.8344151882577773, 'min_child_weight': 16, 'class_weight': 'balanced', 'num_boost_round': 103}\n",
      "[2025-02-14 13:20:58,803] - [   OPTUNA   ] - 1 trials completed\n",
      "[2025-02-14 13:20:58,805] - [BEST PARAMS ] - {'nthread': 12, 'device': 'cpu', 'objective': 'binary:logistic', 'seed': 0, 'verbosity': 0, 'num_boost_round': 103, 'early_stopping_rounds': 100, 'class_weight': 'balanced', 'scale_pos_weight': 1.612565445026178, 'max_depth': 9, 'grow_policy': 'depthwise', 'max_leaves': 284, 'gamma': 8.473095986778095, 'subsample': 0.6813047017599905, 'colsample_bytree': 0.49382849013642327, 'colsample_bylevel': 0.9025957007038717, 'reg_lambda': 9.636627605010293, 'reg_alpha': 3.8344151882577773, 'min_child_weight': 16, 'time_series': False, 'model_type': 'classification', 'n_splits': 5, 'name': 'XGBClassification', 'eval_metric': None}\n",
      "[2025-02-14 13:20:58,805] - [    END     ] - Tuning XGBClassification\n",
      "[2025-02-14 13:20:58,806] - [   START    ] - Fitting XGBClassification\n",
      "[2025-02-14 13:21:51,341] - [    END     ] - Fitting XGBClassification\n",
      "[2025-02-14 13:21:51,478] - [   SCORE    ] - Train: 0.7221495815899581\n",
      "[2025-02-14 13:21:51,481] - [   SCORE    ] - OOF: 0.706584510111576\n",
      "[2025-02-14 13:21:51,611] - [   SCORE    ] - Test: 0.6972050603118565\n",
      "[2025-02-14 13:21:51,612] - [   SCORE    ] - Overfit: 3.45 %\n",
      "[2025-02-14 13:21:51,622] - [    END     ] - Working with XGBClassification\n",
      "[2025-02-14 13:21:51,623] - [BEST  MODEL ] - CatBoostClassification. Best score: 0.7280376581347456 \n",
      "\n",
      "[2025-02-14 13:21:51,625] - [   MODEL    ] - 6 out of 10. LightGBMClassification\n",
      "[2025-02-14 13:21:51,626] - [   START    ] - Working with LightGBMClassification\n",
      "[2025-02-14 13:21:51,627] - [   START    ] - Tuning LightGBMClassification\n",
      "[2025-02-14 13:21:54,192] - [   OPTUNA   ] - Trial 0. New best score 0.6543375586051408 with parameters {'max_depth': 9, 'num_leaves': 369, 'min_data_in_leaf': 155, 'bagging_fraction': 0.7724415914984484, 'bagging_freq': 10, 'feature_fraction': 0.7875364678399936, 'lambda_l1': 4.375872112626925, 'lambda_l2': 8.917730007820797, 'min_gain_to_split': 19.273255210020587, 'is_unbalance': 'false', 'num_iterations': 2}\n",
      "[2025-02-14 13:21:57,110] - [   OPTUNA   ] - Trial 1. New best score 0.652331262835457 with parameters {'max_depth': 9, 'num_leaves': 295, 'min_data_in_leaf': 237, 'bagging_fraction': 0.5355180290989434, 'bagging_freq': 0, 'feature_fraction': 0.41213103846419546, 'lambda_l1': 8.32619845547938, 'lambda_l2': 7.781567509498505, 'min_gain_to_split': 17.400242964936382, 'is_unbalance': 'true', 'num_iterations': 4}\n",
      "[2025-02-14 13:22:06,381] - [   OPTUNA   ] - Trial 2. New best score 0.6152687456759642 with parameters {'max_depth': 8, 'num_leaves': 402, 'min_data_in_leaf': 31, 'bagging_fraction': 0.819960510663762, 'bagging_freq': 0, 'feature_fraction': 0.9668013502297503, 'lambda_l1': 5.218483217500717, 'lambda_l2': 4.146619399905235, 'min_gain_to_split': 5.29111224209254, 'is_unbalance': 'true', 'num_iterations': 14}\n",
      "[2025-02-14 13:22:06,384] - [   OPTUNA   ] - 3 trials completed\n",
      "[2025-02-14 13:22:06,386] - [BEST PARAMS ] - {'num_iterations': 14, 'num_threads': 12, 'seed': 0, 'verbosity': -1, 'device_type': 'cpu', 'early_stopping_round': 100, 'early_stopping_min_delta': 0.0001, 'objective': 'binary', 'metric': '', 'max_depth': 8, 'num_leaves': 402, 'min_data_in_leaf': 31, 'bagging_fraction': 0.819960510663762, 'bagging_freq': 0, 'feature_fraction': 0.9668013502297503, 'lambda_l1': 5.218483217500717, 'lambda_l2': 4.146619399905235, 'min_gain_to_split': 5.29111224209254, 'is_unbalance': 'true', 'time_series': False, 'model_type': 'classification', 'n_splits': 5, 'name': 'LightGBMClassification', 'eval_metric': None}\n",
      "[2025-02-14 13:22:06,387] - [    END     ] - Tuning LightGBMClassification\n",
      "[2025-02-14 13:22:06,388] - [   START    ] - Fitting LightGBMClassification\n",
      "[2025-02-14 13:22:06,742] - [    END     ] - Fitting LightGBMClassification\n",
      "[2025-02-14 13:22:06,780] - [   SCORE    ] - Train: 0.7379489191073918\n",
      "[2025-02-14 13:22:06,785] - [   SCORE    ] - OOF: 0.7106051691073919\n",
      "[2025-02-14 13:22:07,055] - [   SCORE    ] - Test: 0.7021182700794352\n",
      "[2025-02-14 13:22:07,057] - [   SCORE    ] - Overfit: 4.86 %\n",
      "[2025-02-14 13:22:07,084] - [    END     ] - Working with LightGBMClassification\n",
      "[2025-02-14 13:22:07,087] - [BEST  MODEL ] - CatBoostClassification. Best score: 0.7280376581347456 \n",
      "\n",
      "[2025-02-14 13:22:07,088] - [   MODEL    ] - 7 out of 10. TabularLama\n",
      "[2025-02-14 13:22:07,090] - [   START    ] - Working with TabularLama\n",
      "[2025-02-14 13:22:07,093] - [   START    ] - Fitting TabularLama\n",
      "[2025-02-14 13:23:04,004] - [    END     ] - Fitting TabularLama\n",
      "[2025-02-14 13:23:04,148] - [   SCORE    ] - Train: 0.8670022663877266\n",
      "[2025-02-14 13:23:04,153] - [   SCORE    ] - OOF: 0.7491883116883116\n",
      "[2025-02-14 13:23:04,337] - [   SCORE    ] - Test: 0.7622830244189468\n",
      "[2025-02-14 13:23:04,347] - [   SCORE    ] - Overfit: 12.08 %\n",
      "[2025-02-14 13:23:04,361] - [    END     ] - Working with TabularLama\n",
      "[2025-02-14 13:23:04,363] - [  NEW BEST  ] - TabularLama. Best score: 0.7622830244189468 \n",
      "\n",
      "[2025-02-14 13:23:04,365] - [   MODEL    ] - 8 out of 10. TabularLamaUtilized\n",
      "[2025-02-14 13:23:04,368] - [   START    ] - Working with TabularLamaUtilized\n",
      "[2025-02-14 13:23:04,369] - [   START    ] - Fitting TabularLamaUtilized\n",
      "[2025-02-14 13:23:19,432] - [    END     ] - Fitting TabularLamaUtilized\n",
      "[2025-02-14 13:23:19,651] - [   SCORE    ] - Train: 0.886408211297071\n",
      "[2025-02-14 13:23:19,672] - [   SCORE    ] - OOF: 0.7629609048117154\n",
      "[2025-02-14 13:23:19,902] - [   SCORE    ] - Test: 0.7609885260370697\n",
      "[2025-02-14 13:23:19,903] - [   SCORE    ] - Overfit: 14.15 %\n",
      "[2025-02-14 13:23:19,917] - [    END     ] - Working with TabularLamaUtilized\n",
      "[2025-02-14 13:23:19,927] - [BEST  MODEL ] - TabularLama. Best score: 0.7622830244189468 \n",
      "\n",
      "[2025-02-14 13:23:19,928] - [   MODEL    ] - 9 out of 10. Stacker\n",
      "[2025-02-14 13:23:19,934] - [   START    ] - Working with Stacker\n",
      "[2025-02-14 13:23:19,935] - [   START    ] - Tuning Stacker\n",
      "[2025-02-14 13:23:21,559] - [   OPTUNA   ] - Trial 0. New best score 0.6304636383507742 with parameters {'max_depth': 9, 'num_leaves': 369, 'min_data_in_leaf': 155, 'bagging_fraction': 0.7724415914984484, 'bagging_freq': 10, 'feature_fraction': 0.7875364678399936, 'lambda_l1': 4.375872112626925, 'lambda_l2': 8.917730007820797, 'min_gain_to_split': 19.273255210020587, 'is_unbalance': 'false', 'num_iterations': 5}\n",
      "[2025-02-14 13:23:24,245] - [   OPTUNA   ] - Trial 1. New best score 0.6139789169720162 with parameters {'max_depth': 9, 'num_leaves': 295, 'min_data_in_leaf': 237, 'bagging_fraction': 0.5355180290989434, 'bagging_freq': 0, 'feature_fraction': 0.41213103846419546, 'lambda_l1': 8.32619845547938, 'lambda_l2': 7.781567509498505, 'min_gain_to_split': 17.400242964936382, 'is_unbalance': 'true', 'num_iterations': 11}\n",
      "[2025-02-14 13:23:28,189] - [   OPTUNA   ] - Trial 2. New best score 0.5846950336343075 with parameters {'max_depth': 8, 'num_leaves': 402, 'min_data_in_leaf': 31, 'bagging_fraction': 0.819960510663762, 'bagging_freq': 0, 'feature_fraction': 0.9668013502297503, 'lambda_l1': 5.218483217500717, 'lambda_l2': 4.146619399905235, 'min_gain_to_split': 5.29111224209254, 'is_unbalance': 'true', 'num_iterations': 19}\n",
      "[2025-02-14 13:23:36,798] - [   OPTUNA   ] - 4 trials completed\n",
      "[2025-02-14 13:23:36,799] - [BEST PARAMS ] - {'num_iterations': 19, 'num_threads': 12, 'seed': 0, 'verbosity': -1, 'device_type': 'cpu', 'early_stopping_round': 100, 'early_stopping_min_delta': 0.0001, 'objective': 'binary', 'metric': '', 'max_depth': 8, 'num_leaves': 402, 'min_data_in_leaf': 31, 'bagging_fraction': 0.819960510663762, 'bagging_freq': 0, 'feature_fraction': 0.9668013502297503, 'lambda_l1': 5.218483217500717, 'lambda_l2': 4.146619399905235, 'min_gain_to_split': 5.29111224209254, 'is_unbalance': 'true', 'time_series': False, 'model_type': 'classification', 'n_splits': 5, 'name': 'Stacker', 'eval_metric': None}\n",
      "[2025-02-14 13:23:36,802] - [    END     ] - Tuning Stacker\n",
      "[2025-02-14 13:23:36,804] - [   START    ] - Fitting Stacker\n",
      "[2025-02-14 13:23:36,971] - [    END     ] - Fitting Stacker\n",
      "[2025-02-14 13:23:36,981] - [   SCORE    ] - Train: 0.776619159693166\n",
      "[2025-02-14 13:23:37,017] - [   SCORE    ] - OOF: 0.751868680264993\n",
      "[2025-02-14 13:23:37,160] - [   SCORE    ] - Test: 0.743924683730509\n",
      "[2025-02-14 13:23:37,161] - [   SCORE    ] - Overfit: 4.21 %\n",
      "[2025-02-14 13:23:37,182] - [    END     ] - Working with Stacker\n",
      "[2025-02-14 13:23:37,194] - [BEST  MODEL ] - TabularLama. Best score: 0.7622830244189468 \n",
      "\n",
      "[2025-02-14 13:23:37,201] - [   MODEL    ] - 10 out of 10. Blender\n",
      "[2025-02-14 13:23:37,203] - [   START    ] - Working with Blender\n",
      "[2025-02-14 13:23:37,205] - [   START    ] - Tuning Blender\n",
      "  0%|          | 0/17 [04:33<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 24\u001b[0m\n\u001b[1;32m      8\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[1;32m      9\u001b[0m automl \u001b[38;5;241m=\u001b[39m AutoML(\n\u001b[1;32m     10\u001b[0m     task\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclassification\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     11\u001b[0m     use_preprocessing_pipeline\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     22\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     23\u001b[0m     )\n\u001b[0;32m---> 24\u001b[0m automl \u001b[38;5;241m=\u001b[39m \u001b[43mautoml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtarget_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtarget_name\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtarget_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtarget_name\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_numpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauto_model_fit_kwargs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtuning_timeout\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m train_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter() \u001b[38;5;241m-\u001b[39m start_time\n\u001b[1;32m     33\u001b[0m test_predictions \u001b[38;5;241m=\u001b[39m automl\u001b[38;5;241m.\u001b[39mpredict(test\u001b[38;5;241m.\u001b[39mdrop(columns\u001b[38;5;241m=\u001b[39m[target_name,]))\n",
      "File \u001b[0;32m/workspaces/automl/src/automl/main.py:219\u001b[0m, in \u001b[0;36mAutoML.fit\u001b[0;34m(self, X_train, y_train, X_test, y_test, max_obs_for_preproc, auto_model_fit_kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m     categorical_features \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mintersect1d(\n\u001b[1;32m    215\u001b[0m         categorical_features, X_train\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m    216\u001b[0m     )\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m    218\u001b[0m \u001b[38;5;66;03m# fit the AutoModel\u001b[39;00m\n\u001b[0;32m--> 219\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mauto_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcategorical_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcategorical_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mauto_model_fit_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m/workspaces/automl/src/automl/model/main.py:197\u001b[0m, in \u001b[0;36mAutoModel.fit\u001b[0;34m(self, X, y, Xs_test, ys_test, tuning_timeout, categorical_features, save_models, save_params, save_oof, save_test)\u001b[0m\n\u001b[1;32m    194\u001b[0m log\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWorking with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, msg_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    196\u001b[0m \u001b[38;5;66;03m# tune the model\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtune\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_train_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtuning_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcategorical_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;66;03m# fit the tuned model and obtain out of fold predictions\u001b[39;00m\n\u001b[1;32m    204\u001b[0m oof_preds \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m    205\u001b[0m     x_train_iter, y, categorical_feature\u001b[38;5;241m=\u001b[39mcategorical_features\n\u001b[1;32m    206\u001b[0m )\n",
      "File \u001b[0;32m/workspaces/automl/src/automl/model/blender.py:294\u001b[0m, in \u001b[0;36mCoordDescBlender.tune\u001b[0;34m(self, X, y, timeout, categorical_feature)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights[idx] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    292\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m--> 294\u001b[0m opt_res \u001b[38;5;241m=\u001b[39m \u001b[43mminimize_scalar\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_objective\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# self._get_scorer(splitted_preds, weights_idx, candidate),\u001b[39;49;00m\n\u001b[1;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mBounded\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdisp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaxiter\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_inner_iters\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    303\u001b[0m weights[idx] \u001b[38;5;241m=\u001b[39m opt_res\u001b[38;5;241m.\u001b[39mx\n\u001b[1;32m    304\u001b[0m weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madjust_weights(weights, idx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_thresh)\n",
      "File \u001b[0;32m/workspaces/automl/.venv/lib/python3.8/site-packages/scipy/optimize/_minimize.py:913\u001b[0m, in \u001b[0;36mminimize_scalar\u001b[0;34m(fun, bracket, bounds, args, method, tol, options)\u001b[0m\n\u001b[1;32m    910\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m bounds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    911\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe `bounds` parameter is mandatory for \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    912\u001b[0m                          \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmethod `bounded`.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m--> 913\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_minimize_scalar_bounded\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgolden\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    915\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _minimize_scalar_golden(fun, bracket, args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[0;32m/workspaces/automl/.venv/lib/python3.8/site-packages/scipy/optimize/_optimize.py:2213\u001b[0m, in \u001b[0;36m_minimize_scalar_bounded\u001b[0;34m(func, bounds, args, xatol, maxiter, disp, **unknown_options)\u001b[0m\n\u001b[1;32m   2211\u001b[0m rat \u001b[38;5;241m=\u001b[39m e \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m   2212\u001b[0m x \u001b[38;5;241m=\u001b[39m xf\n\u001b[0;32m-> 2213\u001b[0m fx \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2214\u001b[0m num \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2215\u001b[0m fmin_data \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1\u001b[39m, xf, fx)\n",
      "File \u001b[0;32m/workspaces/automl/src/automl/model/blender.py:261\u001b[0m, in \u001b[0;36mCoordDescBlender._objective\u001b[0;34m(self, weight, weights, X, y, idx)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_pred\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m y_pred\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m    258\u001b[0m     \u001b[38;5;66;03m# binary case\u001b[39;00m\n\u001b[1;32m    259\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m y_pred[:, \u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m--> 261\u001b[0m metric \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscorer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m*\u001b[39m metric \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscorer\u001b[38;5;241m.\u001b[39mgreater_is_better \u001b[38;5;28;01melse\u001b[39;00m metric\n",
      "File \u001b[0;32m/workspaces/automl/src/automl/metrics/functions.py:20\u001b[0m, in \u001b[0;36mScorerWrapper.score\u001b[0;34m(self, y, y_pred)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mscore\u001b[39m(\u001b[38;5;28mself\u001b[39m, y, y_pred):\n\u001b[0;32m---> 20\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscorer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_score_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspaces/automl/.venv/lib/python3.8/site-packages/sklearn/utils/validation.py:63\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m extra_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(all_args)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m extra_args \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# extra_args > 0\u001b[39;00m\n\u001b[1;32m     66\u001b[0m args_msg \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(name, arg)\n\u001b[1;32m     67\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m name, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(kwonly_args[:extra_args],\n\u001b[1;32m     68\u001b[0m                                  args[\u001b[38;5;241m-\u001b[39mextra_args:])]\n",
      "File \u001b[0;32m/workspaces/automl/.venv/lib/python3.8/site-packages/sklearn/metrics/_ranking.py:524\u001b[0m, in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[1;32m    522\u001b[0m y_type \u001b[38;5;241m=\u001b[39m type_of_target(y_true)\n\u001b[1;32m    523\u001b[0m y_true \u001b[38;5;241m=\u001b[39m check_array(y_true, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m--> 524\u001b[0m y_score \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_score\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m (y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    527\u001b[0m                               y_score\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    528\u001b[0m                               y_score\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m):\n\u001b[1;32m    529\u001b[0m     \u001b[38;5;66;03m# do not support partial ROC computation for multiclass\u001b[39;00m\n\u001b[1;32m    530\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m max_fpr \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m max_fpr \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1.\u001b[39m:\n",
      "File \u001b[0;32m/workspaces/automl/.venv/lib/python3.8/site-packages/sklearn/utils/validation.py:63\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m extra_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(all_args)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m extra_args \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# extra_args > 0\u001b[39;00m\n\u001b[1;32m     66\u001b[0m args_msg \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(name, arg)\n\u001b[1;32m     67\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m name, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(kwonly_args[:extra_args],\n\u001b[1;32m     68\u001b[0m                                  args[\u001b[38;5;241m-\u001b[39mextra_args:])]\n",
      "File \u001b[0;32m/workspaces/automl/.venv/lib/python3.8/site-packages/sklearn/utils/validation.py:720\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    716\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    717\u001b[0m                          \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name))\n\u001b[1;32m    719\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[0;32m--> 720\u001b[0m         \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    723\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    724\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n",
      "File \u001b[0;32m/workspaces/automl/.venv/lib/python3.8/site-packages/sklearn/utils/validation.py:103\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (allow_nan \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39misinf(X)\u001b[38;5;241m.\u001b[39many() \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m    101\u001b[0m             \u001b[38;5;129;01mnot\u001b[39;00m allow_nan \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misfinite(X)\u001b[38;5;241m.\u001b[39mall()):\n\u001b[1;32m    102\u001b[0m         type_err \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minfinity\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m allow_nan \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNaN, infinity\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 103\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    104\u001b[0m                 msg_err\u001b[38;5;241m.\u001b[39mformat\n\u001b[1;32m    105\u001b[0m                 (type_err,\n\u001b[1;32m    106\u001b[0m                  msg_dtype \u001b[38;5;28;01mif\u001b[39;00m msg_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m    107\u001b[0m         )\n\u001b[1;32m    108\u001b[0m \u001b[38;5;66;03m# for object dtype data, we only check for NaNs (GH-13254)\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_nan:\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "from automl import AutoML\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "results = []\n",
    "for train, test, target_name, dataset_name in get_train_test_datasets(datasets, datasets_path='./datasets', test_size=0.3, random_state=0):\n",
    "    train, test = train, test\n",
    "    start_time = time.perf_counter()\n",
    "    automl = AutoML(\n",
    "        task='classification',\n",
    "        use_preprocessing_pipeline=False,\n",
    "        feature_selector_type=None,\n",
    "        use_val_test_pipeline=False,\n",
    "        auto_models_init_kwargs = {\n",
    "            \"metric\": \"roc_auc\",\n",
    "            \"time_series\": False,\n",
    "            \"models_list\": [\"all\"],\n",
    "            \"blend\": True,\n",
    "            \"stack\": True\n",
    "        },\n",
    "        n_jobs=12, \n",
    "        random_state=0,\n",
    "        )\n",
    "    automl = automl.fit(\n",
    "        train.drop(columns=[target_name,]), train[target_name].to_numpy(), \n",
    "        test.drop(columns=[target_name,]), test[target_name].to_numpy(),\n",
    "        auto_model_fit_kwargs = {\n",
    "            \"tuning_timeout\": 10\n",
    "        }\n",
    "    )\n",
    "    train_time = time.perf_counter() - start_time\n",
    "    \n",
    "    test_predictions = automl.predict(test.drop(columns=[target_name,]))\n",
    "    predict_time = time.perf_counter() - start_time - train_time\n",
    "    all_time = train_time + predict_time\n",
    "    \n",
    "    test_score = roc_auc_score(test[target_name], test_predictions[:, 1])\n",
    "    results.append((dataset_name, test_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Распределение классов: Counter({0: 90, 1: 10})\n",
      "\n",
      "=== class_weight=None ===\n",
      "\n",
      "=== class_weight=balanced ===\n",
      "\n",
      "=== class_weight=balanced_subsample ===\n",
      "\n",
      "=== class_weight={0: 1, 1: 5} ===\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay\n",
    "from collections import Counter\n",
    "\n",
    "# Создаём несбалансированный набор данных\n",
    "X, y = make_classification(n_classes=2, class_sep=2, \n",
    "                           weights=[0.9, 0.1], # 90% одного класса, 10% другого\n",
    "                           n_samples=100, n_features=10, random_state=42)\n",
    "\n",
    "# Проверяем баланс классов\n",
    "print(f\"Распределение классов: {Counter(y)}\")\n",
    "\n",
    "# Функция для тестирования class_weight\n",
    "def test_class_weight(class_weight):\n",
    "    model = RandomForestClassifier(class_weight=class_weight, random_state=42, n_estimators=100, bootstrap=False)\n",
    "    model.fit(X, y)\n",
    "    y_pred = model.predict(X)\n",
    "    \n",
    "    print(f\"\\n=== class_weight={class_weight} ===\")\n",
    "\n",
    "# 1. Без балансировки\n",
    "test_class_weight(None)\n",
    "\n",
    "# 2. Автоматическая балансировка\n",
    "test_class_weight(\"balanced\")\n",
    "\n",
    "# 2. Автоматическая балансировка\n",
    "test_class_weight(\"balanced_subsample\")\n",
    "\n",
    "# 3. Явное задание весов (например, уменьшаем перевес в 5 раз)\n",
    "test_class_weight({0: 1, 1: 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[0] = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "y = np.array([0, 0, 0])\n",
    "compute_class_weight('balanced', classes=np.unique(y), y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('yasserh/titanic-dataset', 0.7718152397764049),\n",
       " ('rabieelkharoua/predict-liver-disease-1700-records-dataset',\n",
       "  0.9383984211098853),\n",
       " ('devzohaib/eligibility-prediction-for-loan', 0.7440266087428727)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-02-14 12:13:02,768] - [   START    ] - Tuning ABCMeta\n",
      "[2025-02-14 12:13:02,768] - [   START    ] - Tuning ABCMeta\n",
      "[2025-02-14 12:13:02,768] - [   START    ] - Tuning ABCMeta\n",
      "[2025-02-14 12:13:02,768] - [   START    ] - Tuning ABCMeta\n",
      "[2025-02-14 12:13:02,768] - [   START    ] - Tuning ABCMeta\n",
      "[2025-02-14 12:13:02,768] - [   START    ] - Tuning ABCMeta\n",
      "[2025-02-14 12:13:03,598] - [   OPTUNA   ] - Trial 0. New best score 0.7309119871907097 with parameters {'n_estimators': 423, 'max_depth': 12, 'min_samples_split': 2.2874963468977327e-05, 'min_samples_leaf': 0.060466514526367955, 'max_features': 0.23208030173540176, 'bootstrap': False, 'criterion': 'entropy', 'class_weight': 'balanced'}\n",
      "[2025-02-14 12:13:18,515] - [   OPTUNA   ] - Trial 12. New best score 0.73238412552521 with parameters {'n_estimators': 857, 'max_depth': 5, 'min_samples_split': 0.040037769829065185, 'min_samples_leaf': 0.04872820966539076, 'max_features': 0.36908535128002506, 'bootstrap': True, 'max_samples': 0.946191524282273, 'oob_score': False, 'criterion': 'entropy', 'class_weight': 'balanced'}\n",
      "[2025-02-14 12:13:22,502] - [   OPTUNA   ] - Trial 14. New best score 0.7326163668592438 with parameters {'n_estimators': 840, 'max_depth': 15, 'min_samples_split': 0.042574493393550975, 'min_samples_leaf': 0.032761917009704405, 'max_features': 0.2784945320105183, 'bootstrap': False, 'criterion': 'entropy', 'class_weight': 'balanced'}\n",
      "[2025-02-14 12:13:24,597] - [   OPTUNA   ] - Trial 15. New best score 0.7380405287114846 with parameters {'n_estimators': 848, 'max_depth': 15, 'min_samples_split': 0.04604832614399038, 'min_samples_leaf': 0.028143892266236745, 'max_features': 0.43062414712610436, 'bootstrap': True, 'max_samples': 0.714359501139363, 'oob_score': False, 'criterion': 'entropy', 'class_weight': 'balanced'}\n",
      "[2025-02-14 12:13:28,361] - [   OPTUNA   ] - Trial 17. New best score 0.7401132848972922 with parameters {'n_estimators': 700, 'max_depth': 14, 'min_samples_split': 0.08618124360646423, 'min_samples_leaf': 0.019470122706256643, 'max_features': 0.48342382452897115, 'bootstrap': True, 'max_samples': 0.651370960767607, 'oob_score': False, 'criterion': 'entropy', 'class_weight': 'balanced'}\n",
      "[2025-02-14 12:13:31,779] - [   OPTUNA   ] - Trial 19. New best score 0.7458032431722688 with parameters {'n_estimators': 692, 'max_depth': 13, 'min_samples_split': 0.10180439069361111, 'min_samples_leaf': 0.0009429167573029376, 'max_features': 0.4359951856596382, 'bootstrap': True, 'max_samples': 0.7747611541926194, 'oob_score': False, 'criterion': 'entropy', 'class_weight': 'balanced'}\n",
      "[2025-02-14 12:13:35,648] - [   OPTUNA   ] - Trial 21. New best score 0.7458647000466854 with parameters {'n_estimators': 903, 'max_depth': 13, 'min_samples_split': 0.09516213025187295, 'min_samples_leaf': 0.0054817659118747315, 'max_features': 0.44257595017724316, 'bootstrap': True, 'max_samples': 0.7401942982527656, 'oob_score': False, 'criterion': 'entropy', 'class_weight': 'balanced'}\n",
      "[2025-02-14 12:13:37,900] - [   OPTUNA   ] - Trial 22. New best score 0.7463476015406162 with parameters {'n_estimators': 922, 'max_depth': 13, 'min_samples_split': 0.09588995610224543, 'min_samples_leaf': 0.0002935763570997771, 'max_features': 0.44398791830966056, 'bootstrap': True, 'max_samples': 0.7519193556074006, 'oob_score': False, 'criterion': 'entropy', 'class_weight': 'balanced'}\n",
      "[2025-02-14 12:13:56,375] - [   OPTUNA   ] - Trial 31. New best score 0.7464365954715219 with parameters {'n_estimators': 763, 'max_depth': 13, 'min_samples_split': 0.09721268298499108, 'min_samples_leaf': 0.0044906127507777505, 'max_features': 0.4010081889455233, 'bootstrap': True, 'max_samples': 0.8133553654170007, 'oob_score': False, 'criterion': 'entropy', 'class_weight': 'balanced'}\n",
      "[2025-02-14 12:13:58,281] - [   OPTUNA   ] - Trial 32. New best score 0.7467805351307191 with parameters {'n_estimators': 766, 'max_depth': 13, 'min_samples_split': 0.11108577698079326, 'min_samples_leaf': 0.0002323696070544402, 'max_features': 0.34239342546811735, 'bootstrap': True, 'max_samples': 0.8667146239031396, 'oob_score': False, 'criterion': 'entropy', 'class_weight': 'balanced'}\n",
      "[2025-02-14 12:14:03,856] - [   OPTUNA   ] - 36 trials completed\n",
      "[2025-02-14 12:14:03,856] - [   OPTUNA   ] - 36 trials completed\n",
      "[2025-02-14 12:14:03,856] - [   OPTUNA   ] - 36 trials completed\n",
      "[2025-02-14 12:14:03,856] - [   OPTUNA   ] - 36 trials completed\n",
      "[2025-02-14 12:14:03,856] - [   OPTUNA   ] - 36 trials completed\n",
      "[2025-02-14 12:14:03,856] - [   OPTUNA   ] - 36 trials completed\n",
      "[2025-02-14 12:14:03,861] - [BEST PARAMS ] - {'random_state': 1, 'n_jobs': 1, 'verbose': 0, 'n_estimators': 766, 'max_depth': 13, 'min_samples_split': 0.11108577698079326, 'min_samples_leaf': 0.0002323696070544402, 'max_features': 0.34239342546811735, 'bootstrap': True, 'max_samples': 0.8667146239031396, 'oob_score': False, 'criterion': 'entropy', 'class_weight': 'balanced', 'time_series': False, 'model_type': 'classification', 'n_splits': 2, 'name': 'ABCMeta', 'eval_metric': 'custom_metric'}\n",
      "[2025-02-14 12:14:03,861] - [BEST PARAMS ] - {'random_state': 1, 'n_jobs': 1, 'verbose': 0, 'n_estimators': 766, 'max_depth': 13, 'min_samples_split': 0.11108577698079326, 'min_samples_leaf': 0.0002323696070544402, 'max_features': 0.34239342546811735, 'bootstrap': True, 'max_samples': 0.8667146239031396, 'oob_score': False, 'criterion': 'entropy', 'class_weight': 'balanced', 'time_series': False, 'model_type': 'classification', 'n_splits': 2, 'name': 'ABCMeta', 'eval_metric': 'custom_metric'}\n",
      "[2025-02-14 12:14:03,861] - [BEST PARAMS ] - {'random_state': 1, 'n_jobs': 1, 'verbose': 0, 'n_estimators': 766, 'max_depth': 13, 'min_samples_split': 0.11108577698079326, 'min_samples_leaf': 0.0002323696070544402, 'max_features': 0.34239342546811735, 'bootstrap': True, 'max_samples': 0.8667146239031396, 'oob_score': False, 'criterion': 'entropy', 'class_weight': 'balanced', 'time_series': False, 'model_type': 'classification', 'n_splits': 2, 'name': 'ABCMeta', 'eval_metric': 'custom_metric'}\n",
      "[2025-02-14 12:14:03,861] - [BEST PARAMS ] - {'random_state': 1, 'n_jobs': 1, 'verbose': 0, 'n_estimators': 766, 'max_depth': 13, 'min_samples_split': 0.11108577698079326, 'min_samples_leaf': 0.0002323696070544402, 'max_features': 0.34239342546811735, 'bootstrap': True, 'max_samples': 0.8667146239031396, 'oob_score': False, 'criterion': 'entropy', 'class_weight': 'balanced', 'time_series': False, 'model_type': 'classification', 'n_splits': 2, 'name': 'ABCMeta', 'eval_metric': 'custom_metric'}\n",
      "[2025-02-14 12:14:03,861] - [BEST PARAMS ] - {'random_state': 1, 'n_jobs': 1, 'verbose': 0, 'n_estimators': 766, 'max_depth': 13, 'min_samples_split': 0.11108577698079326, 'min_samples_leaf': 0.0002323696070544402, 'max_features': 0.34239342546811735, 'bootstrap': True, 'max_samples': 0.8667146239031396, 'oob_score': False, 'criterion': 'entropy', 'class_weight': 'balanced', 'time_series': False, 'model_type': 'classification', 'n_splits': 2, 'name': 'ABCMeta', 'eval_metric': 'custom_metric'}\n",
      "[2025-02-14 12:14:03,861] - [BEST PARAMS ] - {'random_state': 1, 'n_jobs': 1, 'verbose': 0, 'n_estimators': 766, 'max_depth': 13, 'min_samples_split': 0.11108577698079326, 'min_samples_leaf': 0.0002323696070544402, 'max_features': 0.34239342546811735, 'bootstrap': True, 'max_samples': 0.8667146239031396, 'oob_score': False, 'criterion': 'entropy', 'class_weight': 'balanced', 'time_series': False, 'model_type': 'classification', 'n_splits': 2, 'name': 'ABCMeta', 'eval_metric': 'custom_metric'}\n",
      "[2025-02-14 12:14:03,866] - [    END     ] - Tuning ABCMeta\n",
      "[2025-02-14 12:14:03,866] - [    END     ] - Tuning ABCMeta\n",
      "[2025-02-14 12:14:03,866] - [    END     ] - Tuning ABCMeta\n",
      "[2025-02-14 12:14:03,866] - [    END     ] - Tuning ABCMeta\n",
      "[2025-02-14 12:14:03,866] - [    END     ] - Tuning ABCMeta\n",
      "[2025-02-14 12:14:03,866] - [    END     ] - Tuning ABCMeta\n"
     ]
    }
   ],
   "source": [
    "from automl.model.catboost import CatBoostClassification, CatBoostRegression\n",
    "from automl.model.lightgbm import LightGBMClassification, LightGBMRegression\n",
    "from automl.model.xgboost import XGBClassification, XGBRegression\n",
    "from automl.model.sklearn import ExtraTreesClassification, ExtraTreesRegression\n",
    "from automl.model.sklearn import RandomForestClassification, RandomForestRegression\n",
    "from automl.model.sklearn import LogisticRegression, RidgeRegression\n",
    "from automl.model.lama import TabularLamaClassification, TabularLamaRegression\n",
    "from automl.model.lama import TabularLamaUtilizedClassification, TabularLamaUtilizedRegression\n",
    "\n",
    "\n",
    "model = RandomForestClassification(n_splits=2, n_jobs=1, num_iterations=2, random_state=1)\n",
    "model.tune(train.drop(columns=[target_name,]), train[target_name].to_numpy(), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 32\u001b[0m\n\u001b[1;32m     29\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Оцениваем качество модели с помощью среднеквадратичной ошибки (MSE)\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m mse \u001b[38;5;241m=\u001b[39m \u001b[43mmean_squared_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMean Squared Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmse\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Пример предсказания для новых данных\u001b[39;00m\n",
      "File \u001b[0;32m/workspaces/automl/.venv/lib/python3.8/site-packages/sklearn/utils/validation.py:63\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m extra_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(all_args)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m extra_args \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# extra_args > 0\u001b[39;00m\n\u001b[1;32m     66\u001b[0m args_msg \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(name, arg)\n\u001b[1;32m     67\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m name, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(kwonly_args[:extra_args],\n\u001b[1;32m     68\u001b[0m                                  args[\u001b[38;5;241m-\u001b[39mextra_args:])]\n",
      "File \u001b[0;32m/workspaces/automl/.venv/lib/python3.8/site-packages/sklearn/metrics/_regression.py:335\u001b[0m, in \u001b[0;36mmean_squared_error\u001b[0;34m(y_true, y_pred, sample_weight, multioutput, squared)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;129m@_deprecate_positional_args\u001b[39m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmean_squared_error\u001b[39m(y_true, y_pred, \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m    276\u001b[0m                        sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    277\u001b[0m                        multioutput\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muniform_average\u001b[39m\u001b[38;5;124m'\u001b[39m, squared\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    278\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Mean squared error regression loss.\u001b[39;00m\n\u001b[1;32m    279\u001b[0m \n\u001b[1;32m    280\u001b[0m \u001b[38;5;124;03m    Read more in the :ref:`User Guide <mean_squared_error>`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;124;03m    0.825...\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 335\u001b[0m     y_type, y_true, y_pred, multioutput \u001b[38;5;241m=\u001b[39m \u001b[43m_check_reg_targets\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmultioutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    337\u001b[0m     check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[1;32m    338\u001b[0m     output_errors \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39maverage((y_true \u001b[38;5;241m-\u001b[39m y_pred) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m    339\u001b[0m                                weights\u001b[38;5;241m=\u001b[39msample_weight)\n",
      "File \u001b[0;32m/workspaces/automl/.venv/lib/python3.8/site-packages/sklearn/metrics/_regression.py:90\u001b[0m, in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[1;32m     88\u001b[0m check_consistent_length(y_true, y_pred)\n\u001b[1;32m     89\u001b[0m y_true \u001b[38;5;241m=\u001b[39m check_array(y_true, ensure_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m---> 90\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_true\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m     93\u001b[0m     y_true \u001b[38;5;241m=\u001b[39m y_true\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32m/workspaces/automl/.venv/lib/python3.8/site-packages/sklearn/utils/validation.py:63\u001b[0m, in \u001b[0;36m_deprecate_positional_args.<locals>._inner_deprecate_positional_args.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m extra_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(all_args)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m extra_args \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# extra_args > 0\u001b[39;00m\n\u001b[1;32m     66\u001b[0m args_msg \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(name, arg)\n\u001b[1;32m     67\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m name, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(kwonly_args[:extra_args],\n\u001b[1;32m     68\u001b[0m                                  args[\u001b[38;5;241m-\u001b[39mextra_args:])]\n",
      "File \u001b[0;32m/workspaces/automl/.venv/lib/python3.8/site-packages/sklearn/utils/validation.py:720\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    716\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    717\u001b[0m                          \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name))\n\u001b[1;32m    719\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[0;32m--> 720\u001b[0m         \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    723\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_samples \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    724\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(array)\n",
      "File \u001b[0;32m/workspaces/automl/.venv/lib/python3.8/site-packages/sklearn/utils/validation.py:103\u001b[0m, in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (allow_nan \u001b[38;5;129;01mand\u001b[39;00m np\u001b[38;5;241m.\u001b[39misinf(X)\u001b[38;5;241m.\u001b[39many() \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m    101\u001b[0m             \u001b[38;5;129;01mnot\u001b[39;00m allow_nan \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misfinite(X)\u001b[38;5;241m.\u001b[39mall()):\n\u001b[1;32m    102\u001b[0m         type_err \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minfinity\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m allow_nan \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNaN, infinity\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 103\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    104\u001b[0m                 msg_err\u001b[38;5;241m.\u001b[39mformat\n\u001b[1;32m    105\u001b[0m                 (type_err,\n\u001b[1;32m    106\u001b[0m                  msg_dtype \u001b[38;5;28;01mif\u001b[39;00m msg_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m    107\u001b[0m         )\n\u001b[1;32m    108\u001b[0m \u001b[38;5;66;03m# for object dtype data, we only check for NaNs (GH-13254)\u001b[39;00m\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_nan:\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Создаем синтетические данные для примера\n",
    "np.random.seed(42)\n",
    "y = [0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1,]\n",
    "X = np.random.rand(len(y), 5) \n",
    "# Разделяем данные на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Создаем модель ExtraTreesRegressor\n",
    "model = ExtraTreesRegressor(**{\n",
    "    'n_estimators': 162, \n",
    "    'max_depth': 10, \n",
    "    'min_samples_split': 0.05738637015674741, \n",
    "    'min_samples_leaf': 0.0808205755459821, \n",
    "    'max_features': 0.7034906283443978, \n",
    "    'bootstrap': True, \n",
    "    'max_samples': 0.014692718456558174, \n",
    "    # 'oob_score': False,\n",
    "    })\n",
    "\n",
    "# Обучаем модель на обучающей выборке\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Делаем предсказания на тестовой выборке\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Оцениваем качество модели с помощью среднеквадратичной ошибки (MSE)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse:.4f}\")\n",
    "\n",
    "# Пример предсказания для новых данных\n",
    "new_data = np.array([[0.5, 0.3, 0.2, 0.1, 0.4]])\n",
    "prediction = model.predict(new_data)\n",
    "print(f\"Prediction for new data: {prediction[0]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.12203823, 0.49517691, 0.03438852, 0.9093204 , 0.25877998],\n",
       "       [0.86310343, 0.62329813, 0.33089802, 0.06355835, 0.31098232],\n",
       "       [0.37454012, 0.95071431, 0.73199394, 0.59865848, 0.15601864],\n",
       "       [0.87146059, 0.80367208, 0.18657006, 0.892559  , 0.53934224],\n",
       "       [0.92187424, 0.0884925 , 0.19598286, 0.04522729, 0.32533033]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, nan, nan, nan, nan])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
