{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "\n",
    "\n",
    "def get_array_type(array):\n",
    "    if isinstance(array, pd.DataFrame):\n",
    "        return 'pandas'\n",
    "    elif isinstance(array, np.ndarray):\n",
    "        return 'numpy'\n",
    "    elif isinstance(array, pl.DataFrame):\n",
    "        return 'polars'\n",
    "    else:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "\n",
    "import kaggle\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "kaggle.api.authenticate()\n",
    "\n",
    "datasets = [\n",
    "    {\n",
    "        'link': 'https://www.kaggle.com/datasets/yasserh/titanic-dataset', \n",
    "        'target': 'Survived',\n",
    "        'id_cols': ['PassengerId',],\n",
    "    },\n",
    "    {\n",
    "        'link': 'https://www.kaggle.com/datasets/rabieelkharoua/predict-liver-disease-1700-records-dataset', \n",
    "        'target': 'Diagnosis',\n",
    "    },\n",
    "    {\n",
    "        'link': 'https://www.kaggle.com/datasets/devzohaib/eligibility-prediction-for-loan', \n",
    "        'target': 'Loan_Status',\n",
    "        'id_cols': ['Loan_ID',],\n",
    "    },\n",
    "    {\n",
    "        'link': 'https://www.kaggle.com/datasets/deepcontractor/smoke-detection-dataset', \n",
    "        'target': 'Fire Alarm',\n",
    "        'id_cols': ['index',],\n",
    "    },\n",
    "    {\n",
    "        'link': 'https://www.kaggle.com/datasets/stealthtechnologies/employee-attrition-dataset', \n",
    "        'target': 'Attrition',\n",
    "        'id_cols': ['Employee ID',],\n",
    "    },\n",
    "    {\n",
    "        'link': 'https://www.kaggle.com/datasets/rabieelkharoua/cancer-prediction-dataset', \n",
    "        'target': 'Diagnosis',\n",
    "    },\n",
    "    {\n",
    "        'link': 'https://www.kaggle.com/datasets/yasserh/heart-disease-dataset', \n",
    "        'target': 'target',\n",
    "    },\n",
    "    {\n",
    "        'link': 'https://www.kaggle.com/datasets/rabieelkharoua/predict-online-course-engagement-dataset', \n",
    "        'target': 'CourseCompletion',\n",
    "        'id_cols': ['UserID',],\n",
    "    },\n",
    "    {\n",
    "        'link': 'https://www.kaggle.com/datasets/rabieelkharoua/predicting-hiring-decisions-in-recruitment-data', \n",
    "        'target': 'HiringDecision',\n",
    "    },\n",
    "    {\n",
    "        'link': 'https://www.kaggle.com/datasets/barun2104/telecom-churn', \n",
    "        'target': 'Churn',\n",
    "    },\n",
    "    {\n",
    "        'link': 'https://www.kaggle.com/datasets/rabieelkharoua/predicting-manufacturing-defects-dataset', \n",
    "        'target': 'DefectStatus',\n",
    "    },\n",
    "    {\n",
    "        'link': 'https://www.kaggle.com/datasets/rabieelkharoua/predict-customer-purchase-behavior-dataset',\n",
    "        'target': 'PurchaseStatus',\n",
    "    },\n",
    "    {\n",
    "        'link': 'https://www.kaggle.com/datasets/teejmahal20/airline-passenger-satisfaction', \n",
    "        'target': 'Satisfaction',\n",
    "    },\n",
    "    {\n",
    "        'link': 'https://www.kaggle.com/datasets/dhanushnarayananr/credit-card-fraud', \n",
    "        'target': 'fraud',\n",
    "    },\n",
    "    {\n",
    "        'link': 'https://www.kaggle.com/datasets/rameshmehta/credit-risk-analysis', \n",
    "        'target': 'default_ind',\n",
    "        'id_cols': ['id', 'member_id',],\n",
    "        'time_col': 'issue_d',\n",
    "    },\n",
    "    {\n",
    "        'link': 'https://www.kaggle.com/datasets/marcpaulo/titanic-huge-dataset-1m-passengers', \n",
    "        'target': 'Survived',\n",
    "        'id_cols': ['PassengerId',],\n",
    "    },\n",
    "    # {\n",
    "    #     'link': 'https://www.kaggle.com/datasets/manishtripathi86/fedex-data', \n",
    "    #     'target': 'Delivery_Status',\n",
    "    #     'time_col': 'Year',\n",
    "    # },\n",
    "    {\n",
    "        'link': 'https://www.kaggle.com/datasets/ban7002/fraud-challenge-data', \n",
    "        'target': 'EVENT_LABEL',\n",
    "        'time_col': 'EVENT_TIMESTAMP',\n",
    "    },\n",
    "    {\n",
    "        'link': 'https://www.kaggle.com/datasets/ulrikthygepedersen/kickstarter-projects', \n",
    "        'target': 'State',\n",
    "        'id_cols': ['ID',],\n",
    "        'time_col': 'Launched',\n",
    "    },\n",
    "]\n",
    "\n",
    "def get_train_test_datasets(datasets, datasets_path, test_size=0.3, random_state=0):\n",
    "    from tqdm import tqdm\n",
    "    from pathlib import Path\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    \n",
    "    \n",
    "    for dataset in tqdm(datasets):\n",
    "        dataset_name = dataset['link'].replace('https://www.kaggle.com/datasets/', '')\n",
    "        files = list((Path(datasets_path) / dataset_name).glob('*.csv'))\n",
    "        if len(files) == 1:\n",
    "            dataset_path = files[0]\n",
    "            data = pd.read_csv(dataset_path)\n",
    "            target_name = dataset['target']\n",
    "            data = data.dropna(subset=[target_name])\n",
    "            \n",
    "            if dataset.get('id_cols'):\n",
    "                data = data.drop(columns=[dataset['id_cols']], errors='ignore')\n",
    "\n",
    "            le = LabelEncoder()\n",
    "            data[target_name] = le.fit_transform(data[target_name])\n",
    "            data = data.select_dtypes(include=[np.number]).dropna(how='any')\n",
    "            train_data, test_data = train_test_split(\n",
    "                data, \n",
    "                test_size=test_size, \n",
    "                stratify=data[target_name], \n",
    "                random_state=random_state\n",
    "            )\n",
    "            yield train_data, test_data, target_name, dataset_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/18 [00:00<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "for train, test, target_name, dataset_name in get_train_test_datasets(datasets, datasets_path='./datasets', test_size=0.3, random_state=0):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>350</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>519</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>796</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856</th>\n",
       "      <td>857</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>164.8667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>245</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>808</th>\n",
       "      <td>809</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>192</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>499 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass   Age  SibSp  Parch      Fare\n",
       "349          350         0       3  42.0      0      0    8.6625\n",
       "518          519         1       2  36.0      1      0   26.0000\n",
       "44            45         1       3  19.0      0      0    7.8792\n",
       "795          796         0       2  39.0      0      0   13.0000\n",
       "69            70         0       3  26.0      2      0    8.6625\n",
       "..           ...       ...     ...   ...    ...    ...       ...\n",
       "83            84         0       1  28.0      0      0   47.1000\n",
       "856          857         1       1  45.0      1      1  164.8667\n",
       "244          245         0       3  30.0      0      0    7.2250\n",
       "808          809         0       2  39.0      0      0   13.0000\n",
       "191          192         0       2  19.0      0      0   13.0000\n",
       "\n",
       "[499 rows x 7 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "        'A': ['apple', 'banana', None],\n",
    "        'B': [None, 'dog', 'cat'],\n",
    "        'C': [1, None, 3],\n",
    "        'D': ['red', None, 'red']\n",
    "    })\n",
    "df_obj = df.select_dtypes(include='object')\n",
    "counter_ = df_obj.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Series.corr() missing 1 required positional argument: 'other'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m X \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[1;32m      2\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mA\u001b[39m\u001b[38;5;124m'\u001b[39m: [np\u001b[38;5;241m.\u001b[39mnan, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, np\u001b[38;5;241m.\u001b[39mnan],\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m, np\u001b[38;5;241m.\u001b[39mnan, np\u001b[38;5;241m.\u001b[39mnan, \u001b[38;5;241m8\u001b[39m],\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, np\u001b[38;5;241m.\u001b[39mnan, np\u001b[38;5;241m.\u001b[39mnan],\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m]  \u001b[38;5;66;03m# Shouldn't affect selection\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     })\n\u001b[0;32m----> 7\u001b[0m \u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mA\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorr\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: Series.corr() missing 1 required positional argument: 'other'"
     ]
    }
   ],
   "source": [
    "X = pd.DataFrame({\n",
    "        'A': [np.nan, 1, 2, 3, np.nan],\n",
    "        'B': [4, 5, np.nan, np.nan, 8],\n",
    "        'C': [1, 2, 3, np.nan, np.nan],\n",
    "        'D': [1, 1, 1, 1, 1]  # Shouldn't affect selection\n",
    "    })\n",
    "X['A'].corr()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
